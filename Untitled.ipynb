{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a48355b-5f1c-46de-9b32-3f352e9eebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Optional, Literal, Callable\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import ToolMessage, AIMessage\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "from table_agent import (\n",
    "    table_searching_runnable,\n",
    "    search_table,\n",
    ")\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"primary_assistant\",\n",
    "                \"search_table_assistant\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]\n",
    "\n",
    "\n",
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state_and_leave(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "def route_primary_assistant(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"enter_search_table\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == ToTableSearchingAssistant.__name__:\n",
    "            return \"enter_search_table\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "\n",
    "def route_search_table(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"search_table_tools\",\n",
    "    \"leave_assistant\",\n",
    "    \"leave_assistant2\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if last_message.content == \"问题中需要提供型号名称才能完成搜索\":\n",
    "            status = \"retry\"\n",
    "        elif last_message.content == \"搜索结果和问题的匹配度很低，请换个问法\":\n",
    "            status = \"ask_for_human\"\n",
    "        else:\n",
    "            status = \"reset\"\n",
    "        if status == \"ask_for_human\":\n",
    "            return \"leave_assistant\"\n",
    "        elif status == \"retry\":\n",
    "            return \"__end__\"\n",
    "        else:\n",
    "            return \"leave_assistant2\"\n",
    "    return \"search_table_tools\"\n",
    "\n",
    "\n",
    "def set_entry_point(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"primary_assistant\",\n",
    "    \"search_table_assistant\",\n",
    "]:\n",
    "    current_at = state.get(\"dialog_state\", [])\n",
    "    if not current_at:\n",
    "        return \"primary_assistant\"\n",
    "    else:\n",
    "        return current_at[-1]\n",
    "\n",
    "\n",
    "class SearchTableAssistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        # print(\"state:\", state)\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if isinstance(last_message, ToolMessage) and (last_message.name == \"search_table\"):\n",
    "            result = AIMessage(content=last_message.content)\n",
    "            # if last_message.content == \"问题中需要提供型号名称才能完成搜索\":\n",
    "            #     status = \"retry\"\n",
    "            # elif last_message.content == \"搜索结果和问题的匹配度很低，请换个问法\":\n",
    "            #     status = \"ask_for_human\"\n",
    "            # else:\n",
    "            #     status = \"reset\"\n",
    "            return {\"messages\": result}\n",
    "\n",
    "        # status = state.get(\"status\", \"reset\")\n",
    "        while True:\n",
    "            # if status == \"reset\":\n",
    "            #     suffix = \" Directly use the query as input to your tools, and do not make any language translations or rephrases\"\n",
    "            # else:\n",
    "            #     suffix = \"\"\n",
    "            # input_dict = {\"messages\": state[\"messages\"], \"suffix\": suffix}\n",
    "            # result = self.runnable.invoke(input_dict)\n",
    "            result = self.runnable.invoke(state)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        # return {\"messages\": result, \"status\": status}\n",
    "        print(\"I am search table assistant\")\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        print(\"Im am primary\")\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "class ToTableSearchingAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant for searching table about parameter of cleaning machines.\"\"\"\n",
    "    query: str = Field(\n",
    "        description=\"Ensure to keep all the necessary information and keep the language the same as the original.\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for household cleaning machines. \"\n",
    "            \"Reject to answer if a customer queries about something out of this scope. \"\n",
    "            \"When a task takes expertise, delegate it to the appropriate specialized assistant\"\n",
    "            \" by invoking the corresponding tool. \"\n",
    "            \"The user is not aware of the different specialized assistants,\"\n",
    "            \" so do not mention them and just quietly delegate through function calls.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "    [\n",
    "        ToTableSearchingAssistant\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        query = state[\"messages\"][-1].tool_calls[0][\"args\"][\"query\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation and\"\n",
    "                    \" use your tools to assist the user if appropriate. \"\n",
    "                    \"Do not mention who you are - just act as the proxy for the assistant. \"\n",
    "                    \"Use the query below as input to your tools:\"\n",
    "                    f\"\\n\\nquery: {query}\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": assistant_name,\n",
    "        }\n",
    "    return entry_node\n",
    "\n",
    "\n",
    "# begin of graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# search_table subgraph\n",
    "# node\n",
    "builder.add_node(\"search_table_assistant\", SearchTableAssistant(table_searching_runnable))\n",
    "builder.add_node(\n",
    "    \"search_table_tools\",\n",
    "    create_tool_node_with_fallback([search_table]),\n",
    ")\n",
    "# edge\n",
    "builder.add_edge(\"search_table_tools\", \"search_table_assistant\")\n",
    "builder.add_conditional_edges(\"search_table_assistant\", route_search_table)\n",
    "\n",
    "# interface to search_table subgraph\n",
    "builder.add_node(\n",
    "    \"enter_search_table\",\n",
    "    create_entry_node(\"search_table_assistant\"),\n",
    ")\n",
    "builder.add_edge(\"enter_search_table\", \"search_table_assistant\")\n",
    "builder.add_node(\"leave_assistant\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_assistant\", \"primary_assistant\")\n",
    "builder.add_node(\"leave_assistant2\", pop_dialog_state_and_leave)\n",
    "builder.add_edge(\"leave_assistant2\", END)\n",
    "\n",
    "# primary assistant\n",
    "# node\n",
    "builder.add_node(\"primary_assistant\", Assistant(assistant_runnable))\n",
    "builder.set_conditional_entry_point(\n",
    "    set_entry_point,\n",
    ")\n",
    "\n",
    "# edge\n",
    "builder.add_conditional_edges(\n",
    "    \"primary_assistant\",\n",
    "    route_primary_assistant,\n",
    "    {\n",
    "        \"enter_search_table\": \"enter_search_table\",\n",
    "        \"__end__\": END,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52d41ad9-9f7a-4997-aa33-a38449651664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fbe1d17f-eb4f-482f-b858-66672aa62de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(part_4_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d76a4b76-0d31-4810-8648-b1874e1e029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight informatio\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": \"198197a5-c74c-463d-8312-ded3f1d94479\",\n",
    "    }\n",
    "}\n",
    "_printed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ed544e4c-0068-4e83-9101-134f4d445b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"这两个相比哪个水箱大\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f3d49002-2e9f-4905-8559-165e8ac71b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "这两个相比哪个水箱大\n",
      "Im am primary\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "从上述信息中，我们可以看出，G20标准版的清水箱容量为3.5L，污水箱容量为2.9L；P10标准版的清水箱容量为5L，污水箱容量为4.2L。所以，P10的水箱容量更大。\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8a432-f187-48d5-93ad-d8b15163b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "g20 | 标准版 | 清水箱3.5L，污水箱2.9L |\n",
    "| p10 | 上下水版 | None |\n",
    "| g20 | 上下水版 | None |\n",
    "| p10 | 标准版 | 清水箱5L，污水箱4.2L |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "005fae71-a227-4e1b-99a1-c1416c77d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = table_searching_runnable.invoke({\"messages\": [\"你好\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "be79bad4-f99d-4aaa-b488-225750144e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，有什么可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 109, 'total_tokens': 127}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-1bf6ec82-65fa-433a-9893-1eee8a65189f-0', usage_metadata={'input_tokens': 109, 'output_tokens': 18, 'total_tokens': 127})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e875c768-aa32-43c0-94bd-c23ed45ab90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，有什么可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 109, 'total_tokens': 127}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, name='ddd', id='run-1bf6ec82-65fa-433a-9893-1eee8a65189f-0', usage_metadata={'input_tokens': 109, 'output_tokens': 18, 'total_tokens': 127})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=\"ddd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d63fc-67b0-49e1-bc50-b98e36582b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004efc5-4452-46d0-bb0b-009174755f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba5691ec-8e01-4bfd-b337-08778fd59f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAGCAbgDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAYHBAUIAwIBCf/EAFcQAAEEAQIDAgkGCAoGCQQDAAEAAgMEBQYRBxIhEzEIFBYiQVFVlNEVFzJhk+EjOFRxdoGStDM2QlJWc3SRobEJNUNicnUYJDdFU4Kys8MlosHSg4SV/8QAGwEBAAMBAQEBAAAAAAAAAAAAAAECAwQFBgf/xAA6EQEAAQIBCQQJBAEEAwAAAAAAAQIDEQQSExQhMVFSoUFhkfAFFTJicYGxweEiMzTRU0JDcrJjwvH/2gAMAwEAAhEDEQA/AP6poiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiDAtZ/F0p3Q2MlUgmbtzRyzta4dN+oJ9S8vKrC+2KHvLPiqzmxVK7rPWMlinBYeMlG0Olia47eJVum5CyPJ7F+zaf2DPguHKMvsZPcm1VTMzGHDtiJerbyHSURVnb1ieVWF9sUPeWfFPKrC+2KHvLPiq78nsX7Np/YM+CeT2L9m0/sGfBc/rXJ+Srxhp6u97osTyqwvtih7yz4p5VYX2xQ95Z8VXfk9i/ZtP7BnwTyexfs2n9gz4J61yfkq8YPV3vdFieVWF9sUPeWfFPKrC+2KHvLPiq78nsX7Np/YM+CeT2L9m0/sGfBPWuT8lXjB6u97osTyqwvtih7yz4p5VYX2xQ95Z8VXfk9i/ZtP7BnwTyexfs2n9gz4J61yfkq8YPV3vdFlU85jshN2VXIVbMu2/JDM17tvXsCs5VRp/G1KPEbCGtVhrl1S2HGKMN3/gu/YK116lFdN23Rdo3VR2/GY+zzr9rQ15mOIiIrOcREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERBVMf8b9Zf8zj/cqyzlgx/wAb9Zf8zj/cqyzl8n6T/lVfCP8ArD6vJ/2afgKIa34taU4c26lXP5XxO1ajfNHBFWmsP7NpAdI5sTHFrASN3O2H1qXqjPCGisY/K0s3pzG6qZrqrj5o8Zk8Bjzbqy7uBFS23q3s3Pa07uA5e8OBGx4LVMV15tS9yqaacYSaPjpizxluaBkp3Wyw0608dxlGzI2SWZz/ADCWxcrGBrWntHO5SXFu4LHBbTF8bdFZnV3kxVzW+aMstdkEtWaJksse/aMjlewMe5vK7cNcT0PqUKrW83pfjrBmczp3Jzxag05j6D7OIqPtV6tyOeUyslc3fs2DtgQ93TYHruFWQo6szuc0XkM9idb3tUY3VsdrL9pDMMTSrdpLE01owezkaGvjPOwPcG85c4dV1RZoq8OPawm5VHjw7F9v476NdkMrj6uQtX7+LfZitwU8bam7GSBrnSMeWRENOzHcu/09tm8xX1wV4t0+MeiKOcr1LFCxJDHJYrTVpmMic4E8rJJI2CYDb6bNwtRwU07cxmP4ix26E2PkyGrMpYiNiF0fbRvc0MlG485pA6OHQgdF4eDLdu0uF+G0tlMFl8LltPU4qVr5RpPihle0ubvDIfNlb5u+7SRs4LKuiiKas3fGHa0pqrmqMe3FbiIi5XQ8MT/2iYL+y3P/AIlZ6rDE/wDaJgv7Lc/+JWevt8k/iWvhP/ap83l370iIi6XAIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgqmP+N+sv8Amcf7lWUdz3B7QuqctPlMzo/CZTJT8va27lCKWWTlaGt3c5pJ2aAPzAKyslwzx2Ry97Ii9k6k12RsszKtnkYXBjYwdtv5rG/3LH+aqj7Yzfvv3LzcpyCb96btFzDGI7J7IiHtW8stU26aKoxwVcfB/wCGZ230Bps7d2+Lh6f/AGqVaa0phdG435PwOKp4ajzmTxajA2GPmO27uVoA3Ow6/UpP81VH2xm/ffuT5qqPtjN++/cuafRVdWyb31aRltmNsUtai2XzVUfbGb99+5VFhKt2/wCFJqXQkubyhwFDTlbJwsFjaQTPmLHEv26jYdyp6n/8seEresLXCVlrR6p0Np3XEEEOosHj85FXcXxMyFZkzY3EbEtDgdipd81VH2xm/ffuT5qqPtjN++/cpj0RMTjF2PCUTl9qdkxKrv8Ao/8ADPbbyA03t6vkuH/9VuNL8L9H6JvyXdP6YxOEuSRGF89CnHC9zCQS0loBI3a07fUFOfmqo+2M3779yfNVR9sZv337lafRdcxhN76qxltiNsU9IabE/wDaJgv7Lc/+JWeorhOHdDB5iLJsuZC3ZijfFH43Y7RrQ7bm2G3f5oUqXsW7cWbNFqJxzYn6zP3eXlN2L1zPpERFdzCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgLnfS/492tv0Lo/vBXRC530v8Aj3a2/Quj+8FB0QiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAud9L/j3a2/Quj+8FdELnfS/492tv0Lo/vBQdEIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAi8bduChVls2Zo69eFhfJNK4NYxoG5JJ6AAekqE3OJNu28twmHM8PUC3kZTWY762s5XPI/OG+sb9N9KbdVUYxu8GlFuu5OFMYp4irU6z1aT0q4UD1F8xTyz1d+TYT9qZX0Uc0eLfVL3BZSKtfLPV35NhP2pk8s9Xfk2E/amTRRzR4mqXuCykVa+WervybCftTJ5Z6u/JsJ+1MmijmjxNUvcGZx54XRcaeEGqNGSyiB2Uq8sEriQ1k7HNkhc7bryiRjCR6QCv4k6Z4X6g1RxOp6Cr0nx6jnyPyY+tIOsMoeWyc+2+wZs4uPoDSfQv7VeWervybCftTKo8LwZOD8IDLcW69TE/L2QqCDxYmTsIZSA2SdnTcPexoaf+J56l3Roo5o8TVL3B0Fw30FjOF+g8FpTDs5cdiarK0ZIAc8gec9238pzi5x+txUkVa+WervybCftTJ5Z6u/JsJ+1MmijmjxNUvcFlIq18s9Xfk2E/amTyz1d+TYT9qZNFHNHiape4LKRVr5Z6u/JsJ+1Mnlnq78mwn7UyaKOaPE1S9wWUirZutNWjqamFf8AUHzN3/Xsf8lnUeJrqsgZn8YcZF+XVpvGKzfreeVr2D6y3lHXdw7y0Mz7MxPwlWrJrtMYzSnaL5Y9srGvY4PY4btc07gj1hfSwcwiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiCs9R5V2qM/Yr7k4nGS9mIwfNsWRsXPcPSIzsGg/wAsOOxLWEfK0+kXumwMUr/4WaWaWX+sdK9z9/r5iVDuPOpM3pvTGEdp/JfJN6/qDG411rsGTcsc9hsb/NeCD0d9R9RCvlGy5NHZTs8P7fS2qYs2owWSsXI5ajh4opb9yvSjllZBG+zK2MPkeeVjASRu5xIAHeSei564gcRda8L4+IeBl1I7N26WlTqLFZielBHYrOEronRyMYwRvG4a5p5B/KB32Wz4h1tWYDAaHyGU1YcvNd1RiI7VKbFUzWDZZ42uZGHRF7Q0klr+YvB683Rc+C03d+Ebl+IuYtVcQOIVfS/EHVVDV7arNN6pdiqmLfjIJIJoDPAzaVxHOSBP0LXNPm9SSdxKLmu85w91HrjAak1p4xSp6cgzdTPWcbF2tJ8ks0BZ2UTWtlHPG0tbtzHfl3O+6Gljh58wvVFzPp/itrnGN4hYrLWstJNR0lJqDFXs7i6lO3E8CVvWKEuY5nM1pAe0OBDg4Fbt2pNcaO4e6R17mdWyZalPLjp85Q8QrRV4Kk7CyR0ZbH2nmPmikJLu6J3QAkJgRdiexfqKv+F2qMrrTMa0yk1rn09FlnYzEVxGwAMrtEc8oeBu7nn7QdSQBGNttzvk8Y9TnS2iZZ4c1YwV6xYhq1J6dBt6xLM94Aihhd0e943A36DvPQFF86M3OTdFzHjeJXFK7pPWuKrMyVnPYDLUWPtz42qMoMfMxskrm1o3ugfM1vNygHZwI83m6LN1FxG1L5HaSy+G1rfvaV7S63Papo4GKW5Ucwjsmz1Cz8G1vniQiPcFoOzQUwZ6aMMcPO50K/LUY8nHjXXK7cjJE6dlQytEz42kBzwzfctBc0E7bAketZMkjYmOe9wYxo3c5x2AHrKombN56Xi/WOFy9LUjrugbWQxbpaddkb7LZKzY3tma3tBFI53MW85b1HqG1ca31JnNV+Dprqpm9ZZOXUtGGjJksNfxEFKxRe6Qc7NgzaSF5ILXt3/g/pnchMCb0RjsdfIqd4lZTOaOwmm8DW1tnLepr883ZPoYanZyGQY0czgGOayCJsYc3d5AG2w33O6hWneK2udYYzhzjTl/kPL5LO5bCZS2aELpHtqxzkP7MlzGSfgh3EtDt+jm+aSZuxE4TDpaSRsTC57gxo73OOwX6uUuJeX1LqThhqfB5TUc8t7TeuMbj25OGrAyS3C+arJEZGcnIHMM4PmNaCY27jYuB6fwVC1i8TWq3cnPmLUTdpL1mOOOSY797mxtawerzWjuRamvOnDBuNF5V2BzkOEeT8m3mvdSDndIJWjmdC0fzSwOe0fyeR47i0CxFUGXe6G3gpY/4VmWqBvr2dK1j/8A7HP/AMVb666/1UU3J3zsn5fjB4mWURRc2doiIsXCIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiwsjm8diH1mX79Wk+1IIYG2JmxmV5IAY3cjmcSQNh16hBmoojU4s6Tv8AEfIaBrZiObV9Cp49YxbY3h7ISIyHcxbyf7WPpzb+d3dDtF8Xxj1FrbhjldSaS4b50ZqvbFWpgNVcuHmtN3j3mDn8zRGA9xH87s3AddkCWg7Tuochi5AWwzyyXqTiej43v5pGj/gkeRt6Guj9eyr3j3ojKa/0thcbiWz9rHn8danlrTshlggjsNdJKxziPOa0Fw23O46A9yvZ+Fk1fpTHNz1X5NyzoIp5G1JQ59KyWDm7OTYg8pLm77EOG4ILXEGI3MJqTCvLZMcM3AN+WzjntY/b0c0UjhsfR5rnevp3DaqnTTnUzt7ez5/P6vZsZRRXRo7k4KvHg8YGfB6spZHL5zM3tTVBQvZjIWmSXGwDfljiIjDGNBc47BnUnc7qXas0Fj9ZY7D0rs1mKLF5Gpk4TA5oc6WvIJIw7dp3aS0bgbHbuIW1N/IA7HTmaB/soP8Ak5PlC/8A0czXun3qur3eDsiuzHbCG3+CWDyOltUYGS3kG09RZY5m09skfaMm7SKTljPJsGbwt6EE7E9e7b21jwY0/rrL5nIZV9x8mVxEOGmjilDGMjinfPHIzZvMJBI/ffcjzW9O/eWfKF/+jma90+9PlC//AEczXun3pq93gZ9njCvYfB+xXjmWu3dR6jy2QyuGnwVu3ftxvdJWk7gGiIMYWHmLS1oG7nFwdus7iJpi/Bwgm0jp/C+URsY/5FZHbtMgbHEYTH20ryOobsCQxpJJ6D1TT5Qv/wBHM17p96fKF/8Ao5mvdPvTV7vBGdawwiqEK0/prP8ACvQWl9M6Uw2MzkePqCCzLkMo+lvIACXjlgl5i9xkcd+Xb69+nxldJ5vijjfk/V2Kr6aFOxDfx+QwGadZsw2YyeV7eesxrdgSOocCHEEKcfKF/wDo5mvdPvWqh11UsajsafiqW5c9XgFmbFsEZtRxEgCR0QfzBpJA5iNuoTV7vAz7W7O2fJE6fAKjjXZuenq3VdXJZl9aa5ko8gzxiSWHmDX7mMgbtdylm3JytaA0bL4Pg+Y2HT8eKoap1Ti2vmtWLtqnfYJsjJYIMz5+aMtcTsNi1rS3ry7blWJ8oX/6OZr3T70+UL/9HM17p96avd4GdZ4x4onT4NYHGXsdZx81/HfJ2npNNVY60/KIqr3RnnDtuftQYm7O5vWdieq1VbwedPyY3UlbM5PNannz9JmOtXsvba+w2uwuLGRljGhvK5xdvsST1JKsH5Qv/wBHM17p968beat0as1mbTubbDCx0jy2kXENA3PQHc/mCavd4JzrPGEJt8Da92vhXzav1Q/M4h83iucNuHxwRyta2SFx7Hkcw8jD1ZvuNwd00zwC0/pS7hbFO/l5fkjK28vWjtWWyjtrMLopQ5zmc7mnne/q7m5nE7kdFItJcQqmu8HDmMDjMtksZM98cdmKoQ1zmOLXgbkHcOa4H6wfUt18oX/6OZr3T701e7wRnWcccYQ7LcEdP5rE6xx9qa+6HU9+PJWXsmaySvPG2JsboXBvm8pgjcN+brv3g7KWaZwkmnMLXx8uVv5qSLm3vZN7H2JN3E+cWNa3pvsNmjoAvYXsi7cN03mi70A1g3f9ZcAs6jpzUeck5X1Rp6mT509h7JbJH+5G0uYD9bnHbpuw9Qmr1/6sI+M+Z8ETes0fqxfmDx7s/q+k1o3p4lxtWHg9DMWFsUR+vZxkPq5WfzgrPWDhsNUwFCOnSi7OJu5JJ3c9x73OPe5xPUk9Ss5K6onCmndDw712b1ecIiLNgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIvl72xtLnENaBuSTsAEH0ihOo+NehdKaJvavv6noO01RlEFnI0pDbjjkJADD2IeebdzRttv1HrWPkeLIizWjqeK0vn89j9SRNsMzVGoDSpQuAIfO8kFhIcCG8vdv6kE+RV/jctxFy2o9Y0bWBxeBwsELo8BlTc8ZktS7HaSWIAcjASDy9/Q9/etO/hXrPVvC+np/VvEfJVdQC4bNrO6RY3Gyvj3dtA3o7ZoDgObbc8oPegtZz2tLQ5wBcdmgnvO2+w/UD/cobJxj0e6hq61SzdfMHSkb5MzXxbvGZqnKHkscxm55/wUg5e/dpC/Mhwc0pl+I+D17fx8lvVuFqGlRyT7MjTFGRIHbsa4McSJZASWn6SkOI0thsBbv2sXiKGNs5CUz3JqlZkT7MhJJfI5oBe4lzjudzuT60ECvcZ8nlNAae1RovQmZ1U3MWOxFCZzMfPWjDntMsomPmt8w7evdvrW8kl4gv4qRRxwYBnDplPeWZ75vlN9kg7BoH4MMBA3369encpqiCrsXwl1Jf0nqrCaw4i5bO/Ldgvgu4yFmLsY6HcFsUL4t/QAC4jc9enVbWTgfo6/i9JUstivl46W5XYq1lZXTzwvHL55eTu53mNO53+iFPEQeEdGtFalssrxMsSgCSZrAHv2Gw3PedtgvdEQEREBERAREQEREGj1xrHG8PdH5nUuYm7DGYqrJbnd6S1o35W+txOwA9JIC/jdofwps7gvChHFzIOe+S7fc7I1Inbh1J+zHQN7twyMNDN/TGw+hf164w8KsTxt4c5fRecsXamLyfY9tNj3sZO3s5mSt5S9rmjzowDu09Ce7vXCeA8ALh3c8JvP8AD+fK6kkweMwFbLxv8agE8kr5ixzHuEG3JsO4AH60H9FcVlKmbxdPI0J2WqNyFlivPGd2yRvaHNcD6iCD+tZSifCrhxR4R8PsNpDG38hk8fio3QwWcrK2WwWF7nBrnNa0bNDuVoDRs1rR6N1LEBERBDeJPCbT3FehjKueit//AEy6zI05qNyWtJDO3cB4dG4ddnOHXfo49x6ryaNdY3iJmb1y1ibvD75P7WpSrVZTlIrLQ3du4PK9jvwh7ubflaB3kzdEEM4XcU8ZxV0hWz9KlksMyaeSq6jm6pq2YpmEh8ZYe8ggjzSR0PqO0zUQ4ncJ9McYcBBh9VY92QpV7LLkAjnkhfDOzflka5jgQRuf7yvH5N1vU4mz5A5rG2NAOx/KMOKLhdhst22cyUO2e1w5id+7ZoDepcgmqKBcNuMGP4g6UbmreLyejX+POxr6GpoW1JxYG3mNBcQ7cnZux67Hop6gIiICIiAiIgIiICIiAiIgIiICIiAiIgIi8bYY6rMJHFjCxwc4egbdSgiA4rY1/FR2go8bmZMmyp45JfbRcaETSN2tdP3Bx67D6iO9aHFav4oav0TqWeronH6M1NBZ7DCw6iv+NVbUYLd5pew2ewEc+ze/oD13Xv4NmM0zhuCemaejs/Z1RpuJk4qZa5v2tgGeQuLt2t7nlze4dGhWYgrjLaK15qSDQtibXDNOXcU9k+eqYei2Wtl3gxkxh0p54o92PHTqRId+4LZYvhLhsVxNzWumWMlNmMrVbSmr2Lr31I4gIxtHCfNaT2TST6y7+cVNUQR7RfD3TPDrCfJGmMFQwWMMvbmrRgbGx0mzRzkDvds1vnHr5o9SkKIgIiICIiAiIgIiICIiAiIgIiICIiAiIgLnbS/49+t/0Lo/vBXRK520v+Pfrf8AQuj+8FB0SiIgIiICIiAiIgi3Enhfpfi7pl+n9XYiLM4p0jZhBI5zCyRoIa9rmkOa4BxG4I7z61hnTusKvEyrkqmpKbdCtx/i0unHY8CVk7d+WWOcO367gFpGwDBsNySJqiCG8L+IFziJhLly/pPNaPt1Lb6ctHNxNY95aGntIy1xD4yHDZw6Eggb7bqZKtpcVSPhFw5Ly1ezIjS7q/kb2vmvi8a5vHuTm7wfwe/L+v0KyUBERAREQEREBERARF5WLUNSPtJ5WQx93PI4NH95TePVFqzqnCg7HL0Af7Sz4p5VYX2xQ95Z8Vpo6+WU4S2iLV+VWF9sUPeWfFPKrC+2KHvLPimjr5ZMJbRFq/KrC+2KHvLPinlVhfbFD3lnxTR18smEtouZfC08MS74MGewlGXQB1LicxUfJHkTlvFW9qxxEkPJ2D99mujdvuN+0226Lobyqwvtih7yz4qk/DA4cYLjzwQzOGr5HHyZ6kPlHEu8ZZzeMRgnsx1/2jS5nq3cD6E0dfLJhKlfBp8O6LXus9M8NNHcG6+n8bNK5u1TNfgaMG7pJpezFUDoC92245nEDcErupcJf6NHhLjtA6PymvdQT1qOezRNOnBalbHLBTY4cxLXbFpkkb3H0RMI6OXbPlVhfbFD3lnxTR18smEtoi1flVhfbFD3lnxTyqwvtih7yz4po6+WTCW0Ravyqwvtih7yz4p5VYX2xQ95Z8U0dfLJhLaItX5VYX2xQ95Z8U8qsL7Yoe8s+KaOvlkwltEWNTydPIA+K24LO3U9jIH/AORWSqTExslAiIoBERAREQEREBERAREQEREBc7aX/Hv1v+hdH94K6JXO2l/x79b/AKF0f3goOiUREBERAREQEREBERBV0uV0sPCbgxztPWjrQ6SdYbqAb9gKPjfKa30tubtPP+j3en0K0VDH2tbDjFFWbTpHh0cGZH2yR4yMl2+wZtzb8nZdfo7b+n0KZoCIiAiIgIiICIsPM5OPC4i9kJgTDUgfYeB/Na0uP+SmImqcIEZ1Zqyy25JiMO8RWmAGzecwPbXBG4a0Ho6QjY7HcNBBIO4a6G+S2NmmNi5XGUtkbOtZE+MSH09C/flH1N2A2GwGwXrp2vLBiK77JD7tgeMWpB/Lmf5zz+bmJ2HoGw9CwdZa8wWgMfFdzt8UoppRDCxsT5pZpCCeWOONrnvOwJ2aD0BK0ruzRM0W5wiOHb54PorNmizTjO9sPJ/Fn/u2p9g34J5P4v2bT+wb8FE38c9Cx6dq51+oIW4yzeOMjlMMvOLQY5/YPj5edj+Vh2a4Ak8oHVzQdHrXwitO4DhhnNX4ftc18mTtqSUnVrEEsc7i3ZkrHR88XRwdu5oB6DfqFjpLnNLea6I24rI8n8X7Np/YN+CeT+L9m0/sG/BRq/xj0nitN0M5dv2KdK/K6GrFPjrLLU72khwbWMfbHblJ+h3de4grws8dNC1NOY/Oy6hhbi79w46CYQykmyGucYXMDeZj9mO81wB32HeQC0lfNKc6jjCWeT+L9m0/sG/BPJ/F+zaf2DfgmBztTUuIr5Kj2/is4JZ4zWkrydCQd45Gte3qD3getR7WfFzSfD/JVcfncqat6xEZ2QRVprDxEDymR4jY7kZv05nbDf0ppK+aUzNMRjKQ+T+L9m0/sG/BPJ/F+zaf2Dfgozq7jRo3QuVONzWZFa6yMTSxxVppxXjO+z5nRscImnY7F5aOi89Wcb9E6HsVYsxmxX8ZrMuRyw1pp4hA4kNldJGxzWMOx2c4gdE0lfNKJqojfMJV5P4v2bT+wb8E8n8X7Np/YN+CjOpOM2j9J5eDF5DKvORsU234KtOnPakmgc4tD2CJjuYbtd3bkAbnp1XzleNei8Nqjyds5nfLtkjhkgr1Zpmwvk25GSyMYWRuO42DyD1CaSvmkzqOMJR5P4v2bT+wb8E8n8X7Np/YN+CqrTHhIYF2odSYXU+SqYy9R1FNiKgirzdn2Q5BEZpNnMY5znOALnNB26BXImkr5pKaqatzA8n8X7Np/YN+CeT+L9m0/sG/BQQccMazjPd4fy07jJoKlaZluOlZkY+WVz/MJbEWMYGtae0LuUlxbuC0hbKpxs0Xd1h5Lx5rlzRsSVGwy1Zo45Jmb88bJnMEbnjlPmtcT0KaSvmlGfRPalPk/i/ZtP7BvwTyfxfs2n9g34KqNHeEpgLeYzWH1PkquKyVbUd3DVQytO2BzI5iyESTEOjbI4DuLm7+gBSrTvEOe9r3iJickadPE6Z8TdFaO7CGS1u1kdK5zuXYHfqANh3796aS5zSRXRO5KJdK4eZzX/JtaOVpDmyxRiORpHcQ5uxH6it3gtU29MSxV8pakv4d7hG23Oeaaq4nYdo7+XH1ALz5ze9xc0lzIJpDjLo7XeV+TcLmPGLxiM8cM1aauZ4wQC+LtWNErRuPOZuOo9amM0MdmGSKVjZIpGlr2OG4cD0IK0pvVbq5xjzu4M7lq3ep+60UUU4ZZCW7pSKCeQyz4+aWi57iSXNjeQwknqSWchJPpJ7+9StK6cyqaeD5yqmaZmmRERUVEREBERAREQEREBERAXO2l/x79b/oXR/eCuiVztpf8e/W/wChdH94KDolERAREQEREBERAREQVtLiqR8IuHJeWr2ZEaXdX8je1818XjXN49yc3eD+D35f1+hWSqulyulh4TcGOdp60daHSTrDdQDfsBR8b5TW+ltzdp5/0e70+hWigIiICIiAiIgLVasxL89pbM4yMgPu0pqzSfW9haP81tUVqapoqiqN8G5UmDvDJ4ajbALe2hY8tcNi0kDcEegg9CFTfhBaXu2taaE1McfqDKYHFtu1b8WmLM8V+Dt2x9nMwQObI9oMZa5rTvs7fYq9dS4V2kblq9FGTgrMjp5SwEmpK4kvcR/4Tju4n+SS4nzTu3ximjsRMkie2SN4DmvYdw4esFLtGbVnU+zO7+vjD6SiunKLexzpNoem6vobK6c05qiubWuK1/InPmzPcLI6s8QsS9q972M25GgvI280EDovPiRoXUGfj8ICvj8RamkycWKloAxFjbrooGGQROI2e7zOXp6dgukUWOK2iiYw87sHN3EjxjWer9G67Ontb+TdWrcxlunjY7dDKU5JDE9kwhicyV8Z5Cx3LuOgOx2C9pNBUjFw6v6f03qSvBZ1s3LZFme7exbaW1LEQszGRz3MaeSLYuI23buATsui0UYp0UY4yKiPCBZdxeoa2b0ni9Ut17DjjDQyGHx/jVC20yEinb33a1nMObmdy8vNuHb9FZGd4P6G1PlZ8nl9IYTJ5GfbtbduhFJLJs0NG7i3c7AAfmAW907pnEaRxjcdhMZUxFBji9talC2KMEnckNaANyi1VM1xhLmzIaVtae1/rebVun9dZNmoJob1ObR1274tKDXjjfWlbBKxrXMcwgOk2BaR1AGyyuIml8tTs39Hw4zWJ0nBpuChpjHaedKIJJjHIyRtydrhsW7RACV4YW83eSum0TFTQxt2qA4M6fykPEDSORvYbIU2VuHFHGyz3Kj4uyssn/CQkuA2f5u/L3kbHuIKyOHGayPCfL6o05ltI6iv2sjqO3kq2VxePNitbhsyhzJHzA8sbmA8rmvI2DBtv0V7oiYt4YYS5m1PpDN2OB/HSjFhMhJfyGortmjWZUeZbLSa5ZJE3bd4Jadi3f6J27l0yihN/gfw8yt6zduaIwFq5ZkdNNPNjonPke4kuc4lu5JJJJ+tExRNO2EVyM17SPhF2MrPg8tfxOdwdPHQ3sbTfYignjszFwmLd+zbyzNdzO6bA9dwqnzFHVmdy+Bu5zFa2yGpcZrKC7eZHDKMRUostlrHV427RzDsiw8zQ+Tq8uIG66txOIpYHG18fjakNCjXYI4a1eMMjjaO4NaOgCy0Vm1j2uUMxUzd/h7xM4fR6Kz9rL6l1HlH0LUuOc2g2KW0Syy+c+axrducb9Ts0tBBBW411w71NmrvGnTNOhefY1Jh6E+MyjmEVbLq8LIpIXy77Mkc4bcrttw4nuBXS6KcTQxO+fO3+1FcKcJgM9q7FZN2muIOPzGIrSyxzasuXpK1SR7RFJFGZ5XNkcWuds5gLdm77g7K9UWLTrTawsPx+NkIqg8lzIx/Qhbvs6ONw+lKRuNh9D6Tv5LX3oom5Pd2zwTM02aZmpJeFNct05aubENvX7Fhm42JYH9m0/mIjDh9RCma8aVODHU4KlaJsFaCNsUUTBs1jWjYAfUAAvZa3Ks+uaofN11Z1U1cRERZqCIiAiIgIiICIiAiIgLnbS/49+t/0Lo/vBXRK520v+Pfrf8AQuj+8FB0SiIgIiICIiAiIgIiIIY+1rYcYoqzadI8OjgzI+2SPGRku32DNubfk7Lr9Hbf0+hTNVtLiqR8IuHJeWr2ZEaXdX8je1818XjXN49yc3eD+D35f1+hWSgIiICIiAiIgIiICid7hhp+3PJPDWmxk0hLnuxtiSs1xJ3JLGENJJ67kb/3lSxFemuqj2ZwWiqadsShJ4UUCSflfND8137l+fNRQ9r5r337lN0WmnucWmmuc0oR81FD2vmvffuT5qKHtfNe+/cpuinT3OP0NNc5pQj5qKHtfNe+/cnzUUPa+a99+5TdE09zj9DTXOaUI+aih7XzXvv3LyucLKMNSeRuXzXMxjnDe56QPzKeLGyP+r7X9U7/ACKae5x+hprnNLnrwVcfa4t8AtJ6t1BmspJmMkyw6w6vY7NhLLEsbdmgdPNY1Wv81FD2vmvffuVbeAR+KTw//qrf75OugE09zj9DTXOaUI+aih7XzXvv3J81FD2vmvffuU3RNPc4/Q01zmlCPmooe181779yfNRQ9r5r337lN0TT3OP0NNc5pQj5qKHtfNe+/cnzUUPa+a99+5TdE09zj9DTXOaUOh4U4MOBtPyGSaCD2du9I6M7etgIafzEEKWVakFGtHXrQx168TQ1kUTQ1jAO4ADoAvVFnVcrr2VSzqqqq9qcRERZqiIiAiIgIiICIiAiIgIiIC520v8Aj363/Quj+8FdErnbS/49+t/0Lo/vBQdEoiICIiAiIgIiICIiCrpcrpYeE3BjnaetHWh0k6w3UA37AUfG+U1vpbc3aef9Hu9PoVoqGPta2HGKKs2nSPDo4MyPtkjxkZLt9gzbm35Oy6/R239PoUzQEREBERAREQEREBERAREQEREBERAWNkf9X2v6p3+RWSsbI/6vtf1Tv8igojwCPxSeH/8AVW/3yddALn/wCPxSeH/9Vb/fJ10AgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAudtL/j363/AELo/vBXRK520v8Aj363/Quj+8FB0SiIgIiICIiAiIgIiIK2lxVI+EXDkvLV7MiNLur+Rva+a+Lxrm8e5ObvB/B78v6/QrJVXS5XSw8JuDHO09aOtDpJ1huoBv2Ao+N8prfS25u08/6Pd6fQrRQEREBERAREQEREBERAREQEREBERAWNkf8AV9r+qd/kVkrg/wD0o/BCTP6Ww/E3HRF9jCtGNyYHU+KvkJif+Zkr3A+vth6GoLw8Aj8Unh//AFVv98nXQC/kv/o3+Bh4kcYhq3IVy/BaT5LTXOHmy3SfwDR/w7Ok6dxYzf6S/rQgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAudtL/j363/Quj+8FdErnbS/49+t/wBC6P7wUHRKIiAiIgIiICIiAiIghj7WthxiirNp0jw6ODMj7ZI8ZGS7fYM25t+Tsuv0dt/T6FM1W0uKpHwi4cl5avZkRpd1fyN7XzXxeNc3j3Jzd4P4Pfl/X6FZKAiIgIiICIiAiIgIiICIonr/AD8+Pgp4ujIYr+SLwJmEB0ELAO0lG/pHMxo9TpGnuBV6Kc+cF6KZrqimO1+5/iDWxduSjj6suZyMZ2kiruDYoDtvtJIejT3eaOZ3UHl2O60T9bark6sx+Gr/AO46xLLt+vkb/ksSrVipV2Qws5I29w3JJJO5JJ6kk7kk9SSSVgw6ow1jPTYOLL0Jc1DH20uNZZYbMcfTz3Rg8wb1HUjbqFOlpp2UUx8/OHne9ujI7VMfq2y2/lnq78mwn7UyeWervybCftTLzX5HI2VjXscHscNw5p3BCaeeWPBpqlng9fLPV35NhP2plqtVXM9rTTOVwGWx+Ds4zJ1pKlmIum86N7S07eo7HofQeq9shl6OIFY3rtekLM7K0HjErY+1ld9GNu5HM4+ho6lZaaeeWPA1WzwV5wC4f5LweuHkGk8FHirUQnktWLtntBLZleRu93KAOjWsaNvQwencqx/LPV35NhP2pl5OcGNLnENaBuSe4I1we0OaQ5pG4I7imnnljwNUs8Hr5Z6u/JsJ+1Mnlnq78mwn7Uywb+Xo4p1Rt27XputzitXFiVrDNKQSI2bnznENcQ0ddgfUvzK5ejgqMl3JXa+PpRlofYtStijaXODW7ucQBuSAPWSAmnnljwNVs8GwGtNWt6mphX/7okmbv+vY/wCS2NDiYK8gZn8ecTGSR49FN21UfW92zXRj63N5R6XevUoRuE00T7VEfLZ58FasjtTGyMFmghwBB3B7iF+qvNDZV2EzDMBI4nH2WOkx/Mf4BzQOeBv+7y+e0fyQHjo0NAsNRXTm4Ybp3PEuW5tVTTIiIqMhERAREQEREBERAREQEREBERAXO2l/x79b/oXR/eCuiVztpf8AHv1v+hdH94KDolERAREQEREBERAREQVdLldLDwm4Mc7T1o60OknWG6gG/YCj43ymt9Lbm7Tz/o93p9CtFQx9rWw4xRVm06R4dHBmR9skeMjJdvsGbc2/J2XX6O2/p9CmaAiIgIiICIiAiIgIiICrLVj3ScSpGP8Aow4iEx7+t80vPt9nH/grNUD4j491O7jtQMH4Cu19W712DYnlpbKfqY5ux9TZHE9y3tbc6ntmPPju+bqyaqKbsTLWPaXMcGuLHEbBw7x9a5O0bnMxwi4XcTtWsyMmo83Jqq3i64tU67CZze8X7ZzmNjLubmY4sLgwcga3kC6yUGZwa04/R2pNMXI58liM/ftZG5FZkHMJZ5TK7kLQ3lDXkFp7xsOpI3XG965TNU4x3qwx1/ijagz+NzAz7MHZwltzsvmKOMrz07LWgsETa0sjXsc0vBD2bt2b5x3K12i85qfRPAXhPjMXqF9rK6t+TcfTt5GpC6PEQuqGR/IxjWdrytjIaJCSSRuTsrl0bwybpPxsWdTai1OyxAK3Z5662dkcY36Na1jASd9i527j6So9U8HPA1tHeTEua1BcxdeaGxiu3ut7XDvhLuyNWRrA5pbzbecXdAB3KWWZVvj6ojxl03qjE6Y0bSuaxfm8nNrTGeKZK3jYY3Vty4Dmji5GybO3PcPQD61NOFWf1CzXGuNIagzPlC7CeI2auTfVjryvisxyHke2MBhLXRO2IA3DuqzI+C1SWljoMnqXUWdko5etmYrOStxyP7WD6DNhGGtjO/UNaCT133WXkdKX9M6kzmqdM0Iszms4Kle5VyeRNSvHFXbKGOjcyCR3MTJsQeh7wRtsS0UzFWc1fhMVprXADXzYLclJ7cPZe58TWuLmtYS5h5gRs4AtJHUBx2IOxUd1Dk8vofhhpbHN1vmJs/k54o6clTD1LV+y3sS4wRRcjImhoHMZHjoGnc9QVNG1tTa1pZHBav0rh6eAyFSWrZfSzktqRzXtLS3kNWPbcE+dzbhakcA6PyHh6L9V6nlu4aybGNzEluE3KgMXYmJruy5DGWbghzXE7k77qCqJqnOp/pTd/VuqeIek9G1MrdlxuosVxKbiBkZ6ULZwGVZ3NkkhY50QkDZACGkt3G/UdFlcVtS6kq6M4maH1NlWailxTcNkKeXFZleWSGe6wdnKxgDA5rojsWgbg77BWh/0a9Ptxr6kec1FEXZtuohZF5rp23hA6EyiRzCfO5uctO45gNgG7tOfBwA047S+pcPkbeWzc2o+z+UstkLfNdl7Pbsdnta1rRGRu0NaAD6DuVOLPR14TH37kN4g8RdaZjinm9K6VjzdapgalWWxPgqVCzLLNOHuaJPHJmBsYawbBgJJ5t3N2G9rcMslqPLaExNrV2ObitRujc25VaW7BzXuaHbNc4DmaGu2Djtzbb9FHczwLx+UyNDK19Sajw+er0I8bYzGOuMZYyELPo+Mc0bmPdvueYNaQXHYgbAT/E45uIxdOiyaeyytCyETWpTLLIGgDme89XOO25J6kqG1FNUVTNTyvvdDmdNyx/wrMrCG+vZwcx23/kc79W6t1Utk9T4bS9mXU2ob7MZpjTJE9288OcxtiUCKKMhoJJAm5j06c0Z9O4s3H6409lMdhr1bNUX1czG2bHSOna3xthAIMYJBd0c3u9YXXXsoopnfh9fOPzePltUVXcI7G8REWLgEREBERAREQEREBERAREQEREBc7aX/AB79b/oXR/eCuiVztpf8e/W/6F0f3goOiUREBERAREQEREBERBW0uKpHwi4cl5avZkRpd1fyN7XzXxeNc3j3Jzd4P4Pfl/X6FZKq6XK6WHhNwY52nrR1odJOsN1AN+wFHxvlNb6W3N2nn/R7vT6FaKAiIgIiICIiAiIgIiIC+ZI2TRujka18bwWua4bgg94IX0iCu8rofKYR7n4ERX8fvuMbYk7OSEeqKTYgt9THbbeh2wDRqH2spD0m0zmI3jva2KOT/Fj3D/FW2i20lNW2unGeO78dHbRld2iMN6ovlC//AEczXun3rVap11X0Rp+7nM/jclicRTYH2LlqAMjjBIaNyXekkADvJIA6lW7qnVOJ0Rp3IZ7O34cXiKERms27DtmRtH+JJOwAG5JIABJUSwVHUup9cZTM289iMtwwyOKrtxGJrVRIZnPHO+eWV2/MCDs0NJa5rh0Bbu5nWuTq0165whGsVqObN4ypkKWBzU9O3E2eGUUyA9jgC12xO/UEFZXyhf8A6OZr3T71bqJnWuTqa9c4QqL5Qv8A9HM17p96fKF/+jma90+9W6iZ1rk6mvXOEOdNe8a9OcLpMazVvjmnjknPbUdfh7NspZy82zidhtzt7yO9YtfwgNH3bOJgp3H5B2WsCpSfRDbEc0x7ow+NxaHH0AkE7H1LJ8PfhJ86vg7ZuStD2uW0/wD/AFmpsPOIjB7ZvrO8RedvS5rV/KHhFpu5n9aYgN1BJovFm9DUt6pc2UQY0ycxYXvZ9FzhG/lBc0EtO7mtDnNZ1rk6mvXOEP7Gi9kXdG6bzTnegGs1u/6y4BbGjpnUOcfyzQDT1Ikh0sj2S2nD/ca3mY0/W4u2/mn0aTC8PszwD0JqbIaPval4p5Gz2NqtiNRZpkjpHjYSujnc0bGQFzyOoLgNgN1ZGC1hUybcVUvGLD6ivUGX3YGzYjNuFpA5gWg+cGuPKXDpuEz6I9miPnt/CtWW3aowjY2GOwVDFYpmOr1mNptBBjf5/OSd3F5O5c4kkknckkk7krR6m4V6S1lc07bzOAp3rGnZ22cTI9mxpSNcxwMe22w3jj6d3mjopWiymZmcZcG9CcbwmxOI4mZvXVW5lG5nL1BUsQSXXvqAARhr2wHzWvAiaNx63esqPV9DcTdJ8MMjisPr2tqjVzrgmo5fU9FrI4oN2bwyNgG7+jX+f37v+oK10UCAZLUmvsLltGUGaQqahq3Y2R5/MU8k2tHjpdm80kcMgL5YyebYA7gbb+lfuN4u17eq9WYa7pvUWGr6dgNmTNZCgY6FyIDcurybkybddwG+hT5EEG0vxv0JrHRFbWGO1PQbpqxMa8eRuvNSMy77cn4YMIdv02IU3jkZNG2SNzXxvAc1zTuCD3EFR/VnDvTGusFJhtQ4DH5jFPl7d1S3Xa+PtOvngbdHdT5w69StZk+EGm8rr7Aaxkhtw5vCVzUqOr3JY4ex2cAx8QdyOA5yRuN99vUEE1RV1jOHmqsDY15cra9vZKxm2ySYatlYGSV8LMRIW8gGxfGC+PzT6I9vStZkslxd0ZwywroMNh+Iut22yzJMr2hi67q5Mha+MvB2cB2QI27y4j0ILYRQu9xEuUuKeP0gNI52xRuVDZ8pYIA7HQPAeTFK/fdrtmN26HcvaPWVjac466G1VDquajno2QaVndXzM12GSrHTcC7cufK1rS3ZpPM0kbbHfqgnqLAw2exmo8ZVyOJyNTKY+03ngt052zRTN7t2PaSHD6wVnoCIiAiIgLnbS/49+t/0Lo/vBXRK520v+Pfrf9C6P7wUHRKIiAiIgIiICIiAiIghj7WthxiirNp0jw6ODMj7ZI8ZGS7fYM25t+Tsuv0dt/T6FM1W0uKpHwi4cl5avZkRpd1fyN7XzXxeNc3j3Jzd4P4Pfl/X6FZKAiIgIiICIiAiIgIiICIiAsPMZihp7F2sllLtfHY6qwyz27crYoomDvc5ziAB9ZWYqsyen7/GHM6w0rr3Q9L5vq0tQ4yexb55clKwiV8hYw+bGHcgAJBOzgQQ4hoe7cFqPX+sdV47WOI05kuFsteq3E1Ht8aluSDaR80nN5oaDsA3Y9WNIPeXWUxjY2NYxoaxo2DWjYAepfMEEdWCOGGNkUMbQxkbGhrWtA2AAHcAF6ICIiAiIg+JYmTRvjkY2SN4LXMcNw4HvBCrvR3g96D0RwyvcP6OBrz6VuzWZrNK20SdsZpC/Z7tg55YORjHuJeGxRjmJburHRBylVyeo/AoyMNDMTXdU8DJ5BFVyjgZrumC47Njm26yVtyAHd7eg79mvv4aM0XrbUOntfR43G5bL065OLz0Ia94hka4eZI36TC17tt9wOYkbElSi9RrZOlPTuV4rdSxG6KaCdgfHIxw2c1zT0IIJBBXJGsJ7PgGZOLNYm43JcG8rc5LOmLFpouYeZ7uslDnO8se53dF1I7+4lwC3ncQc9wM0Hkczxcy1fNVo8t4vXyensTN+DqSEcklmNvNycp5g4t3AAaN3Od1t2GVs8TJGblj2hw3BB2P1HuWv05qLG6x09j81ibLb2KyMDbFecNIEkbhuDsQCOh7iNx6VGJ+G3iHErIa9o5bMz35sWaLsBJkC3GzPad4n8hB5HjzhzDcfhCdt99wnSKvdG8U5pNJYS5xBx1fh3n8lbfj2YrIZCJ4lnaXACJ4IDw8MLmjvI279wTYSAiIgIiICIiAsPLYbH57H2aGTo1sjRtM7KerbhbLFKz+a9rgQ4fUVmIgrzVnAHQuscNpzFXMGyrQ07ZFvFQY2V9RlSQH+S2Mtbt3jYgjqeiz4+HlyLinLq8auzrqUlTxZ2mnzg45rgABK1m24d0O53O5KmiIKuoY7ivpTQeojNl8NrzVYsdpiBNU+TYTCXN3jl5C7qBz7Eepu/pWRk+IurtO1dBx3dAXcpkM26OHMHDWGSwYWR3Zgl7nbF7AXu84eiNx9SslEEKxnF/TWW4n5jh/BYsjUuKqtu2IpKkjYTCRGeZsxbyO27ZgI333J6dCtpoviHpniLhTl9MZ2hncYJfF3WqM7ZGNl2aeRxHc7ZzfNPXzh61IHND2lrgHNI2IPcVC9Q8FtDao0VkNIXtMY9mm8hKJ7WOpR+KRyyAtIeex5Tzbsb13380epBNVztpf8e/W/wChdH94KsfJ8GqlrMaKuY7Umo8BU0rG2CDE4zIGOnchaGgR2WEEygBjR1d6/WqP4fTZK14cvFufHZ+jqGSLS8UUEfI1sVObtW9nWldGSfNcHFxPnef3dAg6yRVQNa8UdL8MIsrndC0tTawbc7KfEaXvCOLxfc/hmOn6k7AeZ39R9a3uT4vYrCa703pC/QysOYztft67o6TpK0ZAcXRyTN81rgGO6H6vWEE6RY1HJVMmyV9O1BbZFK+CR0EgeGSMcWvYdj0c0ggjvBGxWSgIiICIiAiIgq6XK6WHhNwY52nrR1odJOsN1AN+wFHxvlNb6W3N2nn/AEe70+hWioY+1rYcYoqzadI8OjgzI+2SPGRku32DNubfk7Lr9Hbf0+hTNAREQEREBERAREQEREBERAVX8Eqem9JTat0XhtT3dQ5LE5N13IwZBznS0Db3ljiDi0bs5QSOrj37nuClfEjXMPDTQ2Y1RZxeSzFXFw+MTU8REyWy6MEB7mte5oIa0l53cPNa7vPQ/wA7dW/6TeOhn83luH3DDE4nMZOywW83m5nTzXq0TXMhEsUQjLXhvJ/tXtb5zRzb8wD+m6KufB213qDidwW0rqvVFSlRzWXrOtSwY5j2QNY6R/ZFoe5zusfZk7uPUn0KxkBERARF427cFCrLZtTR1q0LDJJNM8NYxoG5JJ6AAekoPZazUepcTpDDWctnMlUxGMrN5prd2ZsUTB9bnEBc+6o8L6TVucs6W4Iabl4lahiPJPlQTFhqJP8AKknOwf69mkB38lxPRfOm/BFua4zNbU/HTU0nEPNRO7Svgot4cLRPqZCNu027uZwHMPpNd3oMS74Tes+NtybD8BdLm9Ra8xT671FG6vjID3EwsI5pnD83Q97CDupFw88EDB4zPx6u4i5a1xS1ydnfKWcaDVqnfflr1urGNB7t99j1by9yvmjRrYynDUp14qlSBgjiggYGMjaOga1o6AD1Be6D8A2Gw6BfqIg0OrtB6d17Uq1tR4SjmoKs7LUDLsDZOylaQWvbv3Hp6O8bg7gkKPPxGsNNav1ZqaTUM2o9NSY/tKGkYaMTJobMbB0in33d2nKRyu2HM/0AKfogiXD7iJX11pHEZqxjMhpefIufEzFZ2IV7bZWFwezkJ3J8xxG3e0b7bKWqKa84V6V4muwztTYeHKvw9xl+g+RzmugmY4ODgWkbjdo3adwdtiCtJLc1zo7UWt89m7dPPaGgpeOYrF4nHyHKRyMZ58IAJEvNykj0lz9vNA2QWMijfDvXuM4m6NxepsQy3DQyEbnxxX67oJ2cri1zXMd1BDmkdNwe8EggqKcH/CN0Txxy2qMbpjIGe7p+7JUnjkMZFhjXFrbMDmPc2SB5B5XA7924HM3cLPREQEREBERAREQFq9TaoxGjMFczWdyNbE4qoztJ7duQRxxj6yfSTsAO8kgDqoFxl8ITT3B/xXGuisaj1jkfNxelsS3tbttx32PKN+zZ0O73dNgduYjZQLTPg/6j4u5yprDjpPBkHwPE2L0HSfzYrGH0On9FmbboSd2jzgOYEABrZNYa/wDCykdV0TLe4dcKXOLZ9VzRmPKZlnpFJh6wxn/xXdeo27nMV48MOE+luDmmIsDpPFRYyi088jh50tiT0ySvPV7z6z+YbAAKWsY2JjWMaGMaNmtaNgB6gvpAREQVFneGN3hTpbVeR4M6fw8Oq8xkI8nZp5KaRla04Edo1oB2Y5zQ4D6LQ55JIU1xfEbA3dWSaQly+PZrKtSiu28NFY55I2PHe3cAuAI9W4BaSBzDeULQ5jR9G9kLGap1qdHVRoS0K2dNRks9dj9iBudi5oeGu5Cdjt9ZQb5FUGK4iXOC+C0Jp3ilnHZzU2duvxcGZxuMkFeaXm/AiXlBDHvaWDuALubYbNc5ayv4W2kbnhLHhBWlgs2m03F2Vhsc0bMg1zi+iW8m3M2NvMXB52dvGQHAgBeSIiAiLjjw2vC94g+DTrnAY/TuH0/dwmUxpnE+VrzyS+MNle2RoLJmDlDTEdtid3Hr3IL84f0sTnOJ+udWYnWNrOxmSLB2cM2Q+K4uzWBErA3u7QlzSTtuPWQellrh7wW/Do0lrLWj9G4nhTktN39QZPxsDCWWXopJ5SfGLNgvERja0Na4lofuA7oNgHdwoCIiAiIgIiiGrtXT1LYxOJDDkC0PnsyDmjqMPd0/lSO/kt7gAXO6crX3ppmqV6KKrlWbTvSuexFVjMk0rImDvdI4NH95Wv8AKnCj/veh7yz4qsH6ao25u3yMZzFsjY2cjtM89d+gI5Wj6mgD6l7eT+LH/dtP7BnwVsbMdsy9KMgnDbUsnyqwvtih7yz4p5VYX2xQ95Z8VW3k/i/ZtP7BvwTyfxfs2n9g34Kc6z39FtQ95ZPlVhfbFD3lnxTyqwvtih7yz4qtvJ/F+zaf2Dfgnk/i/ZtP7BvwTOs9/Q1D3lkHVGEcCDl8eQehBss+K/l34aXgh19I63raj4ctrX9O564yCTF0pQ84+1I7YANbuRC8noe5pPL0HLv355P4v2bT+wb8E8n8X7Np/YN+CZ1nv6Goe8mekp9OaP0rhsDTy9AVMXShowgWWDzI2BjfT6mhbbyqwvtih7yz4qtvJ/F+zaf2Dfgnk/i/ZtP7BvwTOs9/Q1D3lk+VWF9sUPeWfFPKrC+2KHvLPiq28n8X7Np/YN+CeT+L9m0/sG/BM6z39DUPeaLjB4XGD0BljprS+Iva+1pIAGY3GN5a8JcAQ6eyRyMbsQTtzEenlB3Vf0+CuouO9mHK8edfUfkrmEsOgdNXhBQj9IFiUO5pXD6idj3P26K3fJ/F+zaf2Dfgnk/i/ZtP7BvwTOs9/Q1D3kz0szReiMJXw+n34XDYuuNoqlKSKKNvrOwPefST1PpW4i1JiJ3hseUpSOPobYYT/mq08n8X7Np/YN+C+X6cxMrS1+LpPae8OrsI/wAlGdZ7+hqHvLeB3G46hfqqGhjptOPEuAsOxhaSTTHnVJf910fc387OU/WR0NjaY1JDqWg6VsTqtqF3Z2KshBdE/wBW/pBGxDvSCO47gJpiYzqJxjq4r2T12ds7YbhERZOUREQEREHI/wDpItS4TR/CXD5V1+9Q11Hf7PTc+NyD600D3AGxMWskaXMbE3l5gHcr5Ih0Dzv/ADV4F8Wc7wS4mYjVmAD5rFR/LPUBPLaru2EkTtt+jh6djsQ1w6gL+2WrdW2ILb8RiHNbea1rrNuRnOys13cAN9nSkdQD0aCHO3Ba18LdpXG2JzZvwDLXHDZ1rI/h5D136F3Ro39DQAPQFrm00xjcn5Q7bOS13Yzp2QmuiuK+mNeaTxWocdla0dPIwNnZHZlbHLHv3se0nzXNO7SPWCt35VYX2xQ95Z8VW3k/i/ZtT7BvwTyfxfs2n9g34JnWe/o6tQ95ZPlVhfbFD3lnxTyqwvtih7yz4qtvJ/F+zaf2Dfgnk/i/ZtP7BvwU51nv6Goe8snyqwvtih7yz4p5VYX2xQ95Z8VW3k/i/ZtP7BvwTyfxfs2n9g34JnWe/oah7yyfKrC+2KHvLPiqA154RWd19qW1ojhCKkViBxhyeuMyAzG470OEDXbeMyj0AbtB233BJE28n8X7Np/YN+CeT+L9m0/sG/BM6z39DUPeffA7ghpHhcLeQo5A6q1hkBz5XVGQnFi9ccdt/O3PJHuBsxvTYN33I3VtKnLGk8LZIc/F1O0ad2ysha17D62uABB+sFbjDalu6Ska27asZLCE7GSc9pPTH84vPWSMeku3cO/cjoEU0V7KJ28J/v8A+MbmRV0RjTOKy0X41we0OaQ5pG4I7iv1YvOEREBERBU/hO6y1VovhFlbOhsezI6vnLIce14hcK5LhzWOSR7ecsbuWgB+zywuYWB5H8aqujtecPM9TyzNP5rEZHGWGWoLD6UjTHIxwc14JbsdiAd+oX9pOJVOC7rTTMdiCOxGKV8hsrA4b89XrsVgeT2L9m0/sGfBUvXrVjNiuJmZjHs4zH2ePlXpKnJbmjmnH5s/gxxrxPFThfp3VM89fFW8hWDrNKxKI3QztJZK0B2x5Q9rtie8bH0qa+VWF9sUPeWfFV35PYv2bT+wZ8E8nsX7Np/YM+C59dscs9HH67o/xz4/hYnlVhfbFD3lnxXG3+k00fDxC4Z6UyuBMeZy2Ky3iwr0XCWQQ2G8pOzdzt2kcLf/ADBdC+T2L9m0/sGfBPJ7F+zaf2DPgmu2OWeh67o/xz4/hWXgXeD3prwddFm/lcpjLGucvE12QseNRu8VZ0IrRkHuB2LiPpOHpDW7dI+VWF9sUPeWfFV35PYv2bT+wZ8E8nsX7Np/YM+Ca7Y5Z6Hruj/HPj+FieVWF9sUPeWfFPKrC+2KHvLPiq78nsX7Np/YM+C0mucFjYtFagezH1WPbj7DmubA0EERu2IOy1tZVYu3KaMJ2zEdnavR6ZorqinMnb3/AIXn3oviH+CZ/wAIRbPoX5YnZVryzSHaONpe4/UBuVUOmnyW8VHkZ9jbyR8dncN+rngEDr6Gt5Wj6mhWzkqgyGOtVSdhPE6Pf1bgj/8AKqXSsjn6bxoe1zJY4GwyMcNi17ByvB/M5pC1/wBmcOMfd6mQRGdVPahPHji+3hFpmlPBB2+VydyKjTElWxPAxz5Gtc+TsWlxDQ7cMGznkbN3Pdk2+MOD0XicMzVuahOYu1BaMeNxtol0Z/2vYASSRM9G8ncQRvuCBi8d8RezGM0YyhSsXXV9XYizM2tE6QxxMstc+R2wOzWjqXHoB3qvtfaXnwPG7UGfzOL1pksHm8fTjp2tG2rjXV5YBI18M0daRrtnc4e1zgWgl3Ublcz0a6q6apmO5NtU+ETp7Tmq9G42ET5TGaiqT3m5PHVbFtrY2BvZ8ghif2nMSd9juwNBcAHAqQan416M0dnnYXKZns8mxrHywV6s1g12u+iZTExwiB7wXlvTqq1ymnY+G2T4RZnCaVz79NYmDJR2aEEMl69TdcYyRvaMDnvd54eHEFwaSOuy99JZ/IcKNW67iyejtSZfygzBzOPyOIxrrLZoZIYmtgkcD+CfGWObtIWjY7gqEZ9cThPnY21fwj8FhNca0wWq8jVxUeIyUNSo+OtM7aJ9eF/aWHgObGC+RzQ53I3pt3glXICCAQdwVz5m9K5azpjwkYhh7skuWbMcewVXl1w/JUTG9iNvwnngtHLv5wI71dukIpoNJ4WOwx8c7KUDZGSAhzXCNu4IPUHdF7c1TMxPnaheY44Y3B8ZKug7NO7zT49toXIaVmYdq+ZkbI/MiLQzZxJlLuVp6EgrZWONmi6esG6XnzXYZl1htNsclWZsRncN2xdsWdnzncbN5tzv3KL6xmvaR4+4fU0mDy2Vw1vT0uIM+IpvtGCx4zHK3tGs3LWlu/nHpuFU/E6jqzUMuoRlcVrbJ5yjqWG1RrY+GYYmLGQ245I5GNZsyeQxNJI8+XnPQABSzquVU4/FaWI8JPAY/VGrsPq7JVcO/GZ04ynI2rP2XYmKFzHTy7OjY4ve8buLAeUdOhKluH15bvcWNV6anbVjxeJxlG9FOARIXTOnD+dxdy8oETdtgNtzuT6KazE+XxuL4z6WOh9Q5e7qvK2zi3w45zqcrZakMDXvmOzY2tewklxHQbjdZV3htqSpldXaXbWuSy6g0DUw9TORRl1UW68ViN7ZZO+MuMjSCR1BO3UbIiK6/PzW5pjjbonWWbixGIzjLN6cPdXa+vLEy0GjdxgkewMmAHXeMu6de5Tdzgxpcd9gNzsN1zrwh0xhsrktKw5PSvEGhncJEJyc9duyY2lZZH2Z7IyTGJ4Ic8NMYI5T127l0Wob26qqoxqVfwr4+4XiVjM5cfFYw7MVYtiV9yrYhhbXhlcwSumljYwEhvM5m/MzqHDoVu9H8Z9G67t2K2GzTZp4K/jjmWK8tYug327Znasbzx77ee3dvUdeqpd+l8/mOFXFPhqzBZWrnbN/K36dqaq5lG7FJa7eNjLH0CZGu5eXfcedvtsvviBic5x/ylOPBaZzOlosbpvL05rGbpOpAz2q7Yoq0fN9Noc3mc5u7AGjY9VLGLlcRHbPn6Lg0txu0ZrfJPx2CzbLl4wvnhY+vNC2wxvRz4XvY1szQSNzGXBR/R/H3FDhPovVGsbcGNyOoaolZVx9WeYyPA5niOJgkk5WjqT1A9JURxBy3EHUnCqnV0hmtNN0myWbJ2cpSNaGD/qbq4rwuPSYOc4dWbt5Wg7+hRvD4ibF8E9A1Mnp3W+G1lpdtijUyOCxbrEtSdrAHEs85ssEoLRvsWu5TuW7bojSVb/PZ+XUeLyVbNYypkKUonp24WTwygEc7HNDmnY9RuCO9e+EtnEa6xUjNmsyjX0Jh185zGPmiP8A5QyUf/yLQ8PLmdyGhMBZ1PWZT1DNRhffrxjYRzlg5xsCduu/TfotzVruv610zAwE9hPNek2HQMZC+Pv9HnzR/wCK3se3Md0/SVr+E2ZmeC1URFR82IiICx8jdjxmPs3Jt+yrxOlft37NBJ/yWQsDUGNOYwOSoAhptVpIAT6OZpb/APlWpwmqM7cmFW6bZKcRDZskOu3P+t2XjfzpZPOd3+gb7D1AAdANlHNda3vaY1joHE1Yq8lbP5KanadM1xexjKsswLCHAA80bR1B6E9PSpLpy147gMdMWuY50DOZjhs5rgAHNI9YII/Uq9400shDqXhtn6mKu5aph84+S7FjoTNNHHLVmhEnIOpa1z277dQOvoUXsZuVZ2/GX08/pojN7m5z3HHQ+mM9Lh8nno612B7I7DuwlfBWc7blbNM1hjiJ3B2e4HYg+lfWpONuitIaibg8xmvEb/NG13PVmMMZk25A+YMMbN9xtzOHeqKo8P4MXmdY6a1hpzX+W+WM5bswzYG7d+S71SzJzAyiOVsUZaHFr2vA6N6c268eOOntT6hqcQ9OTYzWWQ5akdfTFDDCVuMfWbAwl80jSGySc4k3ZKSTytDGkkLLBjN2uImcHRzuI+nI6+qJpMk2KPTJcMuZYpGGrtEJdyC3dw5CHAt3B9BJWoz/ABz0Tpg025LMuhfaqMvNjZSsSvigeN2yTNZGTC09esgb3H1FVzxD4a5nVuudPz4yrMzTOsKlWvqls0bo3xsquFiLnaRuHSNMldwOxAIBWo1RpaTTPF/XGQz2G13lMZnjVs421o63cbG7kgbE+vOyvIwMcCzdrn+aQ4+cNkWquVxujz5w+bpKhfrZSjXuU547VSxG2WGeFwcyRjhu1zSOhBBBBUW1Zxc0nofOVcPmcqa+TsRCdteKtNO5sZdyCR/ZscI2FwI5n7DcHr0W20Vp3H6S0liMPiqktDG06zIoKs7y98LNujHEkkkd3eVTvHoZLD6uhzejMTqca9bQigrW8bQ8Yxd+PtnHxW2T5rA3dzuc8haH7hx7lDSuqaacUtx3GatRzOu49STV6GOwmarYmi6vBLJNYdNXhe1nI3mdJIXykAMb3Du6ErUa34328JQ4q2MPNjbc2kMbDYjp2adqOVk7hKT2pcGMkjd2Y5TE49ztz3KvMpw61Rj+KWteJFalkrs2Cz9e7UwHixdDkK7qEUVqSvu3eSYNJDHN7nRFo6vK32vtG5zV1zjs3HYq475b0vjIsc6aB8QsyNjtl0bS8Ac45mgt72lwB23Usc+uYmPj91nwa9yEvF/H6UMNb5OsabkzD5Q13aiZtiKMNB5tuTZ56bb77dfQp25oe0tcA5pGxB7iqWw82St8ZdFaoOnsxXxWT0tPinunpuY+jYE0cwbZb3xgtjcA49Cdh6VdShvRMzji3vC266TT1jHPdzHE230Wnr0jAbJEOvqjkjH6lMVCOFdd3iOcvkHs72UkfHuNt2xxxwb/AJuaFx3+tTddl/8Acnj2/HDb1fN3YiLlURxERFgyEREFecQP48aZ/sN//wBdVeS9eIH8eNM/2G//AOuqvJeZ6Q9qj/j/AO1T4r0v/J+UCwc3nMfprEW8plbkNDHVIzLPZneGsjaPSSs5Vb4SWkMtrThbYqYaCe9bq3amQdQrTmCW3HDOyR8TJAQWvIaS0gg8wGxBXmUxEzES8i3TFVcU1ThEtjR4+6Dv4vL5Bmd7Gvia4t3G2qdiCWKEnYS9lJG17mb9OZrSPrWz0rxY0prXKW8diMr29ytALT4pa8sHPATsJozI1okj36c7OZvUdeoXP+tNG4vV3DLX+QwGluIT9RNwL6Fd+qH35pZWyva58EMU8j3OIMTCeVu3dsT1U44w6HzmrNfiviK1iE3NC5nFtyDY3NhinldXETHyAbNJIJA332BI7ltNFDtmzZ3YzG/fhswiJ87mwf4SOCz3EXRWnNJ5CtlocvftVrkzqs4b2cVaWTnrykNZJ57GguaXjY+jcFXMuadP5XI6k1FwSx0ehtSYDybmliyPjmLfFVqFuOmiAbL9FzC7YNcOh3HUEgLpZUuUxThEMMoopommKY7PvItFrz+I2ov+XWf/AGnLerRa8/iNqL/l1n/2nLXJf5Fv/lH1Z2P3afjH1XFD/BM/4QiQ/wAEz/hCL3n6U+1XWqsDLpzI2crUgdNirbzLcjiG760pABlDfTG7bzturXedsQ5xZYqK9NWbjE7YlrauVWqs6lVtazDcgZPXlZPDIOZkkbg5rh6wR0K9FJsnw3wOTsyWRWlo2ZDu+XH2JK5ed9yXBhAcd/SQSsD5qKHtfNe+/craO1O6rD4w9aMuow2xLUItv81FD2vmvffuT5qKHtfNe+/cmit8/SVtet8JahQzLcF9A57JWMhktGYK/fsPMk1mxj4nySOPpc4t3JVlfNRQ9r5r337k+aih7XzXvv3JorfP0lWcttTvhGcFgcbpjFQYzEUK2Mx0G/ZVKkQjij3cXHZo6Dckn85Kz1t/mooe181779yfNRQ9r5r337k0Vvn6SnXrcdktQi2/zUUPa+a99+5Pmooe181779yaK3z9JTr1vhLQZHHVcvj7NG9Xit0rMboZ68zA9krHDZzXA9CCCQQVDq3AnhzSsxWK+hdPQzxPEkckeNhDmOB3BB5ehBVofNRQ9r5r337k+aih7XzXvv3JorfP0lWcstTvhqEW3+aih7XzXvv3J81FD2vmvffuTRW+fpK2vW+EtQi2/wA1FD2vmvffuX6OFGNPR+UzUjfUb7m/4t2P+KaK3z9Ea9b4Sjt/J18d2TZX808zuSCuwc0szu/lY3vcfzd3eeil2idMTYrxjJ5FrG5W41rHRsdzNrxNJLYwfSfOJcR3k+kNC2OA0fh9Mukfj6TYp5ByyWZHulmePU6R5LiPqJW5TGmiJpo7e1w38qm9GbEYQIiLJwiIiAiIgrfU+Dk0tftZGvE6TC2pDNO2Jpc6pM4kvkIH+zceriPouLnHdriWY0E8VqFksMjJYnjma9jg5rh6wR3q0VFchwzwF6xJYjrS46eQkvkx1h9fnJO5JawhpO/pI3/vK2nMuba5wnjvxelYyzMjNrjFG0W4PCigST8r5of/AN37l+fNRQ9r5r337lGit8/R169b4S1CLb/NRQ9r5r337k+aih7XzXvv3JorfP0k163wlXOd4P6G1PlZ8nl9IYTJ5GfbtbduhFJLJs0NG7i3c7AAfmAW907pnEaRxjcdhMZUxFBji9talC2KMEnckNaANypT81FD2vmvffuT5qKHtfNe+/cmit8/SVYyy1E4xDUItv8ANRQ9r5r337k+aih7XzXvv3JorfP0lbXrfCWoWLWbPqW7JjcTI0vY7kt3G9WVB6Rv3GXY9GejoTsO+Sx8KMIXA25clkG/+HZvy9mfzsa4Bw+oghSyjQrYypFVp14qlWIcscMDAxjB6g0dApiLdG2Jxn4bPz0YXMuxjC3D4xeMrYXG1aFSPsqtaNsUbN99mgbDr6fzrKRFlMzM4y8kREUAiIgrziB/HjTP9hv/APrqqN6r0BprXTazdR4DG5wVS4wDIVWTdlzbc3LzA7b8rd9vUFY+p9FUtVWqVmxYuVp6jZGRyVJuzPK8sLgenX+Db/ctT81VH2xm/ffuWV/J4vzTVFeExGG6eMz93hZZ6PuZRe0tFURs71XjgDw0DCwaC04GEglvyZDsSN9j9H6z/etvpfhfpDRF6S7p/TGJwlySMwvnoU44XuYSCWktAJG7QdvqCnPzVUfbGb99+5Pmqo+2M3779y5tRx33ekuKfROUTGE3I6tai2XzVUfbGb99+5Pmqo+2M3779yr6vj/JHhLP1Ld546tNdpV8lSsVLcMdmrYjdFLDK0OZIxw2c1wPQggkEKEM4A8NI3tezQOnGvadw5uMhBB9f0VaHzVUfbGb99+5Pmqo+2M3779ymMgw3Xekr0+iL9Ps3IjxVb/0fuGX9ANN/wD+XD/+qkevOmhtRf8ALbH/ALTlL/mqo+2M3779y8rfB/F36k1axlMzLXmY6OSN13o5pGxB6ekFbWskii7TXVcxwmJ3SvT6Jv59NVdyJwnvTiH+CZ/whF9NaGtAHcBsi6X1D9REQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQf/9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from find_keywords import LabellerByRulesWithPos\n",
    "from pipeline import NL2SQLPineline\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QAVectorDBSearchEngine\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing import Callable\n",
    "from typing import Literal\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "#%%\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "#%%\n",
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pipeline_config = {\n",
    "    \"router\": router_config,\n",
    "    \"recall\": recall_config,\n",
    "    \"nl2sql\": nl2sql_config,\n",
    "}\n",
    "\n",
    "nl2sql_pipeline = NL2SQLPineline(pipeline_config)\n",
    "#%%\n",
    "@tool\n",
    "def fetch_table(request: str) -> str:\n",
    "    \"\"\"Consult a table about robot model parameters according to the query,\n",
    "    and return the results.\"\"\"\n",
    "    results = nl2sql_pipeline.run(request)\n",
    "    return results\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"fetch_table\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example 1\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to get more information about robot model names.\",\n",
    "            },\n",
    "        }\n",
    "    cancel: bool = Field(description=\"If the current task should be canceled.\")\n",
    "    reason: str = Field(description=\"reason for cancelling or not\")\n",
    "#%%\n",
    "# Table Searching Assistant\n",
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for searching table about robot model parameters.\"\n",
    "            \"The primary assistant delegates work to you whenever the user needs to know parameters about robot models.\"\n",
    "            \"The query must have robot model names such as A10, G20, H1 and so on to complete the search, and\"\n",
    "            ' if it does not have that information, use the tool \"CompleteOrEscalate\" to escalate the task back to the main assistant, '\n",
    "            \" but remember to set cancel = False.\"\n",
    "            'If you have successfully used the \"fetch_table\" tool, please use \"CompleteOrEscalate\" tool to escalate the task back to the main assistant.'\n",
    "            \"\\n\\nIf none of your tools are appropriate, then use the tool \"\n",
    "            ' \"CompleteOrEscalate\" to send the dialog back to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"directly use the user query as input to your tools, and don't make any translations or rephrases.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "     [CompleteOrEscalate, fetch_table]\n",
    ")\n",
    "#%%\n",
    "# Primary Assistant\n",
    "class ToTableSearchingAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to search table for robot model parameters.\"\"\"\n",
    "    request: str = Field(\n",
    "        description=\"directly use the user query as input to the specialized assistant, and don't make any translations or rephrases.\"\n",
    "    )\n",
    "llm_p = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for home cleaning robot. \"\n",
    "            \"Your primary role is to answer customer queries about the home cleaning robot. \"\n",
    "            \"If a customer requests you to answer some questions outof the scope just reject to answer.\"\n",
    "            \"If a customer requests to know some parameter of a robot, \"\n",
    "            \"delegate the task to the appropriate specialized assistant by invoking the corresponding tool. You are not able to make these types of changes yourself.\"\n",
    "            \" Only the specialized assistants are given permission to do this for the user.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "assistant_runnable = primary_assistant_prompt | llm_p.bind_tools(\n",
    "    [\n",
    "        ToTableSearchingAssistant\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        request = state[\"messages\"][-1].tool_calls[0][\"args\"][\"request\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user.\"\n",
    "                    f\" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},\"\n",
    "                    \" and the task is not complete until after you have successfully invoked the appropriate tool.\"       \n",
    "                    \" If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \"If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \" Do not mention who you are - just act as the proxy for the assistant.\"\n",
    "                    \"Directly use the request below as input to your tools and don't translate into English or rephase.\"\n",
    "                    f\"\\n\\nrequest: {request}\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": new_dialog_state,\n",
    "        }\n",
    "    return entry_node\n",
    "#%%\n",
    "builder = StateGraph(State)\n",
    "#%%\n",
    "# fetch table assistant\n",
    "builder.add_node(\n",
    "    \"enter_search_table\",\n",
    "    create_entry_node(\"Assistant of Searching Robot Model Parameters\", \"fetch_table\"),\n",
    ")\n",
    "builder.add_node(\"fetch_table\", Assistant(table_searching_runnable))\n",
    "builder.add_edge(\"enter_search_table\", \"fetch_table\")\n",
    "builder.add_node(\n",
    "    \"fetch_table_tools\",\n",
    "    create_tool_node_with_fallback([fetch_table]),\n",
    ")\n",
    "\n",
    "\n",
    "def route_fetch_table(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"fetch_table_tools\",\n",
    "    \"leave_skill\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    return \"fetch_table_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"fetch_table_tools\", \"fetch_table\")\n",
    "builder.add_conditional_edges(\"fetch_table\", route_fetch_table)\n",
    "#%%\n",
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_skill\", \"primary_assistant\")\n",
    "#%%\n",
    "# Primary assistant\n",
    "builder.add_node(\"primary_assistant\", Assistant(assistant_runnable))\n",
    "builder.set_entry_point(\"primary_assistant\")\n",
    "\n",
    "def route_primary_assistant(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"enter_search_table\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == ToTableSearchingAssistant.__name__:\n",
    "            return \"enter_search_table\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "\n",
    "# The assistant can route to one of the delegated assistants,\n",
    "# directly use a tool, or directly respond to the user\n",
    "builder.add_conditional_edges(\n",
    "    \"primary_assistant\",\n",
    "    route_primary_assistant,\n",
    "    {\n",
    "        \"enter_search_table\": \"enter_search_table\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "# # Each delegated workflow can directly respond to the user\n",
    "# # When the user responds, we want to return to the currently active workflow\n",
    "# def route_to_workflow(\n",
    "#     state: State,\n",
    "# ) -> Literal[\n",
    "#     \"fetch_table\",\n",
    "# ]:\n",
    "#     \"\"\"If we are in a delegated state, route directly to the appropriate assistant.\"\"\"\n",
    "#     dialog_state = state.get(\"dialog_state\")\n",
    "#     if not dialog_state:\n",
    "#         return \"primary_assistant\"\n",
    "#     return dialog_state[-1]\n",
    "\n",
    "\n",
    "# builder.add_conditional_edges(\"primary_assistant\", route_to_workflow)\n",
    "#%%\n",
    "# Compile graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    ")\n",
    "#%%\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_4_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385835f-bdc9-41a6-a978-62849ef571dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "61ec8c4b-2cda-4d09-b1ed-027de3deaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight informatio\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": \"198197a5-c74c-463d-8312-ded3f1d94479\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4b5bb21-320c-426f-9ca4-86b6e10bc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "_printed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "edb5abea-4df8-403a-a45e-255f3b0ec07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"G20电源线多长\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f077750-d665-46cd-93ca-7c6590e32d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'primary_assistant': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YQxnkj5JDjLYS1SVZWWErLTq', 'function': {'arguments': '{\\n  \"request\": \"G20电源线多长\"\\n}', 'name': 'ToTableSearchingAssistant'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 239, 'total_tokens': 261}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-22cafa32-1740-41fa-a87e-ba77a555167f-0', tool_calls=[{'name': 'ToTableSearchingAssistant', 'args': {'request': 'G20电源线多长'}, 'id': 'call_YQxnkj5JDjLYS1SVZWWErLTq'}], usage_metadata={'input_tokens': 239, 'output_tokens': 22, 'total_tokens': 261})}},\n",
       " {'enter_search_table': {'messages': [ToolMessage(content=\"The assistant is now the Assistant of Searching Robot Model Parameters. Reflect on the above conversation between the host assistant and the user. The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are Assistant of Searching Robot Model Parameters, and the task is not complete until after you have successfully invoked the appropriate tool. If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control. Do not mention who you are - just act as the proxy for the assistant.Directly use the request below as input to your tools and don't translate into English or rephase.\\n\\nrequest: G20电源线多长\", id='c6c134f6-6e0b-46d7-a106-c8b590b4c7a4', tool_call_id='call_YQxnkj5JDjLYS1SVZWWErLTq')],\n",
       "   'dialog_state': 'fetch_table'}},\n",
       " {'fetch_table': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5jz3fDBEp6t3LKU6ttuI1BQT', 'function': {'arguments': '{\\n  \"request\": \"G20电源线多长\"\\n}', 'name': 'fetch_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 538, 'total_tokens': 559}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-45104220-55d6-4c22-b73b-af1f22cd22b0-0', tool_calls=[{'name': 'fetch_table', 'args': {'request': 'G20电源线多长'}, 'id': 'call_5jz3fDBEp6t3LKU6ttuI1BQT'}], usage_metadata={'input_tokens': 538, 'output_tokens': 21, 'total_tokens': 559})}},\n",
       " {'fetch_table_tools': {'messages': [ToolMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', name='fetch_table', id='a1f6d800-7cae-4ab7-82d5-6d36dca0e2ac', tool_call_id='call_5jz3fDBEp6t3LKU6ttuI1BQT')]}},\n",
       " {'fetch_table': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Lvs3oZX5McwfztM7P0OLqPr3', 'function': {'arguments': '{\\n\"cancel\": false,\\n\"reason\": \"Successfully fetched the table for robot model parameters\"\\n}', 'name': 'CompleteOrEscalate'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 625, 'total_tokens': 654}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-fd03621d-5bd7-4589-8be6-3c4e0f024c3e-0', tool_calls=[{'name': 'CompleteOrEscalate', 'args': {'cancel': False, 'reason': 'Successfully fetched the table for robot model parameters'}, 'id': 'call_Lvs3oZX5McwfztM7P0OLqPr3'}], usage_metadata={'input_tokens': 625, 'output_tokens': 29, 'total_tokens': 654})}},\n",
       " {'leave_skill': {'messages': [ToolMessage(content='Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.', id='449cee8d-f08e-4e8c-a35d-b490d62c5edd', tool_call_id='call_Lvs3oZX5McwfztM7P0OLqPr3')],\n",
       "   'dialog_state': 'pop'}},\n",
       " {'primary_assistant': {'messages': AIMessage(content='G20型家用清洁机器人的电源线长度为180厘米。无论是标准版还是上下水版，电源线长度都是一样的。', response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 592, 'total_tokens': 639}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-e78756bd-0077-4d80-a97b-4b9a84c4b2d7-0', usage_metadata={'input_tokens': 592, 'output_tokens': 47, 'total_tokens': 639})}}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45b06bf0-184e-4eb9-a58e-a23ad25f772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "G20\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ToTableSearchingAssistant (call_V57rSxH592l6MFm2kVnvtqSP)\n",
      " Call ID: call_V57rSxH592l6MFm2kVnvtqSP\n",
      "  Args:\n",
      "    request: G20 扫地机电源线多长\n",
      "Currently in:  fetch_table\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The assistant is now the Assistant of Searching Robot Model Parameters. Reflect on the above conversation between the host assistant and the user. The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are Assistant of Searching Robot Model Parameters, and the task is not complete until after you have successfully invoked the appropriate tool. If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control. Do not mention who you are - just act as the proxy for the assistant.Directly use the request below as input to your tools and don't translate into English or rephase.\n",
      "\n",
      "request: G20 扫地机电源线多长\n",
      "Currently in:  fetch_table\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  fetch_table (call_d7Totv5lPupge2VgFeXMml94)\n",
      " Call ID: call_d7Totv5lPupge2VgFeXMml94\n",
      "  Args:\n",
      "    request: G20 扫地机电源线多长\n",
      "Currently in:  fetch_table\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: fetch_table\n",
      "\n",
      "| 商品型号 | 版本 | 电源线长 |\n",
      "| --- | --- | --- |\n",
      "| g20 | 标准版 | 180cm |\n",
      "| g20 | 上下水版 | 180cm |\n",
      "Currently in:  fetch_table\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  CompleteOrEscalate (call_V57rSxH592l6MFm2kVnvtqSP)\n",
      " Call ID: call_V57rSxH592l6MFm2kVnvtqSP\n",
      "  Args:\n",
      "    cancel: False\n",
      "    reason: Fetched the table successfully\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "您的G20型号扫地机器人的电源线长为180厘米。\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159b457-36ee-4ffa-8ad5-920cf1dd36d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a11a9a-fc99-4ff4-a0a1-694ca282a487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4059423-2835-4786-9ce6-22961672d5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a84eb-d535-4be7-ae2e-11eaad85bf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8c790e-1b01-49ac-b9af-738ab600e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "from find_keywords import LabellerByRulesWithPos\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QAVectorDBSearchEngine\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import ToolMessage, AIMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "\n",
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "extractor = router_config[\"class\"](router_config[\"config\"])\n",
    "recall = recall_config[\"class\"](recall_config[\"config\"])\n",
    "nl2sql = nl2sql_config[\"class\"](nl2sql_config[\"config\"])\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm_grader = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "structured_llm_grader = llm_grader.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system_grader = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_grader),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_table(question):\n",
    "    \"\"\"Consult a table about parameters of household cleaning machines according to the question,\n",
    "    and return the results.\"\"\"\n",
    "    query_body = extractor.extract_keywords(question)\n",
    "    if not query_body[\"labels\"][\"model\"]:\n",
    "        return \"问题中需要提供型号名称才能完成搜索\"\n",
    "    query_body.update({\"top_n\": recall_config[\"top_n\"]})\n",
    "    recalled_cols = recall.query_recalls(query_body)\n",
    "    pairs = [{\"question\": question, \"document\": d['page_content']} for d in recalled_cols]\n",
    "    scores = retrieval_grader.batch(pairs)\n",
    "    filtered_docs = [recalled_cols[i] for i in range(len(scores)) if scores[i].binary_score == \"yes\"]\n",
    "    if not filtered_docs:\n",
    "        return \"搜索结果和问题的匹配度很低，请换个问法\"\n",
    "    else:\n",
    "        tabler_results = nl2sql.predict(query_body, filtered_docs)\n",
    "        return tabler_results\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    # status: str\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if isinstance(last_message, ToolMessage) and (last_message.name == \"search_table\"):\n",
    "            result = AIMessage(content=last_message.content)\n",
    "            # if last_message.content == \"问题中需要提供型号名称才能完成搜索\":\n",
    "            #     status = \"retry\"\n",
    "            # elif last_message.content == \"搜索结果和问题的匹配度很低，请换个问法\":\n",
    "            #     status = \"ask_for_human\"\n",
    "            # else:\n",
    "            #     status = \"reset\"\n",
    "            # return {\"messages\": result, \"status\": status}\n",
    "            return {\"messages\": result}\n",
    "\n",
    "        # status = state.get(\"status\", \"reset\")\n",
    "        while True:\n",
    "            # if status == \"reset\":\n",
    "            #     suffix = \" Directly use the query as input to your tools, and do not make any language translations or rephrases\"\n",
    "            # else:\n",
    "            #     suffix = \"\"\n",
    "            # input_dict = {\"messages\": state[\"messages\"], \"suffix\": suffix}\n",
    "            # result = self.runnable.invoke(input_dict)\n",
    "            result = self.runnable.invoke(state)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        # return {\"messages\": result, \"status\": status}\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# system = \"\"\"You are a specialized assistant for searching table about parameters \\\n",
    "# of cleaning machines. If the query is appropriate for your specialty, invoke your tools to \\\n",
    "# help with that, otherwise just reject to answer.{suffix} Use the language the same as the query to answer.\"\"\"\n",
    "system = \"\"\"You are a specialized assistant for searching table about parameters \\\n",
    "of cleaning machines. If the query is appropriate for your specialty, invoke your tools to \\\n",
    "help with that, otherwise just reject to answer. Use the language the same as the query to answer.\"\"\"\n",
    "\n",
    "# Table Searching Assistant\n",
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "     [search_table]\n",
    ")\n",
    "\n",
    "\n",
    "# begin of graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# node\n",
    "builder.add_node(\"search_table_assistant\", Assistant(table_searching_runnable))\n",
    "builder.set_entry_point(\"search_table_assistant\")\n",
    "builder.add_node(\n",
    "    \"search_table_tools\",\n",
    "    create_tool_node_with_fallback([search_table]),\n",
    ")\n",
    "\n",
    "\n",
    "# edge\n",
    "def route_search_table(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"search_table_tools\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    return \"search_table_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"search_table_tools\", \"search_table_assistant\")\n",
    "builder.add_conditional_edges(\"search_table_assistant\", route_search_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97345a8b-ea70-4f35-b3a9-59f37a881af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68839581-52c5-41ce-8427-2062c8538a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_4_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f7ed52b-16f8-4af8-a8bc-d4267214e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"198197a5-c74c-463d-8312-ded3f1d94479\",\n",
    "    }\n",
    "}\n",
    "_printed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3947fcc-0cb1-4ed9-a7fd-552d0a1b0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"谢谢\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "062337e8-52de-46b5-9d68-338a5ec5a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "谢谢\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "不客气，有需要再告诉我。\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23c3332-9548-4879-a084-6ebd6f4e3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d023093-f106-4e43-852b-f360d5d25b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e925f-8042-426e-b3ee-8a05fb23fda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "074c8159-c1f9-4b45-9cf3-469edb399c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from find_keywords import LabellerByRulesWithPos\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QAVectorDBSearchEngine\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import ToolMessage, AIMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "\n",
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "extractor = router_config[\"class\"](router_config[\"config\"])\n",
    "recall = recall_config[\"class\"](recall_config[\"config\"])\n",
    "nl2sql = nl2sql_config[\"class\"](nl2sql_config[\"config\"])\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm_grader = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "structured_llm_grader = llm_grader.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_table(question):\n",
    "    \"\"\"Consult a table about parameters of household cleaning machines according to the question,\n",
    "    and return the results.\"\"\"\n",
    "    query_body = extractor.extract_keywords(question)\n",
    "    if not query_body[\"labels\"][\"model\"]:\n",
    "        return \"问题中需要提供型号名称才能完成搜索\"\n",
    "    query_body.update({\"top_n\": recall_config[\"top_n\"]})\n",
    "    recalled_cols = recall.query_recalls(query_body)\n",
    "    pairs = [{\"question\": question, \"document\": d['page_content']} for d in recalled_cols]\n",
    "    scores = retrieval_grader.batch(pairs)\n",
    "    filtered_docs = [recalled_cols[i] for i in range(len(scores)) if scores[i].binary_score == \"yes\"]\n",
    "    if not filtered_docs:\n",
    "        return \"搜索结果和问题的匹配度很低，请换个问法\"\n",
    "    else:\n",
    "        tabler_results = nl2sql.predict(query_body, filtered_docs)\n",
    "        return tabler_results\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    status: str\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if isinstance(last_message, ToolMessage) and (last_message.name == \"search_table\"):\n",
    "            result = AIMessage(content=last_message.content)\n",
    "            if last_message.content == \"问题中需要提供型号名称才能完成搜索\":\n",
    "                status = \"retry\"\n",
    "            elif last_message.content == \"搜索结果和问题的匹配度很低，请换个问法\":\n",
    "                status = \"ask_for_human\"\n",
    "            else:\n",
    "                status = \"reset\"\n",
    "            return {\"messages\": result, \"status\": status}\n",
    "\n",
    "        status = state.get(\"status\", \"reset\")\n",
    "        while True:\n",
    "            if status == \"reset\":\n",
    "                suffix = \" Directly use the query as input to your tools, and do not make any language translations or rephrases\"\n",
    "            else:\n",
    "                suffix = \"\"\n",
    "            input_dict = {\"messages\": state[\"messages\"], \"suffix\": suffix}\n",
    "            result = self.runnable.invoke(input_dict)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result, \"status\": status}\n",
    "\n",
    "\n",
    "system = \"\"\"You are a specialized assistant for searching table about parameters \\\n",
    "of cleaning machines. If the query is appropriate for your specialty, invoke your tools to \\\n",
    "help with that, otherwise just reject to answer.{suffix} Use the language the same as the query to answer.\"\"\"\n",
    "\n",
    "# Table Searching Assistant\n",
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "     [search_table]\n",
    ")\n",
    "\n",
    "\n",
    "# begin of graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# node\n",
    "builder.add_node(\"search_table_assistant\", Assistant(table_searching_runnable))\n",
    "builder.set_entry_point(\"search_table_assistant\")\n",
    "builder.add_node(\n",
    "    \"search_table_tools\",\n",
    "    create_tool_node_with_fallback([search_table]),\n",
    ")\n",
    "\n",
    "\n",
    "# edge\n",
    "def route_search_table(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"search_table_tools\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    return \"search_table_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"search_table_tools\", \"search_table_assistant\")\n",
    "builder.add_conditional_edges(\"search_table_assistant\", route_search_table)\n",
    "\n",
    "# Compile graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "392ccd06-81cf-4f18-8a15-8f6887e419d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_4_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "99de3aee-4e97-444f-b503-cdc916e1445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"198197a5-c74c-463d-8312-ded3f1d94479\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4418b1ca-aae5-4acc-b853-77a0958c3763",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"谢谢你\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0168d83c-76ae-4e23-adac-10c2be998b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "谢谢你\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "不客气，有其他问题欢迎随时向我提问。\n"
     ]
    }
   ],
   "source": [
    "_printed = set()\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a348a6ee-4f2b-4919-a4ec-7ab1c8ce4c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='你好', id='cf113f05-d9e8-4c69-9b92-ad9d2a31037e'), AIMessage(content='你好，有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 109, 'total_tokens': 128}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-24536ee3-873c-4f8b-8585-bce6f5fb11b8-0', usage_metadata={'input_tokens': 109, 'output_tokens': 19, 'total_tokens': 128}), HumanMessage(content='机器人电源线多长', id='5462dbfb-7882-4a4c-9c35-dfbfb2e73ff2'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QfUt6VwiREtMQaNWOjflZ7dL', 'function': {'arguments': '{\\n  \"question\": \"机器人电源线多长\"\\n}', 'name': 'search_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 143, 'total_tokens': 165}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-a48632d6-c027-4ae4-a986-30dda2b53832-0', tool_calls=[{'name': 'search_table', 'args': {'question': '机器人电源线多长'}, 'id': 'call_QfUt6VwiREtMQaNWOjflZ7dL'}], usage_metadata={'input_tokens': 143, 'output_tokens': 22, 'total_tokens': 165}), ToolMessage(content='问题中需要提供型号名称才能完成搜索', name='search_table', id='77671a1c-f6f0-4245-9bfb-15f140db06eb', tool_call_id='call_QfUt6VwiREtMQaNWOjflZ7dL'), AIMessage(content='问题中需要提供型号名称才能完成搜索', id='c6d47290-0226-4ea9-9ce4-38145f614741'), HumanMessage(content='G20', id='05f2fdde-bc89-4bbd-84e7-a884613c7908'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QfUt6VwiREtMQaNWOjflZ7dL', 'function': {'arguments': '{\"question\": \"G20机器人电源线多长\"}', 'name': 'search_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 224, 'total_tokens': 245}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-0062be34-b805-4212-b964-54444eb015a4-0', tool_calls=[{'name': 'search_table', 'args': {'question': 'G20机器人电源线多长'}, 'id': 'call_QfUt6VwiREtMQaNWOjflZ7dL'}], usage_metadata={'input_tokens': 224, 'output_tokens': 21, 'total_tokens': 245}), ToolMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', name='search_table', id='660b9307-5ffd-4a8f-af8f-ebf472fe5a92', tool_call_id='call_QfUt6VwiREtMQaNWOjflZ7dL'), AIMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', id='f83cd20b-eea3-4c4f-8587-81271c9d4168'), HumanMessage(content='它功率多大', id='24f3d3a2-e37c-4090-b387-e186b375c913'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IyEMwSvwlgz99scj3SGSuwjm', 'function': {'arguments': '{\"question\": \"G20\\\\u673a\\\\u5668\\\\u4eba\\\\u529f\\\\u7387\\\\u591a\\\\u5927\"}', 'name': 'search_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 405, 'total_tokens': 439}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-2dd2bfcf-7852-4a17-80ee-d8fa24101ac5-0', tool_calls=[{'name': 'search_table', 'args': {'question': 'G20机器人功率多大'}, 'id': 'call_IyEMwSvwlgz99scj3SGSuwjm'}], usage_metadata={'input_tokens': 405, 'output_tokens': 34, 'total_tokens': 439}), ToolMessage(content='| 商品型号 | 版本 | 主机额定功率 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 69W |\\n| g20 | 上下水版 | 69W |', name='search_table', id='0ed80c16-c732-44ef-8a63-d8b0eadd255c', tool_call_id='call_IyEMwSvwlgz99scj3SGSuwjm'), AIMessage(content='| 商品型号 | 版本 | 主机额定功率 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 69W |\\n| g20 | 上下水版 | 69W |', id='e21a74f2-567e-442c-877a-ff2e54b4b92e'), HumanMessage(content='谢谢你', id='ac4c6f72-ba50-4afa-a0fa-7cdef9bb2cf9'), AIMessage(content='不客气，有其他问题欢迎随时向我提问。', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 560, 'total_tokens': 581}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-0d5c15c1-cc1c-4779-81ab-21bd8c970975-0', usage_metadata={'input_tokens': 560, 'output_tokens': 21, 'total_tokens': 581})], 'status': 'reset'}, next=(), config={'configurable': {'thread_id': '198197a5-c74c-463d-8312-ded3f1d94479', 'thread_ts': '1ef37a80-efe7-63d1-8013-68414bbe8811'}}, metadata={'source': 'loop', 'step': 19, 'writes': {'search_table_assistant': {'messages': AIMessage(content='不客气，有其他问题欢迎随时向我提问。', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 560, 'total_tokens': 581}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-0d5c15c1-cc1c-4779-81ab-21bd8c970975-0', usage_metadata={'input_tokens': 560, 'output_tokens': 21, 'total_tokens': 581}), 'status': 'reset'}}}, created_at='2024-07-01T12:47:21.736440+00:00', parent_config={'configurable': {'thread_id': '198197a5-c74c-463d-8312-ded3f1d94479', 'thread_ts': '1ef37a80-da06-6bc6-8012-fbbbec8f74d0'}})"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_4_graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3a843ebb-110d-4dad-b232-f405a67b38bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "G20电源线多长\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_table (call_POixWLXoZibFqPJSq8MaPx3b)\n",
      " Call ID: call_POixWLXoZibFqPJSq8MaPx3b\n",
      "  Args:\n",
      "    question: G20 电源线多长\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_table\n",
      "\n",
      "| 商品型号 | 版本 | 电源线长 |\n",
      "| --- | --- | --- |\n",
      "| g20 | 标准版 | 180cm |\n",
      "| g20 | 上下水版 | 180cm |\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The power cord of the standard and water versions of the G20 robot vacuum cleaner is 180cm long.\n"
     ]
    }
   ],
   "source": [
    "_printed = set()\n",
    "question = \"G20电源线多长\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c225a1d-db2c-44d3-a3f3-c43a13f3c209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='你好', id='4e44ec7c-63f9-4cc6-897f-2d13af4fe067'), AIMessage(content='对不起，我无法回答这个问题。我专门帮助寻找关于清洁机器参数的表格信息。如果您有这方面的需求，请提问。', response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 98, 'total_tokens': 149}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-cfec7297-5a55-49d2-a48f-7455a960d0f0-0', usage_metadata={'input_tokens': 98, 'output_tokens': 51, 'total_tokens': 149})]}, next=(), config={'configurable': {'thread_id': '198197a5-c74c-463d-8312-ded3f1d94479', 'thread_ts': '1ef3764c-c36c-6157-8001-1cde80512200'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'search_table_assistant': {'messages': AIMessage(content='对不起，我无法回答这个问题。我专门帮助寻找关于清洁机器参数的表格信息。如果您有这方面的需求，请提问。', response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 98, 'total_tokens': 149}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-cfec7297-5a55-49d2-a48f-7455a960d0f0-0', usage_metadata={'input_tokens': 98, 'output_tokens': 51, 'total_tokens': 149})}}}, created_at='2024-07-01T04:45:53.417195+00:00', parent_config={'configurable': {'thread_id': '198197a5-c74c-463d-8312-ded3f1d94479', 'thread_ts': '1ef3764c-9c81-6703-8000-507c297dbd2b'}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_4_graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc82d8e5-0f62-45f5-85b4-9db7b08b217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "G20\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_table (call_I761kdzrMk1ZF35URKJsxo3p)\n",
      " Call ID: call_I761kdzrMk1ZF35URKJsxo3p\n",
      "  Args:\n",
      "    question: G20电源线多长\n",
      "电源线长\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_table\n",
      "\n",
      "| 商品型号 | 版本 | 电源线长 |\n",
      "| --- | --- | --- |\n",
      "| g20 | 标准版 | 180cm |\n",
      "| g20 | 上下水版 | 180cm |\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "G20型清洁机的电源线长度为180厘米，无论是标准版还是上下水版。\n"
     ]
    }
   ],
   "source": [
    "question = \"G20\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f734e6-0003-4c88-a039-a9bf9277add2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e573360-09e8-40b2-b2eb-5b77c7b50a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3601f-d070-4f6f-ae49-179d2017c6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tutorial_questions = [\n",
    "    \"你好\",\n",
    "    \"G20电源线多长.\",\n",
    "    \"和1米比哪个长\",\n",
    "    \"帮我查询下天气好吗\",\n",
    "]\n",
    "\n",
    "\n",
    "_printed = set()\n",
    "for question in tutorial_questions:\n",
    "    events = part_4_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5bf635-817e-4cd3-a2e4-a2702319ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8fe60-9bf9-448c-86ae-7643b5179c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f91015-2959-4cf7-a097-f9fbc11b7970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7eb4ec-38ba-43d3-9718-55948401b74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fda4a-7046-43c5-9a2e-3e5379980653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c020d2ef-5584-4c5e-8e72-2ecba48b66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from find_keywords import LabellerByRulesWithPos\n",
    "from pipeline import NL2SQLPineline\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QAVectorDBSearchEngine\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing import Callable\n",
    "from typing import Literal\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "#%%\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "#%%\n",
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pipeline_config = {\n",
    "    \"router\": router_config,\n",
    "    \"recall\": recall_config,\n",
    "    \"nl2sql\": nl2sql_config,\n",
    "}\n",
    "\n",
    "nl2sql_pipeline = NL2SQLPineline(pipeline_config)\n",
    "#%%\n",
    "@tool\n",
    "def fetch_table(request: str) -> str:\n",
    "    \"\"\"Consult a table about robot model parameters according to the query,\n",
    "    and return the results.\"\"\"\n",
    "    results = nl2sql_pipeline.run(request)\n",
    "    return results\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"fetch_table\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example 1\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to get more information about robot model names.\",\n",
    "            },\n",
    "        }\n",
    "    cancel: bool = Field(description=\"If the current task should be canceled.\")\n",
    "    reason: str = Field(description=\"reason for cancelling or not\")\n",
    "#%%\n",
    "# Table Searching Assistant\n",
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for searching table about robot model parameters.\"\n",
    "            \"The primary assistant delegates work to you whenever the user needs to know parameters about robot models.\"\n",
    "            \"The query must have robot model names such as A10, G20, H1 and so on to complete the search, and\"\n",
    "            ' if it does not have that information, use the tool \"CompleteOrEscalate\" to escalate the task back to the main assistant, '\n",
    "            \" but remember to set cancel = False.\"\n",
    "            'If you have successfully used the \"fetch_table\" tool, please use \"CompleteOrEscalate\" tool to escalate the task back to the main assistant.'\n",
    "            \"\\n\\nIf none of your tools are appropriate, then use the tool \"\n",
    "            ' \"CompleteOrEscalate\" to send the dialog back to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"directly use the user query as input to your tools, and don't make any translations or rephrases.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "     [CompleteOrEscalate, fetch_table]\n",
    ")\n",
    "#%%\n",
    "# Primary Assistant\n",
    "class ToTableSearchingAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to search table for robot model parameters.\"\"\"\n",
    "    request: str = Field(\n",
    "        description=\"directly use the user query as input to the specialized assistant, and don't make any translations or rephrases.\"\n",
    "    )\n",
    "llm_p = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for home cleaning robot. \"\n",
    "            \"Your primary role is to answer customer queries about the home cleaning robot. \"\n",
    "            \"If a customer requests you to answer some questions outof the scope just reject to answer.\"\n",
    "            \"If a customer requests to know some parameter of a robot, \"\n",
    "            \"delegate the task to the appropriate specialized assistant by invoking the corresponding tool. You are not able to make these types of changes yourself.\"\n",
    "            \" Only the specialized assistants are given permission to do this for the user.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "assistant_runnable = primary_assistant_prompt | llm_p.bind_tools(\n",
    "    [\n",
    "        ToTableSearchingAssistant\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def create_entry_node(assistant_name: str, new_dialog_state: str) -> Callable:\n",
    "    def entry_node(state: State) -> dict:\n",
    "        tool_call_id = state[\"messages\"][-1].tool_calls[0][\"id\"]\n",
    "        request = state[\"messages\"][-1].tool_calls[0][\"args\"][\"request\"]\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    content=f\"The assistant is now the {assistant_name}. Reflect on the above conversation between the host assistant and the user.\"\n",
    "                    f\" The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are {assistant_name},\"\n",
    "                    \" and the task is not complete until after you have successfully invoked the appropriate tool.\"       \n",
    "                    \" If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \"If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.\"\n",
    "                    \" Do not mention who you are - just act as the proxy for the assistant.\"\n",
    "                    \"Directly use the request below as input to your tools and don't translate into English or rephase.\"\n",
    "                    f\"\\n\\nrequest: {request}\",\n",
    "                    tool_call_id=tool_call_id,\n",
    "                )\n",
    "            ],\n",
    "            \"dialog_state\": new_dialog_state,\n",
    "        }\n",
    "    return entry_node\n",
    "#%%\n",
    "builder = StateGraph(State)\n",
    "#%%\n",
    "# fetch table assistant\n",
    "builder.add_node(\n",
    "    \"enter_search_table\",\n",
    "    create_entry_node(\"Assistant of Searching Robot Model Parameters\", \"fetch_table\"),\n",
    ")\n",
    "builder.add_node(\"fetch_table\", Assistant(table_searching_runnable))\n",
    "builder.add_edge(\"enter_search_table\", \"fetch_table\")\n",
    "builder.add_node(\n",
    "    \"fetch_table_tools\",\n",
    "    create_tool_node_with_fallback([fetch_table]),\n",
    ")\n",
    "\n",
    "\n",
    "def route_fetch_table(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"fetch_table_tools\",\n",
    "    \"leave_skill\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    return \"fetch_table_tools\"\n",
    "\n",
    "\n",
    "builder.add_edge(\"fetch_table_tools\", \"fetch_table\")\n",
    "builder.add_conditional_edges(\"fetch_table\", route_fetch_table)\n",
    "#%%\n",
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }\n",
    "\n",
    "\n",
    "builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "builder.add_edge(\"leave_skill\", \"primary_assistant\")\n",
    "#%%\n",
    "# Primary assistant\n",
    "builder.add_node(\"primary_assistant\", Assistant(assistant_runnable))\n",
    "builder.set_entry_point(\"primary_assistant\")\n",
    "\n",
    "def route_primary_assistant(\n",
    "    state: State,\n",
    ") -> Literal[\n",
    "    \"enter_search_table\",\n",
    "    \"__end__\",\n",
    "]:\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    if tool_calls:\n",
    "        if tool_calls[0][\"name\"] == ToTableSearchingAssistant.__name__:\n",
    "            return \"enter_search_table\"\n",
    "    raise ValueError(\"Invalid route\")\n",
    "\n",
    "\n",
    "# The assistant can route to one of the delegated assistants,\n",
    "# directly use a tool, or directly respond to the user\n",
    "builder.add_conditional_edges(\n",
    "    \"primary_assistant\",\n",
    "    route_primary_assistant,\n",
    "    {\n",
    "        \"enter_search_table\": \"enter_search_table\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "# # Each delegated workflow can directly respond to the user\n",
    "# # When the user responds, we want to return to the currently active workflow\n",
    "# def route_to_workflow(\n",
    "#     state: State,\n",
    "# ) -> Literal[\n",
    "#     \"fetch_table\",\n",
    "# ]:\n",
    "#     \"\"\"If we are in a delegated state, route directly to the appropriate assistant.\"\"\"\n",
    "#     dialog_state = state.get(\"dialog_state\")\n",
    "#     if not dialog_state:\n",
    "#         return \"primary_assistant\"\n",
    "#     return dialog_state[-1]\n",
    "\n",
    "\n",
    "# builder.add_conditional_edges(\"primary_assistant\", route_to_workflow)\n",
    "#%%\n",
    "# Compile graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "part_4_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    ")\n",
    "#%%\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(part_4_graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "\n",
    "\n",
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight informatio\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": \"198197a5-c74c-463d-8312-ded3f1d94479\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28a3ab87-f4f6-46bc-95fc-6bfebc46b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"今天天气如何\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae9801e-c0a5-451c-9567-672035cd5925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'primary_assistant': {'messages': AIMessage(content='对不起，我无法回答关于天气的问题，我主要是回答与家庭清洁机器人相关的问题。如果您有关于家庭清洁机器人的问题，我会很乐意帮助您。', response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 239, 'total_tokens': 309}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-a1ef2236-d5c2-4347-9cce-10e270e15b2f-0', usage_metadata={'input_tokens': 239, 'output_tokens': 70, 'total_tokens': 309})}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9d5ae98-87ee-4583-b196-36bd75ec2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "我机器人的功率多大\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ToTableSearchingAssistant (call_mgZ8ky8NfR2kMAGmVZEupXAA)\n",
      " Call ID: call_mgZ8ky8NfR2kMAGmVZEupXAA\n",
      "  Args:\n",
      "    request: 我机器人的功率多大\n",
      "Currently in:  fetch_table\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "The assistant is now the Assistant of Searching Robot Model Parameters. Reflect on the above conversation between the host assistant and the user. The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are Assistant of Searching Robot Model Parameters, and the task is not complete until after you have successfully invoked the appropriate tool. If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control. Do not mention who you are - just act as the proxy for the assistant.Directly use the request below as input to your tools and don't translate into English or rephase.\n",
      "\n",
      "request: 我机器人的功率多大\n",
      "Currently in:  fetch_table\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  CompleteOrEscalate (call_5anG6K4PwyBDh4eQXVFDN0F4)\n",
      " Call ID: call_5anG6K4PwyBDh4eQXVFDN0F4\n",
      "  Args:\n",
      "    cancel: True\n",
      "    reason: The user query lacks specific robot model name. Escalating to the main assistant for further clarification.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "对不起，为了能准确地为您查找，我需要知道您的机器人型号是什么？\n"
     ]
    }
   ],
   "source": [
    "question = \"我机器人的功率多大\"\n",
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "e0d34490-c24f-439e-a885-4973c67b59f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "tutorial_questions = [\n",
    "    \"你好\",\n",
    "    \"G20电源线多长.\",\n",
    "    \"和1米比哪个长\",\n",
    "    \"帮我查询下天气好吗\",\n",
    "]\n",
    "#%%\n",
    "_printed = set()\n",
    "for question in tutorial_questions:\n",
    "    events = part_4_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "f02af9a2-028a-4573-b33e-2a177d6c7966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "你好\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "您好！请问需要什么帮助？\n"
     ]
    }
   ],
   "source": [
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", \"你好\")}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "8a685acf-a205-43a7-a526-677b6eb193a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'primary_assistant': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_d7Totv5lPupge2VgFeXMml94', 'function': {'arguments': '{\\n\"request\": \"G20电源线长度\"\\n}', 'name': 'ToTableSearchingAssistant'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 883, 'total_tokens': 903}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-a7dff181-d75c-44ec-9e78-8fdcd25db445-0', tool_calls=[{'name': 'ToTableSearchingAssistant', 'args': {'request': 'G20电源线长度'}, 'id': 'call_d7Totv5lPupge2VgFeXMml94'}], usage_metadata={'input_tokens': 883, 'output_tokens': 20, 'total_tokens': 903})}},\n",
       " {'enter_search_table': {'messages': [ToolMessage(content=\"The assistant is now the Assistant of Searching Robot Model Parameters. Reflect on the above conversation between the host assistant and the user. The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are Assistant of Searching Robot Model Parameters, and the task is not complete until after you have successfully invoked the appropriate tool. If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control. Do not mention who you are - just act as the proxy for the assistant.Directly use the request below as input to your tools and don't translate into English or rephase.\\n\\nrequest: G20电源线长度\", id='dfb1d96f-736d-4372-be6f-2c56c6b10114', tool_call_id='call_d7Totv5lPupge2VgFeXMml94')],\n",
       "   'dialog_state': 'fetch_table'}},\n",
       " {'fetch_table': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_d7Totv5lPupge2VgFeXMml94', 'function': {'arguments': '{\"request\": \"G20\\\\u7535\\\\u6e90\\\\u7ebf\\\\u957f\\\\u5ea6\"}', 'name': 'fetch_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 1182, 'total_tokens': 1213}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-2bacd9ce-1545-4030-a2ec-380d930b0ef2-0', tool_calls=[{'name': 'fetch_table', 'args': {'request': 'G20电源线长度'}, 'id': 'call_d7Totv5lPupge2VgFeXMml94'}], usage_metadata={'input_tokens': 1182, 'output_tokens': 31, 'total_tokens': 1213})}},\n",
       " {'fetch_table_tools': {'messages': [ToolMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', name='fetch_table', id='d1a4cff1-cc33-48f6-aefe-defc6115431a', tool_call_id='call_d7Totv5lPupge2VgFeXMml94')]}},\n",
       " {'fetch_table': {'messages': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6lTbJyosxUKp6HDoi3gTgluc', 'function': {'arguments': '{\"cancel\": false, \"reason\": \"Success\"}', 'name': 'CompleteOrEscalate'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 1270, 'total_tokens': 1290}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-76fa13d7-f4c8-4d39-b183-7796b9d01f68-0', tool_calls=[{'name': 'CompleteOrEscalate', 'args': {'cancel': False, 'reason': 'Success'}, 'id': 'call_6lTbJyosxUKp6HDoi3gTgluc'}], usage_metadata={'input_tokens': 1270, 'output_tokens': 20, 'total_tokens': 1290})}},\n",
       " {'leave_skill': {'messages': [ToolMessage(content='Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.', id='bd746d2e-59eb-4291-b764-bd40e6be5f51', tool_call_id='call_6lTbJyosxUKp6HDoi3gTgluc')],\n",
       "   'dialog_state': 'pop'}},\n",
       " {'primary_assistant': {'messages': AIMessage(content='您的G20型清洁机器人的电源线长度是180cm。', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1230, 'total_tokens': 1251}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-3938da2f-6681-428a-9915-0c8ab4dc62da-0', usage_metadata={'input_tokens': 1230, 'output_tokens': 21, 'total_tokens': 1251})}}]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(part_4_graph.stream(\n",
    "        {\"messages\": (\"user\", \"G20电源线多长\")}, config\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "e9c8b7a9-aec3-4d99-89b4-59c8524d7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(part_4_graph.stream(\n",
    "        {\"messages\": (\"user\", \"G20电源线多长\")}, config, stream_mode=\"values\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "1708935b-abfb-4677-9263-837756e2d00c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[475], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "a[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "72afb934-ad21-4e99-9c9b-ec457f2ec858",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = part_4_graph.stream(\n",
    "    {\"messages\": (\"user\", \"你好\")}, config, stream_mode=\"values\"\n",
    ")\n",
    "# for event in events:\n",
    "#     _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "fa0150ca-444b-46f2-9f8f-5f5447fe878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "10187428-bf10-493d-9d22-3d25e51b0bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='你好', id='63692bbe-b5da-4010-b8b5-4885fe475f5d'),\n",
       "  AIMessage(content='您好！请问有什么我可以帮助您的？', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 234, 'total_tokens': 253}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-9c2bfb87-abe0-4175-a1ca-9dafa68b9c0d-0', usage_metadata={'input_tokens': 234, 'output_tokens': 19, 'total_tokens': 253}),\n",
       "  HumanMessage(content='G20电源线多长', id='02bfdf4b-5a8f-4546-8fae-f3e490e1a73d'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9u2JgQfoHHmk6UaKS5s3nTiB', 'function': {'arguments': '{\\n  \"request\": \"G20电源线长度\"\\n}', 'name': 'ToTableSearchingAssistant'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 267, 'total_tokens': 288}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-9fb6559c-0ff3-4960-8633-cdd1108a42a2-0', tool_calls=[{'name': 'ToTableSearchingAssistant', 'args': {'request': 'G20电源线长度'}, 'id': 'call_9u2JgQfoHHmk6UaKS5s3nTiB'}], usage_metadata={'input_tokens': 267, 'output_tokens': 21, 'total_tokens': 288}),\n",
       "  ToolMessage(content=\"The assistant is now the Assistant of Searching Robot Model Parameters. Reflect on the above conversation between the host assistant and the user. The user's intent is unsatisfied. Use the provided tools to assist the user. Remember, you are Assistant of Searching Robot Model Parameters, and the task is not complete until after you have successfully invoked the appropriate tool. If the you needs more information to complete the task, call the CompleteOrEscalate function to let the primary host assistant take control.If you successfullyt complete the task, call the CompleteOrEscalate function to let the primary host assistant take control. Do not mention who you are - just act as the proxy for the assistant.Directly use the request below as input to your tools and don't translate into English or rephase.\\n\\nrequest: G20电源线长度\", id='2c1d0e34-698f-424b-b53e-4e62559e16ab', tool_call_id='call_9u2JgQfoHHmk6UaKS5s3nTiB'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nZloLpMNI52ysfXwcl6Icjv4', 'function': {'arguments': '{\\n\"request\": \"G20电源线长度\"\\n}', 'name': 'fetch_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 566, 'total_tokens': 585}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-ec666f5a-5333-423f-9576-86cf755dcdd9-0', tool_calls=[{'name': 'fetch_table', 'args': {'request': 'G20电源线长度'}, 'id': 'call_nZloLpMNI52ysfXwcl6Icjv4'}], usage_metadata={'input_tokens': 566, 'output_tokens': 19, 'total_tokens': 585}),\n",
       "  ToolMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', name='fetch_table', id='9112dd42-2077-49aa-952d-ca727f86b14c', tool_call_id='call_nZloLpMNI52ysfXwcl6Icjv4'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_m22E4CbfvF4JSS8vOw4IgaiR', 'function': {'arguments': '{\\n\"cancel\": false,\\n\"reason\": \"Success\"\\n}', 'name': 'CompleteOrEscalate'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 654, 'total_tokens': 676}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-c41d5ea6-6b8b-4e9c-9e2c-4a1d9a14a01c-0', tool_calls=[{'name': 'CompleteOrEscalate', 'args': {'cancel': False, 'reason': 'Success'}, 'id': 'call_m22E4CbfvF4JSS8vOw4IgaiR'}], usage_metadata={'input_tokens': 654, 'output_tokens': 22, 'total_tokens': 676}),\n",
       "  ToolMessage(content='Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.', id='c1981b58-2673-4155-b326-6ae8a5e85b5e', tool_call_id='call_m22E4CbfvF4JSS8vOw4IgaiR'),\n",
       "  AIMessage(content='您的G20型清洁机器人的电源线长度是180cm。', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 614, 'total_tokens': 635}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-bb7c68f6-6acf-4b98-b247-264259fb2440-0', usage_metadata={'input_tokens': 614, 'output_tokens': 21, 'total_tokens': 635}),\n",
       "  HumanMessage(content='你好', id='fe957d09-ffab-40c5-b6fc-7b20063b5fdb'),\n",
       "  AIMessage(content='您好！请问有什么我可以帮助您的？', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 644, 'total_tokens': 663}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-cf6df8c2-08b3-40d4-9124-6ae27665acd4-0', usage_metadata={'input_tokens': 644, 'output_tokens': 19, 'total_tokens': 663}),\n",
       "  HumanMessage(content='你好', id='448ebb00-2c65-4763-bc54-7e043c5893a1'),\n",
       "  AIMessage(content='您好！有什么我可以帮您的吗？', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 672, 'total_tokens': 689}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-db1c7251-7023-4622-9e1c-4ef19d447d1f-0', usage_metadata={'input_tokens': 672, 'output_tokens': 17, 'total_tokens': 689}),\n",
       "  HumanMessage(content='你好', id='e743b22c-c737-4eef-8a96-75218c3e9ee9'),\n",
       "  AIMessage(content='您好！有什么我可以为您服务的吗？', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 698, 'total_tokens': 715}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-f5ffca9b-ff3a-4c4c-b139-73350f729d97-0', usage_metadata={'input_tokens': 698, 'output_tokens': 17, 'total_tokens': 715}),\n",
       "  HumanMessage(content='你好', id='6fa94362-aaa3-4131-9886-3d9d505f569a')],\n",
       " 'dialog_state': []}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24174985-677d-489a-af65-d6f1e205d02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095624c-ef3f-4f4f-a905-1131b037a908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc2250-4827-4d0a-a2d6-362f0ec64edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "f44195e7-7c18-4058-8a18-e27792cb2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from find_keywords import LabellerByRulesWithPos\n",
    "from pipeline import NL2SQLPineline\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QAVectorDBSearchEngine\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing import Callable\n",
    "from typing import Literal\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "#%%\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)\n",
    "\n",
    "#%%\n",
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pipeline_config = {\n",
    "    \"router\": router_config,\n",
    "    \"recall\": recall_config,\n",
    "    \"nl2sql\": nl2sql_config,\n",
    "}\n",
    "\n",
    "nl2sql_pipeline = NL2SQLPineline(pipeline_config)\n",
    "#%%\n",
    "@tool\n",
    "def fetch_table(request: str) -> str:\n",
    "    \"\"\"Consult a table about robot model parameters according to the query,\n",
    "    and return the results.\"\"\"\n",
    "    results = nl2sql_pipeline.run(request)\n",
    "    return results\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"tools\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": [result]}\n",
    "\n",
    "# @tool\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example 1\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to get more information about robot model names.\",\n",
    "            },\n",
    "        }\n",
    "    cancel: bool = Field(description=\"If the current task should be canceled.\")\n",
    "    reason: str = Field(description=\"reason for cancelling or not\")\n",
    "#%%\n",
    "# Table Searching Assistant\n",
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for searching table about robot model parameters.\"\n",
    "            \"The primary assistant delegates work to you whenever the user needs to know parameters about robot models.\"\n",
    "            \"The query must have robot model names such as A10, G20, H1 and so on to complete the search, and\"\n",
    "            ' if it does not have that information, use the tool \"CompleteOrEscalate\" to escalate the task back to the main assistant, '\n",
    "            \" but remember to set cancel = False.\"\n",
    "            'If you have successfully used the \"fetch_table\" tool, please use \"CompleteOrEscalate\" tool to escalate the task back to the main assistant.'\n",
    "            \"\\n\\nIf none of your tools are appropriate, then use the tool \"\n",
    "            ' \"CompleteOrEscalate\" to send the dialog back to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"directly use the user query as input to your tools, and don't make any translations or rephrases.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "     [CompleteOrEscalate, fetch_table]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "144d7138-ea94-4544-a3e6-a5aad755180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# class State(TypedDict):\n",
    "#     messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [table_searching_runnable.invoke(state)]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4ebc954e-ff84-4b7f-83c2-acb2d57c32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "# tool_node = BasicToolNode(tools=[CompleteOrEscalate, fetch_table])\n",
    "graph_builder.add_node(\"tools\", create_tool_node_with_fallback([fetch_table]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "8463aadd-e95d-4a74-a104-cfc755ef0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This node will be shared for exiting all specialized assistants\n",
    "def pop_dialog_state(state: State) -> dict:\n",
    "    \"\"\"Pop the dialog stack and return to the main assistant.\n",
    "\n",
    "    This lets the full graph explicitly track the dialog flow and delegate control\n",
    "    to specific sub-graphs.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    if state[\"messages\"][-1].tool_calls:\n",
    "        # Note: Doesn't currently handle the edge case where the llm performs parallel tool calls\n",
    "        messages.append(\n",
    "            ToolMessage(\n",
    "                content=\"Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\n",
    "        \"dialog_state\": \"pop\",\n",
    "        \"messages\": messages,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "e58cbdfe-82cb-4909-9eae-47902cf7834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "# def route_tools(\n",
    "#     state: State,\n",
    "# ) -> Literal[\"tools\", \"__end__\"]:\n",
    "#     \"\"\"\n",
    "#     Use in the conditional_edge to route to the ToolNode if the last message\n",
    "#     has tool calls. Otherwise, route to the end.\n",
    "#     \"\"\"\n",
    "#     # if isinstance(state, list):\n",
    "#     #     ai_message = state[-1]\n",
    "#     if messages := state.get(\"messages\", []):\n",
    "#         ai_message = messages[-1]\n",
    "#     else:\n",
    "#         raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "#     if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "#         return \"tools\"\n",
    "#     return \"__end__\"\n",
    "\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    ") -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # if isinstance(state, list):\n",
    "    #     ai_message = state[-1]\n",
    "    route = tools_condition(state)\n",
    "    if route == END:\n",
    "        return END\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    did_cancel = any(tc[\"name\"] == CompleteOrEscalate.__name__ for tc in tool_calls)\n",
    "    if did_cancel:\n",
    "        return \"leave_skill\"\n",
    "    return \"tools\"\n",
    "        \n",
    "    # if messages := state.get(\"messages\", []):\n",
    "    #     ai_message = messages[-1]\n",
    "    # else:\n",
    "    #     raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "    #     return \"tools\"\n",
    "    # return \"__end__\"\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\", \"leave_skill\": \"leave_skill\"},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.add_node(\"leave_skill\", pop_dialog_state)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "00dc30c8-5dea-4175-9aeb-0caff0df20e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "34b9dd9b-dae3-44f1-b902-ac8baca63d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chatbot': {'messages': [AIMessage(content='{\"functions.CompleteOrEscalate\": {\"cancel\": false, \"reason\": \"The user query does not contain the name of a robot model. Escalating to main assistant.\"}}\\n{\"functions.CompleteOrEscalate\": {\"cancel\": false, \"reason\": \"The user query does not contain the name of a robot model. Escalating to main assistant.\"}}', response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 326, 'total_tokens': 404}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-bf18e73e-f606-4ebc-a6b9-10aa39f54d58-0', usage_metadata={'input_tokens': 326, 'output_tokens': 78, 'total_tokens': 404})]}}]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"你好\"\n",
    "list(graph.stream({\"messages\": [user_input]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "27af2203-1e26-49c4-aae0-94c7ad3dbfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5anG6K4PwyBDh4eQXVFDN0F4', 'function': {'arguments': '{\\n  \"cancel\": false,\\n  \"reason\": \"The query does not contain any specific robot model name\"\\n}', 'name': 'CompleteOrEscalate'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 329, 'total_tokens': 362}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-7a2dd9aa-3a92-4b99-a753-cad2638e1fe2-0', tool_calls=[{'name': 'CompleteOrEscalate', 'args': {'cancel': False, 'reason': 'The query does not contain any specific robot model name'}, 'id': 'call_5anG6K4PwyBDh4eQXVFDN0F4'}], usage_metadata={'input_tokens': 329, 'output_tokens': 33, 'total_tokens': 362})]}},\n",
       " {'leave_skill': {'messages': [ToolMessage(content='Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.', id='0d94c885-0c5a-4a94-a64c-ddbe30e08129', tool_call_id='call_5anG6K4PwyBDh4eQXVFDN0F4')],\n",
       "   'dialog_state': 'pop'}}]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"G20电源线多长\"\n",
    "list(graph.stream({\"messages\": [user_input]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "8b735e20-df11-4c84-a80c-0106bdb3f002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_N49MGrfsRfhmpLStVHZOmznl', 'function': {'arguments': '{\\n\"request\": \"G20电源线多长\"\\n}', 'name': 'fetch_table'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 331, 'total_tokens': 351}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-bc0e2ecc-e375-460c-831a-f263d207657e-0', tool_calls=[{'name': 'fetch_table', 'args': {'request': 'G20电源线多长'}, 'id': 'call_N49MGrfsRfhmpLStVHZOmznl'}], usage_metadata={'input_tokens': 331, 'output_tokens': 20, 'total_tokens': 351})]}},\n",
       " {'tools': {'messages': [ToolMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', name='fetch_table', id='e9c73ef8-8eb0-4b26-85fd-4d1eb2bdbeb7', tool_call_id='call_N49MGrfsRfhmpLStVHZOmznl')]}},\n",
       " {'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4cEwik69mqApT2ZG0EqhxcuH', 'function': {'arguments': '{\\n\"cancel\": false,\\n\"reason\": \"Completed searching table about G20 robot model parameters\"\\n}', 'name': 'CompleteOrEscalate'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 418, 'total_tokens': 448}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-ae618cc4-579a-4660-afc1-d356ae446256-0', tool_calls=[{'name': 'CompleteOrEscalate', 'args': {'cancel': False, 'reason': 'Completed searching table about G20 robot model parameters'}, 'id': 'call_4cEwik69mqApT2ZG0EqhxcuH'}], usage_metadata={'input_tokens': 418, 'output_tokens': 30, 'total_tokens': 448})]}},\n",
       " {'leave_skill': {'messages': [ToolMessage(content='Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.', id='130c029f-9eb5-45e0-97e5-2e026907b6c9', tool_call_id='call_4cEwik69mqApT2ZG0EqhxcuH')],\n",
       "   'dialog_state': 'pop'}}]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"G20电源线多长\"\n",
    "list(graph.stream({\"messages\": [user_input]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "7a1b0f90-e9f0-4d34-9689-01632d4a616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "33fae226-0ae5-43f3-a14f-e860a992bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_printed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "c5e9676d-0bec-49da-9963-77979623db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"G20电源线多长\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": (\"user\", user_input)}\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "35feff43-3e51-47fe-bf02-86618432b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: | 商品型号 | 版本 | 电源线长 |\n",
      "| --- | --- | --- |\n",
      "| g20 | 标准版 | 180cm |\n",
      "| g20 | 上下水版 | 180cm |\n",
      "Assistant: \n",
      "Assistant: Resuming dialog with the host assistant. Please reflect on the past conversation and assist the user as needed.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa93097-a002-428a-8e32-03c34ad8ca14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc691d9-a934-477f-9ff1-3a4dcef93013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccf66c-5576-4de4-a1e4-66f2146e8ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ab3e27eb-2566-4b4f-b690-be32782215d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[381], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [user_input]}):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[43mBaseMessage\u001b[49m):\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant:\u001b[39m\u001b[38;5;124m\"\u001b[39m, value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseMessage' is not defined"
     ]
    }
   ],
   "source": [
    "user_input = \"你好\"\n",
    "for event in graph.stream({\"messages\": [user_input]}):\n",
    "    for value in event.values():\n",
    "        if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "eb58aad4-b779-4a72-baa7-427645dbf8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': AIMessage(content='{ \"functions.CompleteOrEscalate\": { \"cancel\": false, \"reason\": \"The query does not contain a robot model name for me to search for.\" } }', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 310, 'total_tokens': 347}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-545e47f2-8762-4e5d-bbae-d98d94a03bb2-0', usage_metadata={'input_tokens': 310, 'output_tokens': 37, 'total_tokens': 347})}"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead827a4-c666-4f52-8962-408d56a6c37f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d41c3-01bc-4be8-a801-cd352550cdf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd79534-0b88-483c-b227-76198bbf8164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f7e9260b-9ecc-4398-88f5-3831c452e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, List, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from find_keywords import LabellerByRulesWithPos\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QAVectorDBSearchEngine\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "\n",
    "\n",
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "extractor = router_config[\"class\"](router_config[\"config\"])\n",
    "recall = recall_config[\"class\"](recall_config[\"config\"])\n",
    "nl2sql = nl2sql_config[\"class\"](nl2sql_config[\"config\"])\n",
    "\n",
    "\n",
    "# Node: Get keywords\n",
    "def get_keywords(state):\n",
    "    question = state[\"messages\"][-1].content\n",
    "    query_body = extractor.extract_keywords(question)\n",
    "    return {\"query_body\": query_body}\n",
    "\n",
    "\n",
    "# Node: Retrieve\n",
    "def retrieve_documents(state):\n",
    "    query_body = state[\"query_body\"]\n",
    "    query_body.update({\"top_n\": recall_config[\"top_n\"]})\n",
    "    recalled_cols = recall.query_recalls(query_body)\n",
    "    return {\"columns\": recalled_cols}\n",
    "\n",
    "\n",
    "# Node: Generate\n",
    "def generate(state):\n",
    "    query_body = state[\"query_body\"]\n",
    "    recalled_cols = state[\"columns\"]\n",
    "    tabler_results = nl2sql.predict(query_body, recalled_cols)\n",
    "    return {\"messages\": [AIMessage(content=tabler_results)]}\n",
    "\n",
    "\n",
    "# Node: Grade\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "# LLM with function call\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "def grade_documents(state):\n",
    "    question = state[\"query_body\"][\"query\"]\n",
    "    documents = state[\"columns\"]\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d['page_content']}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            continue\n",
    "    return {\"columns\": filtered_docs}\n",
    "\n",
    "\n",
    "#\n",
    "# @tool\n",
    "# class CompleteOrEscalate(BaseModel):\n",
    "#     \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog back to the main assistant,\n",
    "#     who can re-route the dialog based on the user's needs.\"\"\"\n",
    "#     class Config:\n",
    "#         schema_extra = {\n",
    "#             \"example 1\": {\n",
    "#                 \"cancel\": True,\n",
    "#                 \"reason\": \"I have fully completed the task.\",\n",
    "#             },\n",
    "#             \"example 2\": {\n",
    "#                 \"cancel\": False,\n",
    "#                 \"reason\": \"I need to get model names of cleaning machines to complete the task.\",\n",
    "#             },\n",
    "#         }\n",
    "#     cancel: bool = Field(description=\"If the current task should be canceled.\")\n",
    "#     reason: str = Field(description=\"reason for cancelling or not\")\n",
    "#\n",
    "#\n",
    "# # Table Searching Assistant\n",
    "# table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\n",
    "#             \"system\",\n",
    "#             \"You are a specialized assistant for searching table with the fetch_table tool about parameters \\\n",
    "#             of cleaning machines. \"\n",
    "#             \"To use the fetch_table tool, directly send user query as input to it, and don't make any language \\\n",
    "#             translations or rephrases. \"\n",
    "#             \"To use the fetch_table tool, check out if the query contains model names of the cleaning machines \\\n",
    "#             (with pattern: alphabet followed by digits such as a10, G2, H1, m3, P10 and so on), otherwise\"\n",
    "#             ' use the tool \"CompleteOrEscalate\" to mark that you need that information. '\n",
    "#             'Whenever you have completed using fetch_table tool, please then use \"CompleteOrEscalate\" tool \\\n",
    "#             to mark that fetch has been completed. '\n",
    "#             \"If fetch_table tool is not appropriate for the query, then use the tool \"\n",
    "#             ' \"CompleteOrEscalate\" to send the dialog back. '\n",
    "#             'Do not waste the user\\'s time. Do not make up invalid tools or functions.',\n",
    "#         ),\n",
    "#         (\"placeholder\", \"{messages}\"),\n",
    "#     ]\n",
    "# )\n",
    "# llm = AzureChatOpenAI(\n",
    "#     api_version=\"2024-02-15-preview\",\n",
    "#     azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "#     api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "#     deployment_name=\"gpt-4-8k\",\n",
    "# )\n",
    "# table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "#      [CompleteOrEscalate, fetch_table]\n",
    "# )\n",
    "\n",
    "\n",
    "# Edge: Route question\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to search_table or else.\"\"\"\n",
    "    datasource: Literal[\"search_table\", \"else\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to search_table or else.\",\n",
    "    )\n",
    "# LLM with function call\n",
    "llm_router = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "structured_llm_router = llm_router.with_structured_output(RouteQuery)\n",
    "# Prompt\n",
    "system = \"\"\"You are a specialized assistant for searching table about parameters \\\n",
    "of cleaning machines. If the query is appropriate for your specialty, route it to \\\n",
    "search_table, otherwise choose else.\"\"\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router\n",
    "def route_question(state):\n",
    "    question = state[\"messages\"][-1].content\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.datasource == \"search_table\":\n",
    "        print(\"relevant\")\n",
    "        return \"search_table\"\n",
    "    else:\n",
    "        print(\"irrelevant\")\n",
    "        return END\n",
    "\n",
    "\n",
    "# Edge: Decide to generate\n",
    "def decide_to_generate(state):\n",
    "    filtered_documents = state[\"columns\"]\n",
    "    if not filtered_documents:\n",
    "        return END\n",
    "    else:\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "# Begin of Graph\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    query_body: dict\n",
    "    columns: List[dict]\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"get_keywords\", get_keywords)  # web search\n",
    "workflow.add_node(\"retrieve_documents\", retrieve_documents)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "\n",
    "# Build graph\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"search_table\": \"get_keywords\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"get_keywords\", \"retrieve_documents\")\n",
    "workflow.add_edge(\"retrieve_documents\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"generate\": \"generate\",\n",
    "        END: END\n",
    "    },\n",
    ")\n",
    "\n",
    "# # Compile\n",
    "# table_agent = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "6195b766-098b-41b2-85f0-45256d4195ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "# Compile\n",
    "table_agent = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "e8b850b0-23e0-4e03-ba39-fa4f5226242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(table_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1f710bd2-ee57-408b-ba84-74e391f7c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ab5c77c0-8fe5-431d-a9c8-87f45aa54c99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[250], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m table_agent\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [user_input], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_body\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_input}}, config):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssistant:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'messages'"
     ]
    }
   ],
   "source": [
    "user_input = \"G20电源线多长\"\n",
    "for event in table_agent.stream({\"messages\": [user_input], \"query_body\": {\"query\": user_input}}, config):\n",
    "    for value in event.values():\n",
    "        print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "50f103dd-693d-46a9-b3c7-32262c25ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irrelevant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"你好\"\n",
    "list(table_agent.stream({\"messages\": [user_input]}, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "570b692f-bf91-45a7-83e3-fe121eca897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='G20电源线多长', id='d48eae5b-3f08-4017-a257-ae9c24a286ea'), AIMessage(content='| 商品型号 | 版本 | 电源线长 |\\n| --- | --- | --- |\\n| g20 | 标准版 | 180cm |\\n| g20 | 上下水版 | 180cm |', id='b1d64c6a-0e38-4132-aee6-117d85c355b6'), HumanMessage(content='你好', id='e83d2873-49fe-47f6-87a3-80f0ac0c0ad6')], 'query_body': {'query_cleaned': '电源线多长', 'query': 'G20电源线多长', 'labels': {'model': [{'word': 'g20', 'start': 0, 'end': 3}], 'cat': [{'word': 'sweeping', 'start': 0, 'end': 3}], 'error': [], 'entities': [{'word': '电源线', 'start': 3, 'end': 6}, {'word': '长', 'start': 7, 'end': 8}]}, 'top_n': 1}, 'columns': [{'entity': {'word': '电源线', 'start': 3, 'end': 6}, 'page_content': '电源线长', 'metadata': {'content': '电源线长', 'mopping': False, 'sweeping': True, 'washing': False}, 'score': 0.9701595902442932}]}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef36b39-e4a7-6f82-8006-dabda3d66cc6'}}, metadata={'source': 'loop', 'step': 6, 'writes': None}, created_at='2024-06-30T07:37:35.450232+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef36b39-d214-631f-8005-4152482c5ca5'}})"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_agent.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0f7643c0-864c-4f2b-8d19-f5814144131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "    dd: dict\n",
    "    cc: dict\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "67ac1bcc-075c-4ace-8a5a-da410b95f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "i = 0\n",
    "def add_fun(x, c):\n",
    "    if not x:\n",
    "        return {\"query\": 1}\n",
    "    else:\n",
    "        x[c] = 1\n",
    "        return x\n",
    "\n",
    "def chatbot(state: State):\n",
    "    global i\n",
    "    i += 1\n",
    "    dd = state[\"dd\"]\n",
    "    cc = state[\"cc\"]\n",
    "    if i < 3:\n",
    "        return {\"messages\": [llm.invoke(state[\"messages\"])], \"dd\": add_fun(dd, i), \"cc\": add_fun(cc, i)}\n",
    "    else:\n",
    "        return {\"messages\": [llm.invoke(state[\"messages\"])], \"dd\": add_fun(dd, i)}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ccda61a9-b208-466d-a0eb-3891c5c3124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3dc4983e-601c-4526-9682-d81a98f3eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e144b03c-ea10-47aa-b8a2-a922368986c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "caeffab8-c723-4978-834b-5aca479ce8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "fae52bf4-2bcb-4cb5-90db-7186c881c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1b4e7383-66ea-48a2-8a84-2732688ac071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chatbot': {'messages': [AIMessage(content='你好！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 9, 'total_tokens': 27}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-1b6c94bc-e961-4dfd-b3d0-885062e8c663-0', usage_metadata={'input_tokens': 9, 'output_tokens': 18, 'total_tokens': 27})],\n",
       "   'dd': {'query': 1},\n",
       "   'cc': {'query': 1}}}]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"你好\"\n",
    "list(graph.stream({\"messages\": (\"user\", user_input)}, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8b3c9623-7856-4a57-a36a-2ebb3b1e60dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 好的，如果你有任何问题，随时向我提问。祝你有个愉快的一天！\n"
     ]
    }
   ],
   "source": [
    "user_input = \"暂时没事了\"\n",
    "for event in graph.stream({\"messages\": (\"user\", user_input)}, config):\n",
    "    for value in event.values():\n",
    "        print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a5a9c9da-2643-4e6b-957a-15d74db632b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='你好', id='5e9091e6-9f14-4d3a-9f45-2c1b477c022d'), AIMessage(content='你好！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 9, 'total_tokens': 27}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-1b6c94bc-e961-4dfd-b3d0-885062e8c663-0', usage_metadata={'input_tokens': 9, 'output_tokens': 18, 'total_tokens': 27})], 'dd': {'query': 1}, 'cc': {'query': 1}}, next=(), config={'configurable': {'thread_id': '1', 'thread_ts': '1ef36afe-a559-6c99-8001-68983f9e1054'}}, metadata={'source': 'loop', 'step': 1, 'writes': {'chatbot': {'messages': [AIMessage(content='你好！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 9, 'total_tokens': 27}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-1b6c94bc-e961-4dfd-b3d0-885062e8c663-0', usage_metadata={'input_tokens': 9, 'output_tokens': 18, 'total_tokens': 27})], 'dd': {'query': 1}, 'cc': {'query': 1}}}}, created_at='2024-06-30T07:11:05.043009+00:00', parent_config={'configurable': {'thread_id': '1', 'thread_ts': '1ef36afe-92b2-637d-8000-3d226e21815e'}})"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b18a348f-7609-495b-8e19-a44132324571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='你好', id='b8d13a29-862c-4208-ad0d-6c808b0427ff'),\n",
       "  AIMessage(content='你好！有什么我可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 9, 'total_tokens': 27}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-0fd4b6fc-2e3b-4a1a-9450-37b0d170a057-0', usage_metadata={'input_tokens': 9, 'output_tokens': 18, 'total_tokens': 27}),\n",
       "  HumanMessage(content='我说了什么', id='59cf5639-4016-4b42-9abc-58ca8be722fb'),\n",
       "  AIMessage(content='你问我：“我说了什么”。之前你跟我打招呼说了“你好”。', response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 41, 'total_tokens': 69}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-bd592ef5-fe91-4980-b9ce-29623c39568b-0', usage_metadata={'input_tokens': 41, 'output_tokens': 28, 'total_tokens': 69}),\n",
       "  HumanMessage(content='好的', id='02643dde-b926-42ce-9beb-4f93d22c5265'),\n",
       "  AIMessage(content='好的，如果你有任何其他问题，随时向我提问。', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 79, 'total_tokens': 98}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-654c3434-acd8-425c-9845-cfbb7bd4609e-0', usage_metadata={'input_tokens': 79, 'output_tokens': 19, 'total_tokens': 98}),\n",
       "  HumanMessage(content='暂时没事了', id='e3c9ecd5-f2a1-4521-9fbc-69787cf6d84e'),\n",
       "  AIMessage(content='好的，如果你有任何问题，随时向我提问。祝你有个愉快的一天！', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 112, 'total_tokens': 143}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-b832f843-211d-41ea-9310-31b5f1c55af8-0', usage_metadata={'input_tokens': 112, 'output_tokens': 31, 'total_tokens': 143})],\n",
       " 'dd': {'query': 1, '2': 1, '3': 1, '4': 1},\n",
       " 'cc': {'query': 1, '2': 1}}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6157b5f8-4385-4003-8971-401793438544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188ed8e-cfb1-41c5-afa1-5af58a220a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a80a7228-9bfa-47c6-bb97-77933db89ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def fetch_table(request: str) -> str:\n",
    "    \"\"\"Consult a table about parameters of clearning machines according to the query,\n",
    "    and return the results.\"\"\"\n",
    "    return \"\"\n",
    "\n",
    "@tool\n",
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog back to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example 1\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to get model names of cleaning machines to complete the task.\",\n",
    "            },\n",
    "        }\n",
    "    cancel: bool = Field(description=\"If the current task should be canceled.\")\n",
    "    reason: str = Field(description=\"reason for cancelling or not\")\n",
    "\n",
    "\n",
    "# Table Searching Assistant\n",
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for searching table with the fetch_table tool about parameters \\\n",
    "            of cleaning machines. \"\n",
    "            \"To use the fetch_table tool, directly send user query as input to it, and don't make any language \\\n",
    "            translations or rephrases. \"\n",
    "            \"To use the fetch_table tool, check out if the query contains model names of the cleaning machines \\\n",
    "            (with pattern: alphabet followed by digits such as a10, G2, H1, m3, P10 and so on), otherwise\"\n",
    "            ' use the tool \"CompleteOrEscalate\" to mark that you need that information. '\n",
    "            'Whenever you have completed using fetch_table tool, please then use \"CompleteOrEscalate\" tool \\\n",
    "            to mark that fetch has been completed. '\n",
    "            \"If fetch_table tool is not appropriate for the query, then use the tool \"\n",
    "            ' \"CompleteOrEscalate\" to send the dialog back. '\n",
    "            'Do not waste the user\\'s time. Do not make up invalid tools or functions.',\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "table_searching_runnable = create_tool_calling_agent(llm, [CompleteOrEscalate, fetch_table], table_searching_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8acbceb-aa8b-4843-b8da-627b4d3bda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=table_searching_runnable, tools=[CompleteOrEscalate, fetch_table], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5e4165c-7d52-4ca9-aace-1232575f780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CompleteOrEscalate` with `{'cancel': True, 'reason': \"The input doesn't contain a valid query related to cleaning machine parameters or model names. The language used is also not English.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mcancel=True reason=\"The input doesn't contain a valid query related to cleaning machine parameters or model names. The language used is also not English.\"\u001b[0m\u001b[32;1m\u001b[1;3mI'm sorry, but I can only assist with queries related to cleaning machine parameters. Could you please provide the model name or other specific details about the cleaning machine?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['春眠不觉晓'],\n",
       " 'output': \"I'm sorry, but I can only assist with queries related to cleaning machine parameters. Could you please provide the model name or other specific details about the cleaning machine?\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\": [\"春眠不觉晓\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1e515-48d2-405f-bee0-6d34c891cfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3abd9985-4e7e-4739-aa94-f761c8267546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "api_version=\"2024-02-15-preview\",\n",
    "azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "deployment_name=\"gpt-4-8k\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6f295a1-82e0-4db5-b187-a1714440c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += \"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason! You are one of the following team members: {team_members}.\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [\n",
    "                        {\"enum\": options},\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dd74764-4e94-4c2f-b98f-142fdc560b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_agent = create_team_supervisor(\n",
    "    llm,\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  Search, WebScraper. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\",\n",
    "    [\"Search\", \"WebScraper\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0286d16-c1f2-4cc3-a28e-3a55d7f81ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next': 'Search'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor_agent.invoke({\"messages\": [\"when is Taylor Swift's next tour?\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f312856-de8d-475d-96a3-3b5da64cfba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe13070-5a03-4b14-a587-1e814d1e13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "encoder = HuggingFaceEmbeddings(model_name=\"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\", \n",
    "                                   encode_kwargs = {'normalize_embeddings': True},\n",
    "                                   model_kwargs={'device': 'cuda:0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318b3d60-f0a8-41b2-ae13-bb5f1357c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "schema_set = [\"你好\", \"你好啊\", \"你太好了\"]\n",
    "doc_splits = [Document(page_content=line, metadata={\"id\": id}) for id, line in enumerate(schema_set)]\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma1\",\n",
    "    embedding=encoder,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b25e3a-527f-494e-8f11-0c0f203bddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever\",\n",
    "    'If the question has \"哼哼\", search and return relevant key words',\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d28d316-34a6-4728-9aa2-918f004d308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3300a2e3-006b-45fc-83a3-710c6ac91f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "\n",
    "    # Data model\n",
    "    class grade(BaseModel):\n",
    "        \"\"\"Binary score for relevance check.\"\"\"\n",
    "\n",
    "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "\n",
    "    # LLM\n",
    "    model = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    "    )\n",
    "\n",
    "    # LLM with tool and validation\n",
    "    llm_with_tool = model.with_structured_output(grade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "        Here is the user question: {question} \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm_with_tool\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "\n",
    "    score = scored_result.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT---\")\n",
    "        return \"generate\"\n",
    "\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "        print(score)\n",
    "        return \"rewrite\"\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def agent(state):\n",
    "    \"\"\"\n",
    "    Invokes the agent model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    "    )\n",
    "    model = model.bind_tools(tools)\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    "    )\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    "    )\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d23995-81ed-40fe-a307-4690c5b69e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(\"agent\", agent)  # agent\n",
    "retrieve = ToolNode([retriever_tool])\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    # Assess agent decision\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "# Compile graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "# Compile\n",
    "graph = workflow.compile(checkpointer=memory,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b37fbae1-30f4-4967-b0aa-c2716b348470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b0a409-a447-4c07-9e73-b1f5693f5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # The passenger_id is used in our flight tools to\n",
    "        # fetch the user's flight informatio\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": \"198197a5-c74c-463d-8312-ded3f1d94479\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd9b8a21-5255-4204-86ed-e3234f066517",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"哼哼\"),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20b01a3-b774-4dab-9391-5b397ab7eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Output from node 'agent':\"\n",
      "'---'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YQxnkj5JDjLYS1SVZWWErLTq', 'function': {'arguments': '{\\n  \"query\": \"哼哼\"\\n}', 'name': 'retriever'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 126, 'total_tokens': 145}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-4c55d57c-d26d-4900-9492-762be96080c7-0', tool_calls=[{'name': 'retriever', 'args': {'query': '哼哼'}, 'id': 'call_YQxnkj5JDjLYS1SVZWWErLTq'}], usage_metadata={'input_tokens': 126, 'output_tokens': 19, 'total_tokens': 145})]}\n",
      "'\\n---\\n'\n",
      "\"Output from node 'retrieve':\"\n",
      "'---'\n",
      "{ 'messages': [ ToolMessage(content='你好啊\\n\\n你好\\n\\n你太好了', name='retriever', tool_call_id='call_YQxnkj5JDjLYS1SVZWWErLTq')]}\n",
      "'\\n---\\n'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "for output in graph.stream(inputs, config):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da330126-4022-4314-b366-0f5b1509476b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你好'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f479c684-97fc-437a-b9ec-74949f588160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_AOzz4Kuq316jmitDaKx3UZR8', 'function': {'arguments': '{\\n  \"query\": \"你好\"\\n}', 'name': 'retriever'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 65, 'total_tokens': 82}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run-e8d1a7ce-85db-4c61-82c1-484f390760ae-0', tool_calls=[{'name': 'retriever', 'args': {'query': '你好'}, 'id': 'call_AOzz4Kuq316jmitDaKx3UZR8'}], usage_metadata={'input_tokens': 65, 'output_tokens': 17, 'total_tokens': 82})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"messages\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "490bb4d1-e59f-4e52-b691-c305ce717e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='你好\\n\\n你好啊\\n\\n你太好了', name='retriever', id='b14ee807-6ee7-49db-bb1d-ac706140aee4', tool_call_id='call_AOzz4Kuq316jmitDaKx3UZR8')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56fac910-fdd0-4730-87f6-b3180d524890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个\n",
      "多行字符串，\n",
      "但是在打印时，会是一个连续的字符串。\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"这是一个\n",
    "多行字符串，\n",
    "但是在打印时，会\\\n",
    "是一个连续的字符串。\"\"\"\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5b2499f-ae4c-4ebf-b741-77e1054f7f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这是一个\\n多行字符串，\\n但是在打印时，会是一个连续的字符串。'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c241835-3f88-496d-8880-31a5bf89ebd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28e15a-e0a8-4faf-8115-915cf8e7b536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f05c958-683f-4ea4-83da-af09069a11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide your TAVILY_API_KEY ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1416956d-4127-4d57-9b7b-ec090770ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import QAPineline, NL2SQLPineline\n",
    "from vector_db import ChromaDB\n",
    "from search_engine import QASearchEngine, VectorSim, QAVectorDBSearchEngine\n",
    "from find_keywords import LabellerByRules, LabellerByRulesWithPos\n",
    "from recall import RecallBySearchEngine\n",
    "from nl2sql import SimpleLookup\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b43b8ea0-55ae-4014-a7b1-2fb55726173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_config = {\n",
    "    \"class\": LabellerByRulesWithPos,\n",
    "    \"config\": {\n",
    "        \"dim_df_path\": \"data/dim_df20240619.csv\",\n",
    "        \"model_col\": (\"model\", \"model\"),\n",
    "        \"cat_col\": (\"cat_cn\", \"cat\"),\n",
    "        \"error_col\": (\"error\", \"error\"),\n",
    "        \"ner_model_path\": \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "recall_config = {\n",
    "    \"class\": RecallBySearchEngine,\n",
    "    \"config\": {\n",
    "        \"search_engine\": {\n",
    "            \"class\": QAVectorDBSearchEngine,\n",
    "            \"docs_path\": \"data/table_entity.csv\",\n",
    "            \"docs_col\": \"entity_name\",\n",
    "            \"ids_col\": \"ids\",\n",
    "            \"metadata_cols\": [\"sweeping\", \"washing\", \"mopping\", \"content\"],\n",
    "            \"collection_name\": \"table_entity\",\n",
    "            \"reset\": False,\n",
    "            \"encoder_path\": \"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\",\n",
    "            \"vector_db\": {\n",
    "                \"class\": ChromaDB,\n",
    "                \"host\": \"/data/dataset/kefu/chroma\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"top_n\": 1,\n",
    "}\n",
    "\n",
    "nl2sql_config = {\n",
    "    \"class\": SimpleLookup,\n",
    "    \"config\": {\n",
    "        \"db_absolute_path\": \"/root/PycharmProjects/rockchat/data/model_params.db\",\n",
    "        \"reset\": False,\n",
    "        \"df_path\": \"/root/PycharmProjects/rockchat/data/model_params20240620.csv\",\n",
    "        \"table_name\": \"model_params20240620\",\n",
    "        \"output_type\": \"markdown\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pipeline_config = {\n",
    "    \"router\": router_config,\n",
    "    \"recall\": recall_config,\n",
    "    \"nl2sql\": nl2sql_config,\n",
    "}\n",
    "\n",
    "nl2sql_pipeline = NL2SQLPineline(pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc4161b5-4170-4fa8-ae95-855269aaad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fetch_table(query: str) -> str:\n",
    "    \"\"\"Consult a table about model parameters according to the query,\n",
    "    and return the results.\"\"\"\n",
    "    results = nl2sql_pipeline.query(query)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0b616e0-be8f-4a32-9735-65d1664ae813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"fetch_table\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a711ab47-b947-4e30-b6a5-935a4fdd0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c275b61a-b326-42ef-9bb1-62b7ad1bd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteOrEscalate(BaseModel):\n",
    "    \"\"\"A tool to mark the current task as completed and/or to escalate control of the dialog to the main assistant,\n",
    "    who can re-route the dialog based on the user's needs.\"\"\"\n",
    "\n",
    "    cancel: bool = True\n",
    "    reason: str\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"User changed their mind about the current task.\",\n",
    "            },\n",
    "            \"example 2\": {\n",
    "                \"cancel\": True,\n",
    "                \"reason\": \"I have fully completed the task.\",\n",
    "            },\n",
    "            \"example 3\": {\n",
    "                \"cancel\": False,\n",
    "                \"reason\": \"I need to search the table of model parameters to fetch more information.\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74fb87af-460a-477f-b021-6c5ed30638b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_searching_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for searching table about model parameters.\"\n",
    "            \"The primary assistant delegates work to you whenever the user needs information about model parameters.\"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \"\\n\\nUser query: {query}.\"\n",
    "            \"\\n\\nIf the user needs help, and none of your tools are appropriate for it, then\"\n",
    "            ' \"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.',\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "table_searching_runnable = table_searching_prompt | llm.bind_tools(\n",
    "    [fetch_table] + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Primary Assistant\n",
    "class ToTableSearchingAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to search table for model parameters.\"\"\"\n",
    "\n",
    "    request: str = Field(\n",
    "        description=\"model names must be included in the query before proceeding.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6078c-ba04-400a-bb8d-1266eee16a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db46ef-0f00-419a-a843-b68519a8bf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f3d1f-d382-424d-9875-895150f1e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_booking_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling flight updates. \"\n",
    "            \" The primary assistant delegates work to you whenever the user needs help updating their bookings. \"\n",
    "            \"Confirm the updated flight details with the customer and inform them of any additional fees. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\n\\nCurrent user flight information:\\n\\n{user_info}\\n\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            \"\\n\\nIf the user needs help, and none of your tools are appropriate for it, then\"\n",
    "            ' \"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.',\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "update_flight_safe_tools = [search_flights]\n",
    "update_flight_sensitive_tools = [update_ticket_to_new_flight, cancel_ticket]\n",
    "update_flight_tools = update_flight_safe_tools + update_flight_sensitive_tools\n",
    "update_flight_runnable = flight_booking_prompt | llm.bind_tools(\n",
    "    update_flight_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Hotel Booking Assistant\n",
    "book_hotel_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling hotel bookings. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help booking a hotel. \"\n",
    "            \"Search for available hotels based on the user's preferences and confirm the booking details with the customer. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            '\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"CompleteOrEscalate\" the dialog to the host assistant.'\n",
    "            \" Do not waste the user's time. Do not make up invalid tools or functions.\"\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'what's the weather like this time of year?'\\n\"\n",
    "            \" - 'nevermind i think I'll book separately'\\n\"\n",
    "            \" - 'i need to figure out transportation while i'm there'\\n\"\n",
    "            \" - 'Oh wait i haven't booked my flight yet i'll do that first'\\n\"\n",
    "            \" - 'Hotel booking confirmed'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "book_hotel_safe_tools = [search_hotels]\n",
    "book_hotel_sensitive_tools = [book_hotel, update_hotel, cancel_hotel]\n",
    "book_hotel_tools = book_hotel_safe_tools + book_hotel_sensitive_tools\n",
    "book_hotel_runnable = book_hotel_prompt | llm.bind_tools(\n",
    "    book_hotel_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Car Rental Assistant\n",
    "book_car_rental_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling car rental bookings. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help booking a car rental. \"\n",
    "            \"Search for available car rentals based on the user's preferences and confirm the booking details with the customer. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            \"\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"\n",
    "            '\"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'what's the weather like this time of year?'\\n\"\n",
    "            \" - 'What flights are available?'\\n\"\n",
    "            \" - 'nevermind i think I'll book separately'\\n\"\n",
    "            \" - 'Oh wait i haven't booked my flight yet i'll do that first'\\n\"\n",
    "            \" - 'Car rental booking confirmed'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "book_car_rental_safe_tools = [search_car_rentals]\n",
    "book_car_rental_sensitive_tools = [\n",
    "    book_car_rental,\n",
    "    update_car_rental,\n",
    "    cancel_car_rental,\n",
    "]\n",
    "book_car_rental_tools = book_car_rental_safe_tools + book_car_rental_sensitive_tools\n",
    "book_car_rental_runnable = book_car_rental_prompt | llm.bind_tools(\n",
    "    book_car_rental_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "# Excursion Assistant\n",
    "\n",
    "book_excursion_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a specialized assistant for handling trip recommendations. \"\n",
    "            \"The primary assistant delegates work to you whenever the user needs help booking a recommended trip. \"\n",
    "            \"Search for available trip recommendations based on the user's preferences and confirm the booking details with the customer. \"\n",
    "            \"If you need more information or the customer changes their mind, escalate the task back to the main assistant.\"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" Remember that a booking isn't completed until after the relevant tool has successfully been used.\"\n",
    "            \"\\nCurrent time: {time}.\"\n",
    "            '\\n\\nIf the user needs help, and none of your tools are appropriate for it, then \"CompleteOrEscalate\" the dialog to the host assistant. Do not waste the user\\'s time. Do not make up invalid tools or functions.'\n",
    "            \"\\n\\nSome examples for which you should CompleteOrEscalate:\\n\"\n",
    "            \" - 'nevermind i think I'll book separately'\\n\"\n",
    "            \" - 'i need to figure out transportation while i'm there'\\n\"\n",
    "            \" - 'Oh wait i haven't booked my flight yet i'll do that first'\\n\"\n",
    "            \" - 'Excursion booking confirmed!'\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "\n",
    "book_excursion_safe_tools = [search_trip_recommendations]\n",
    "book_excursion_sensitive_tools = [book_excursion, update_excursion, cancel_excursion]\n",
    "book_excursion_tools = book_excursion_safe_tools + book_excursion_sensitive_tools\n",
    "book_excursion_runnable = book_excursion_prompt | llm.bind_tools(\n",
    "    book_excursion_tools + [CompleteOrEscalate]\n",
    ")\n",
    "\n",
    "\n",
    "# Primary Assistant\n",
    "class ToFlightBookingAssistant(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle flight updates and cancellations.\"\"\"\n",
    "\n",
    "    request: str = Field(\n",
    "        description=\"Any necessary followup questions the update flight assistant should clarify before proceeding.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ToBookCarRental(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle car rental bookings.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants to rent a car.\"\n",
    "    )\n",
    "    start_date: str = Field(description=\"The start date of the car rental.\")\n",
    "    end_date: str = Field(description=\"The end date of the car rental.\")\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the car rental.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"location\": \"Basel\",\n",
    "                \"start_date\": \"2023-07-01\",\n",
    "                \"end_date\": \"2023-07-05\",\n",
    "                \"request\": \"I need a compact car with automatic transmission.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class ToHotelBookingAssistant(BaseModel):\n",
    "    \"\"\"Transfer work to a specialized assistant to handle hotel bookings.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants to book a hotel.\"\n",
    "    )\n",
    "    checkin_date: str = Field(description=\"The check-in date for the hotel.\")\n",
    "    checkout_date: str = Field(description=\"The check-out date for the hotel.\")\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the hotel booking.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"location\": \"Zurich\",\n",
    "                \"checkin_date\": \"2023-08-15\",\n",
    "                \"checkout_date\": \"2023-08-20\",\n",
    "                \"request\": \"I prefer a hotel near the city center with a room that has a view.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "class ToBookExcursion(BaseModel):\n",
    "    \"\"\"Transfers work to a specialized assistant to handle trip recommendation and other excursion bookings.\"\"\"\n",
    "\n",
    "    location: str = Field(\n",
    "        description=\"The location where the user wants to book a recommended trip.\"\n",
    "    )\n",
    "    request: str = Field(\n",
    "        description=\"Any additional information or requests from the user regarding the trip recommendation.\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"location\": \"Lucerne\",\n",
    "                \"request\": \"The user is interested in outdoor activities and scenic views.\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# The top-level assistant performs general Q&A and delegates specialized tasks to other assistants.\n",
    "# The task delegation is a simple form of semantic routing / does simple intent detection\n",
    "# llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\", temperature=1)\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for Swiss Airlines. \"\n",
    "            \"Your primary role is to search for flight information and company policies to answer customer queries. \"\n",
    "            \"If a customer requests to update or cancel a flight, book a car rental, book a hotel, or get trip recommendations, \"\n",
    "            \"delegate the task to the appropriate specialized assistant by invoking the corresponding tool. You are not able to make these types of changes yourself.\"\n",
    "            \" Only the specialized assistants are given permission to do this for the user.\"\n",
    "            \"The user is not aware of the different specialized assistants, so do not mention them; just quietly delegate through function calls. \"\n",
    "            \"Provide detailed information to the customer, and always double-check the database before concluding that information is unavailable. \"\n",
    "            \" When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \" If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\n\\nCurrent user flight information:\\n\\n{user_info}\\n\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ").partial(time=datetime.now())\n",
    "primary_assistant_tools = [\n",
    "    TavilySearchResults(max_results=1),\n",
    "    search_flights,\n",
    "    lookup_policy,\n",
    "]\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "    primary_assistant_tools\n",
    "    + [\n",
    "        ToFlightBookingAssistant,\n",
    "        ToBookCarRental,\n",
    "        ToHotelBookingAssistant,\n",
    "        ToBookExcursion,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e69b3-4917-4cda-8ad9-5f4b6862becb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9e3e5-5d94-423c-8372-c78921c3cc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18ce80-76ab-44b8-945e-5af7819bafa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794644d-ce52-4083-aaa1-b2895c71eeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd801bb2-88c7-4813-ba6a-88adeb6b6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "def update_dialog_stack(left: list[str], right: Optional[str]) -> list[str]:\n",
    "    \"\"\"Push or pop the state.\"\"\"\n",
    "    if right is None:\n",
    "        return left\n",
    "    if right == \"pop\":\n",
    "        return left[:-1]\n",
    "    return left + [right]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    dialog_state: Annotated[\n",
    "        list[\n",
    "            Literal[\n",
    "                \"assistant\",\n",
    "                \"update_flight\",\n",
    "                \"book_car_rental\",\n",
    "                \"book_hotel\",\n",
    "                \"book_excursion\",\n",
    "            ]\n",
    "        ],\n",
    "        update_dialog_stack,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fdab9e-298b-4abe-a55e-47d42f8c4ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dd8ac4-7757-47fb-9705-98fdd92548cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f106357-df52-4d62-b89a-f73db75b5bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32234b06-ccf6-4651-a14d-e1406e1b8c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038948e7-0fa9-4f9b-b4f4-9dfa15204b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f316fd-fd2a-4f5e-b828-96a9192317f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdae8bb-6b4c-4f5c-b172-85cd1ce6007f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e70554d-9e0a-43bf-9cf3-60e89c056849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30ac43-1f7e-46c2-b0f7-14afec06f616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78e46d-8cd2-48ec-ab6f-78804b42fe51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a784cf50-b30b-46dc-95cb-9a58ce5bb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.messages import BaseMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e951773-e524-46fc-8585-70fa3f545d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a799be40-ac45-4b60-8afa-beb5bb8fa6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"Table in SQL database.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of table in SQL database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd7c697a-9522-4003-82ca-e84a30a99883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: https://python.langchain.com/docs/modules/model_io/chat/structured_output/Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.https://python.langchain.com/docs/use_cases/extraction/.with_structured_output does not currently support a list of pydantic schemas. If this is a blocker or if you notice other issues, please provide feedback here:https://github.com/langchain-ai/langchain/discussions/18154\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Table(name='Music')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"\"\"Return the names of the SQL tables that are relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "Music\n",
    "Business\"\"\"\n",
    "category_chain = create_extraction_chain_pydantic(Table, llm, system_message=system)\n",
    "category_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c4d9f12-3f1c-4872-a31d-7960265a19dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Album', 'Artist', 'Genre', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_tables(categories: List[Table]) -> List[str]:\n",
    "    tables = []\n",
    "    for category in categories:\n",
    "        if category.name == \"Music\":\n",
    "            tables.extend(\n",
    "                [\n",
    "                    \"Album\",\n",
    "                    \"Artist\",\n",
    "                    \"Genre\",\n",
    "                    \"MediaType\",\n",
    "                    \"Playlist\",\n",
    "                    \"PlaylistTrack\",\n",
    "                    \"Track\",\n",
    "                ]\n",
    "            )\n",
    "        elif category.name == \"Business\":\n",
    "            tables.extend([\"Customer\", \"Employee\", \"Invoice\", \"InvoiceLine\"])\n",
    "    return tables\n",
    "\n",
    "\n",
    "table_chain = category_chain | get_tables  # noqa\n",
    "table_chain.invoke({\"input\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e469023e-8a7d-4152-86de-654e8fd86ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Convert \"question\" key to the \"input\" key expected by current table_chain.\n",
    "table_chain = {\"input\": itemgetter(\"question\")} | table_chain\n",
    "# Set table_names_to_use using table_chain.\n",
    "full_chain = RunnablePassthrough.assign(table_names_to_use=table_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4462e249-4f0c-4c2e-923a-b8fae577c73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are all the genres of Alanis Morisette songs',\n",
       " 'table_names_to_use': ['Album',\n",
       "  'Artist',\n",
       "  'Genre',\n",
       "  'MediaType',\n",
       "  'Playlist',\n",
       "  'PlaylistTrack',\n",
       "  'Track']}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"What are all the genres of Alanis Morisette songs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b1dfbc2-1c57-4d2b-b9ae-a637c9cddbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e55fb-31d7-4209-8b00-eaa70a3758d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_table_info(self, table_names: Optional[List[str]] = None) -> str:\n",
    "        \"\"\"Get information about specified tables.\n",
    "\n",
    "        Follows best practices as specified in: Rajkumar et al, 2022\n",
    "        (https://arxiv.org/abs/2204.00498)\n",
    "\n",
    "        If `sample_rows_in_table_info`, the specified number of sample rows will be\n",
    "        appended to each table description. This can increase performance as\n",
    "        demonstrated in the paper.\n",
    "        \"\"\"\n",
    "        all_table_names = self.get_usable_table_names()\n",
    "        if table_names is not None:\n",
    "            missing_tables = set(table_names).difference(all_table_names)\n",
    "            if missing_tables:\n",
    "                raise ValueError(f\"table_names {missing_tables} not found in database\")\n",
    "            all_table_names = table_names\n",
    "\n",
    "        metadata_table_names = [tbl.name for tbl in self._metadata.sorted_tables]\n",
    "        to_reflect = set(all_table_names) - set(metadata_table_names)\n",
    "        if to_reflect:\n",
    "            self._metadata.reflect(\n",
    "                views=self._view_support,\n",
    "                bind=self._engine,\n",
    "                only=list(to_reflect),\n",
    "                schema=self._schema,\n",
    "            )\n",
    "\n",
    "        meta_tables = [\n",
    "            tbl\n",
    "            for tbl in self._metadata.sorted_tables\n",
    "            if tbl.name in set(all_table_names)\n",
    "            and not (self.dialect == \"sqlite\" and tbl.name.startswith(\"sqlite_\"))\n",
    "        ]\n",
    "\n",
    "        tables = []\n",
    "        for table in meta_tables:\n",
    "            if self._custom_table_info and table.name in self._custom_table_info:\n",
    "                tables.append(self._custom_table_info[table.name])\n",
    "                continue\n",
    "\n",
    "            # Ignore JSON datatyped columns\n",
    "            for k, v in table.columns.items():\n",
    "                if type(v.type) is NullType:\n",
    "                    table._columns.remove(v)\n",
    "\n",
    "            # add create table command\n",
    "            create_table = str(CreateTable(table).compile(self._engine))\n",
    "            table_info = f\"{create_table.rstrip()}\"\n",
    "            has_extra_info = (\n",
    "                self._indexes_in_table_info or self._sample_rows_in_table_info\n",
    "            )\n",
    "            if has_extra_info:\n",
    "                table_info += \"\\n\\n/*\"\n",
    "            if self._indexes_in_table_info:\n",
    "                table_info += f\"\\n{self._get_table_indexes(table)}\\n\"\n",
    "            if self._sample_rows_in_table_info:\n",
    "                table_info += f\"\\n{self._get_sample_rows(table)}\\n\"\n",
    "            if has_extra_info:\n",
    "                table_info += \"*/\"\n",
    "            tables.append(table_info)\n",
    "        tables.sort()\n",
    "        final_str = \"\\n\\n\".join(tables)\n",
    "        return final_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5c534-8e8f-43ef-acf7-49de9069e3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f292a22b-69d4-4e1b-ac2b-790fa4970c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef4df9-8829-425b-8c77-9810a48b3e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acb5ffa1-b7bb-43d6-8bc3-c63f0831981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sqlite_prompt = \"\"\"You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns from the candidate list [{col_list}] and the selection must be based on the meaning of input question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Be careful to not query for columns that do not exist in the candidate list. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_SUFFIX = \"\"\"Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "SQLITE_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\", \"col_list\"],\n",
    "    template=_sqlite_prompt + PROMPT_SUFFIX,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b3b2bfad-b0b4-4c80-a927-fa4ab9db64e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_chain \u001b[38;5;241m=\u001b[39m create_sql_query_chain(llm, \u001b[43mdb\u001b[49m, prompt\u001b[38;5;241m=\u001b[39mSQLITE_PROMPT)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "query_chain = create_sql_query_chain(llm, db, prompt=SQLITE_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff6001-8c69-4b58-8290-b85e06e036d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4922b8-942c-4cb5-803b-6b1821c27241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c5d4c-0216-4895-92c3-3205ab833e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c511f846-0e71-4df8-ab09-d590051670d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建AzureChatOpenAI实例\n",
    "chat = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1afed64-2c1a-4343-b4aa-52f776f02fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"In memory implementation of chat message history.\"\"\"\n",
    "\n",
    "    messages: List[BaseMessage] = Field(default_factory=list)\n",
    "\n",
    "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
    "        \"\"\"Add a list of messages to the store\"\"\"\n",
    "        self.messages.extend(messages)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e02967d-b083-4853-a1b3-27c4afaec2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce8d867f-dc80-45b0-9217-6af56226194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history_for_chain = ChatMessageHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c053108-3dd5-4378-8cf0-e33bb4de4887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_ephemeral_chat_history_for_chain.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "761b2d72-50b2-46e7-8e15-5646c8240409",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "403ded2a-2a44-43d5-81b6-6e63597ad1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa4142f9-22db-4eb8-a7c9-e275dd8fb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83ece750-eba2-4c97-9fcc-7e5f80f23794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 39, 'total_tokens': 46}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-8e929a4e-9cb6-4f0c-b297-209f0bf6450f-0', usage_metadata={'input_tokens': 39, 'output_tokens': 7, 'total_tokens': 46})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"Translate this sentence from English to French: I love programming.\"},\n",
    "    {\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae2feca6-4446-4781-87a0-4d0643627fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n",
       " AIMessage(content=\"J'aime la programmation.\", response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 39, 'total_tokens': 46}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-8e929a4e-9cb6-4f0c-b297-209f0bf6450f-0', usage_metadata={'input_tokens': 39, 'output_tokens': 7, 'total_tokens': 46})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff0fced2-7c34-4b19-bc49-619030e0db74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked me to translate the sentence \"I love programming\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 61, 'total_tokens': 78}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-5ffde32d-86d0-486b-a05b-f7f235ac2de2-0', usage_metadata={'input_tokens': 61, 'output_tokens': 17, 'total_tokens': 78})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"What did I just ask you?\"}, {\"configurable\": {\"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b3d984c-32bc-4050-8844-43773bcd9ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n",
       " AIMessage(content=\"J'aime la programmation.\", response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 39, 'total_tokens': 46}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-8e929a4e-9cb6-4f0c-b297-209f0bf6450f-0', usage_metadata={'input_tokens': 39, 'output_tokens': 7, 'total_tokens': 46}),\n",
       " HumanMessage(content='What did I just ask you?'),\n",
       " AIMessage(content='You asked me to translate the sentence \"I love programming\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 61, 'total_tokens': 78}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-5ffde32d-86d0-486b-a05b-f7f235ac2de2-0', usage_metadata={'input_tokens': 61, 'output_tokens': 17, 'total_tokens': 78})]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"1\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7da872f6-c6fe-4f45-83c4-ef7a8e13c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have real-time conversation history and the ability to recall past interactions. Therefore, I can't recall what your previous question was. Could you please repeat the question you want me to answer?\", response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 34, 'total_tokens': 78}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-867f8268-ba4e-4efa-8661-e77f793a3e6d-0', usage_metadata={'input_tokens': 34, 'output_tokens': 44, 'total_tokens': 78})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_message_history.invoke(\n",
    "    {\"input\": \"What did I just ask you?\"}, {\"configurable\": {\"session_id\": \"2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb5c213e-6e3e-42af-b79a-cb6aa8a43cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What did I just ask you?'),\n",
       " AIMessage(content=\"As an AI, I don't have real-time conversation history and the ability to recall past interactions. Therefore, I can't recall what your previous question was. Could you please repeat the question you want me to answer?\", response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 34, 'total_tokens': 78}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-867f8268-ba4e-4efa-8661-e77f793a3e6d-0', usage_metadata={'input_tokens': 34, 'output_tokens': 44, 'total_tokens': 78})]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"2\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3679cf-cd66-489d-bba6-b2de40893571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec0696-045a-4171-b35a-36c7073d1753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf2befd-60fe-420b-8aad-5f4377e0ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3d9b10-9299-4cb1-8fde-bb06f3dc904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant. Answer all questions to the best of your ability.'), HumanMessage(content='Translate this sentence from English to French: I love programming.'), AIMessage(content=\"J'adore la programmation.\"), HumanMessage(content='What did you just say?')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate this sentence from English to French: I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content=\"J'adore la programmation.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f10ff8d-0c9a-4ed2-bd2c-7d740c2fa821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.fake import FakeStreamingListLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.runnables import Runnable\n",
    "from operator import itemgetter\n",
    "\n",
    "prompt = (\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
    "    + \"{question}\"\n",
    ")\n",
    "llm = FakeStreamingListLLM(responses=[\"foo-lish\"])\n",
    "\n",
    "chain: Runnable = prompt | llm | {\"str\": StrOutputParser()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792a3d46-ebf1-4aa8-82e9-a2e30aaab477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a nice assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])\n",
       "| FakeStreamingListLLM(responses=['foo-lish'])\n",
       "| {\n",
       "    str: StrOutputParser()\n",
       "  }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8345a711-ef2c-4c30-8102-5971f935d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# We need a prompt that we can pass into an LLM to generate a transformed search query\n",
    "\n",
    "\n",
    "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "query_transforming_retriever_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "        # If only one message, then we just pass that message's content to retriever\n",
    "        (lambda x: x[\"messages\"][-1].content),\n",
    "    ),\n",
    "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
    "    query_transform_prompt | chat,\n",
    ").with_config(run_name=\"chat_retriever_chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4590f7b-1d77-4cb7-a085-8fadf6cde619",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_ephemeral_chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e952e558-ef6f-4c4a-a282-8eef3c04f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_ephemeral_chat_history.add_user_message(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcdffb5a-a3ca-47a3-b760-b4d452ba19cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how can langsmith help with testing?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_transforming_retriever_chain.invoke(\n",
    "    {\"messages\": demo_ephemeral_chat_history.messages},\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e337d0-7c97-45e4-88d5-635475a2f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e808a758-0cd5-41c4-b366-c2e5dead92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=\"/data/dataset/kefu/chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f33d501-4a1b-44df-8678-4efa004de758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=hello1), Collection(name=table_entity)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db2d0430-4499-43a5-aa0f-49a71b3f0bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "persistent_client.delete_collection(\"hello1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b57199f2-4756-48d6-a1a1-88de779385b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HuggingFaceEmbeddings(model_name=\"/data/dataset/huggingface/hub/bge-large-zh-v1.5\", \n",
    "                                   encode_kwargs = {'normalize_embeddings': True},\n",
    "                                   model_kwargs={'device': 'cuda:0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd82306-38d9-4627-a6a7-437c518ec5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f30fea-bc8c-4ee5-8c90-24bf8b6d02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('/data/dataset/huggingface/hub/bge-large-zh-v1.5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "74a95df6-8072-44fa-a336-f758ad90bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"平台ID\", \"商品id\", \"商品编码\", \"商品编号\", \"商品名字\", \"版本\", \"商品编辑号\", \"primary_key\"]\n",
    "store = Chroma.from_documents([Document(page_content=line, \n",
    "                                        metadata={\"id\": id, \"content\": line.lower()}\n",
    "                                       )\n",
    " for id, line in enumerate(docs)], embedding=encoder, collection_name=\"hello1\", client=persistent_client,\n",
    "                             collection_metadata={\"hnsw:space\": \"cosine\"}, ids=[str(i) for i in range(len(docs))],\n",
    "                              relevance_score_fn=lambda distance: 1.0 - distance / 2.0\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "41316179-a7bb-420b-bbf0-2c6d5fd8202d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='商品编码', metadata={'content': '商品编码', 'id': 2}),\n",
       "  0.5775375044254822),\n",
       " (Document(page_content='商品id', metadata={'content': '商品id', 'id': 1}),\n",
       "  0.5820137064834018)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search_with_score(\"平台\", k=10, \n",
    "                                   filter={\"id\": {\"$in\": [1, 2]}}, \n",
    "                                   # where_document={\"$contains\":\"ID\"}\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a8c2089-84d6-41ee-9183-d51688814d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa = store.as_retriever(search_type= \"similarity_score_threshold\", \n",
    "                        search_kwargs={\"score_threshold\": 0.00001, \"k\":10, \"filter\": {\"id\": {\"$in\": [0, 1, 2]}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "538efa18-ae9e-47f7-9cb6-63db5fd20fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 8, updating n_results = 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='商品id', metadata={'content': '商品id', 'id': 1}),\n",
       " Document(page_content='商品编码', metadata={'content': '商品编码', 'id': 2}),\n",
       " Document(page_content='平台ID', metadata={'content': '平台ID', 'id': 0})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.invoke(\"商品\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c470377b-b488-4dcd-9352-799fd4515968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f58eda7f940>, search_type='similarity_score_threshold', search_kwargs={'score_threshold': 0.01})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e63f336b-7416-4826-a0b1-3b59b35e2d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='商品名字', metadata={'id': 4}), 0.8752710846122631)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search_with_relevance_scores(\"商品\", k=1, \n",
    "                                   # filter={\"id\": 2}, \n",
    "                                   # where_document={\"$contains\":\"商品\"}\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c69f5e6f-96c4-4b7a-8d87-3c292d3835cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# 测试集处理及计算与正确qa的相似度\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ebda7341-13e5-4783-8fa5-a96670f706e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8752710781745208"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1-cosine_similarity(encoder.embed_query(\"商品\"), encoder.embed_query(\"商品名字\")))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff747a-921c-424c-8623-f30456fcc2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70049e1f-730d-4f44-aa16-5eeab6503677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7696d0f-36b0-4169-ac80-01331bb60f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2533e-892b-43ff-ab63-68a72f576c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c7ca0f90-2bfc-4b04-bd3b-8349d2f3c9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=hello1)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7c40e7a4-eb91-4a02-859a-ddf2ea5df1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_client.list_collections()[0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "26721492-6e35-4e09-a8f9-0559467503b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='商品名字', metadata={'id': 4}), 0.7775232756515339)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search_with_score(\"商品\", k=1, \n",
    "                                   # filter={\"id\": 2}, \n",
    "                                   # where_document={\"$contains\":\"商品\"}\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d8379494-38c4-4a02-b1ae-d8cb76046296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='商品名字', metadata={'id': 4}), 0.7775232756515339),\n",
       " (Document(page_content='商品id', metadata={'id': 1}), 0.8199618126485422),\n",
       " (Document(page_content='商品编号', metadata={'id': 3}), 0.8280622766192032)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search_with_score(\"商品\", k=3, \n",
    "                                   # filter={\"id\": 2}, \n",
    "                                   # where_document={\"$contains\":\"商品\"}\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5bc4458b-48bf-4945-af5c-51f5369bbcab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'dd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m商品\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;66;43;03m# filter={\"id\": 2}, \u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$contains\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m商品\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdd\u001b[49m  \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'dd'"
     ]
    }
   ],
   "source": [
    "store.similarity_search_with_score(\"商品\", k=1, \n",
    "                                   # filter={\"id\": 2}, \n",
    "                                   where_document={\"$contains\":\"商品\"}\n",
    "                                  )[0][0].dd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657657bd-335a-4437-b9b8-3a670d81af1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8d0d7d58-5029-4b22-95a9-83bae80b9114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search_with_score(\"商品\", k=3, \n",
    "                                   # filter={\"id\": 2}, \n",
    "                                   where_document={\"$contains\":\"ddd\"}\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a20aeaef-ff5b-4e9d-ac62-0764ea25676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(\n",
    "        name=\"hello\", # collection名称\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1627967-da31-404f-9adc-81eb0e9c44fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "941f7073-7055-4658-a7e3-58cc0b76f5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ec7fa2-ee91-4136-bda8-433202a4273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell LangChain to use our client and collection name\n",
    "db4 = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"hello\",\n",
    "    embedding_function=encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bcf6bf1-501a-48e2-abee-3403e75d25fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db4.similarity_search_with_score(\"商品\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b142c0-f48a-448d-b6e5-333915bbebf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='商品名字', metadata={'id': 4}), 0.7775232756515339),\n",
       " (Document(page_content='商品id', metadata={'id': 1}), 0.8199618126485422),\n",
       " (Document(page_content='商品分类', metadata={'id': 3}), 0.8444705972295098)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db4.similarity_search_with_score(\"商品\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1caad60-ae66-4b20-8d75-2da00d391d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db4.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a68b4c-b4b8-450b-b226-235f98070167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize the Chroma client\n",
    "chroma_client = Chroma()\n",
    "\n",
    "# List all collections\n",
    "collections = chroma_client._client.list_collections()\n",
    "for collection in collections:\n",
    "    chroma_client._client.delete_collection(collection.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ddbc2-6977-48ec-be63-c438441d6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collection = client.create_collection(\"my_collection\")\n",
    "for doc in docs:\n",
    "    collection.add(\n",
    "        ids=[str(uuid.uuid1())], metadatas=doc.metadata, documents=doc.page_content\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1885ed71-a6a8-4c02-aed5-873ff0d6df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# 创建连接\n",
    "conn = mysql.connector.connect(user='root', password='123456', host='192.168.111.48', database='test', port=3306)\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da873991-e9ee-44c4-999f-883fd1c691f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM test1 union select id from test1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93562a54-8c1b-4679-be3c-7b1c1108316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9191fd83-63f5-45c7-80b5-7726c2c3628b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jack',), (' ',), ('1',), ('2',)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "827c8b88-2af4-46bb-ab78-576122baf247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_substring_positions(a, b):\n",
    "    positions = []\n",
    "    for match in re.finditer(re.escape(b), a):\n",
    "        start = match.start()\n",
    "        end = match.end()\n",
    "        positions.append((start, end))\n",
    "    return positions\n",
    "\n",
    "# 示例用法\n",
    "a = \"  \\n我的A1 \\n扫地\\n人不工作了怎么办扫地器人不好扫地dfdf\"\n",
    "b = \"扫地机\"\n",
    "positions = find_substring_positions(a, b)\n",
    "print(positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c54eb4-9226-432e-8a98-3c70967df85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'扫地机'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[positions[0][0]:positions[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb2912c2-a6f6-4f9a-a881-36d5cda0980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'扫地机'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[positions[1][0]:positions[1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7ff688-7df1-4ce7-9c8e-36f52ffd09fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FAISS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m平台ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m商品id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m商品编码\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m商品分类\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m商品名字\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m版本\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m商品型号\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprimary_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m encoder \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/dataset/huggingface/hub/bge-large-zh-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                    encode_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[1;32m      4\u001b[0m                                    model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m----> 5\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_documents([Document(page_content\u001b[38;5;241m=\u001b[39mline, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mid\u001b[39m})\n\u001b[1;32m      6\u001b[0m  \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(docs)], embedding\u001b[38;5;241m=\u001b[39mencoder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FAISS' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = [\"平台ID\", \"商品id\", \"商品编码\", \"商品分类\", \"商品名字\", \"版本\", \"商品型号\", \"primary_key\"]\n",
    "encoder = HuggingFaceEmbeddings(model_name=\"/data/dataset/huggingface/hub/bge-large-zh-v1.5\", \n",
    "                                   encode_kwargs = {'normalize_embeddings': True},\n",
    "                                   model_kwargs={'device': 'cuda:0'})\n",
    "store = FAISS.from_documents([Document(page_content=line, metadata={\"id\": id})\n",
    " for id, line in enumerate(docs)], embedding=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "895de26a-1cf3-4de9-a07e-6fa42ccf9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7f77b04f65c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63115632-8a9f-4f0e-bf3a-877d803650d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='商品名字', metadata={'id': 4}), 0.5650778615247458)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.similarity_search_with_relevance_scores(\"商品分类\", k=3, filter=filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1aed8586-551b-4e29-9f31-681d998fd4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreRetrieverFilter(vectorstore=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfd47d59-6552-4e94-b1ce-a8cda6c879fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Collection.query() got an unexpected keyword argument 'fetch_k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/retrievers.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    244\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    248\u001b[0m         result,\n\u001b[1;32m    249\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/retrievers.py:242\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\n\u001b[1;32m    239\u001b[0m             query, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    244\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n",
      "Cell \u001b[0;32mIn[29], line 65\u001b[0m, in \u001b[0;36mVectorStoreRetrieverFilter._get_relevant_documents\u001b[0;34m(self, query, filter)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Only similarity search is implemented for now\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m         docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Filter is not provided\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:348\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[0;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    333\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:438\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 438\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__query_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/utils/utils.py:35\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     invalid_group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_groups[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m invalid_groups]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m     )\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:155\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[0;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Collection.query() got an unexpected keyword argument 'fetch_k'"
     ]
    }
   ],
   "source": [
    "filter = {\"id\": 4}\n",
    "index.get_relevant_documents(query=\"a\", filter=filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a893db60-5cdc-4318-8303-c4505ae2cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import AzureOpenAI\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a02cfeb-8eda-460a-b1f9-054235699ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQAFilter.from_chain_type(\n",
    "            llm=client,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=index,\n",
    "            # chain_type_kwargs=<some_kwargs>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08c9733a-8a5d-4aa3-8bdc-e4b2c604c947",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mfilter\u001b[39m \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mqa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m商品编码\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m context \n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m, in \u001b[0;36mRetrievalQAFilter._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question, \u001b[38;5;28mfilter\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:574\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    570\u001b[0m         _output_key\n\u001b[1;32m    571\u001b[0m     ]\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    575\u001b[0m         _output_key\n\u001b[1;32m    576\u001b[0m     ]\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:137\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    136\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 137\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_docs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother_keys\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:244\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m, {}\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/llm.py:293\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    101\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 103\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/llm.py:115\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    123\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/language_models/llms.py:597\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    591\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    595\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    596\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/language_models/llms.py:767\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    754\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    755\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m         )\n\u001b[1;32m    766\u001b[0m     ]\n\u001b[0;32m--> 767\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/language_models/llms.py:634\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    633\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    635\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/language_models/llms.py:621\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    613\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    618\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 621\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    629\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    630\u001b[0m         )\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_community/llms/openai.py:460\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    449\u001b[0m         {\n\u001b[1;32m    450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m         }\n\u001b[1;32m    458\u001b[0m     )\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# V1 client returns the response in an PyDantic object instead of\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# dict. For the transition period, we deep convert it to dict.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_community/llms/openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(llm, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/openai/resources/completions.py:516\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Completion \u001b[38;5;241m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_of\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mecho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/openai/_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1205\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1206\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1207\u001b[0m     )\n\u001b[0;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/openai/_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/openai/_base_client.py:988\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    985\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    987\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    991\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    992\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    995\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    996\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "filter = {\"id\": 2}\n",
    "context = qa({\"query\": \"商品编码\", \"filter\": None})\n",
    "context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c72c9c-9479-4a5c-90c5-a3c618862325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4eb381-fe53-417a-980c-d390e2a95988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "091e068a-523c-466c-b842-b30c9c5ef381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`run` supported with either positional arguments or keyword arguments but not both. Got args: ('帮我选择一个型号吧',) and kwargs: {'models': ['型号A', '型号B', '型号C']}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 44\u001b[0m\n\u001b[1;32m     36\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m     37\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[choose_model_tool],\n\u001b[1;32m     38\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     39\u001b[0m     agent_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-react-description\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 运行 agent\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m帮我选择一个型号吧\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m型号A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m型号B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m型号C\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:615\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but not both. Got args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `run` supported with either positional arguments or keyword arguments but not both. Got args: ('帮我选择一个型号吧',) and kwargs: {'models': ['型号A', '型号B', '型号C']}."
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import random\n",
    "\n",
    "# 定义自定义的 tool a\n",
    "def choose_model(models):\n",
    "    return random.choice(models)\n",
    "\n",
    "# 包装自定义的 tool a\n",
    "choose_model_tool = Tool(\n",
    "    name=\"choose_model\",\n",
    "    description=\"从型号列表中随机选择一个型号\",\n",
    "    func=choose_model\n",
    ")\n",
    "\n",
    "# 定义一个提示模板\n",
    "template = \"\"\"你是一个帮助用户选择型号的助手。\n",
    "用户: {input}\n",
    "助手:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "# 创建一个 AzureChatOpenAI 实例\n",
    "llm = azure_llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "# 创建一个 LLMChain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# 初始化 agent\n",
    "agent = initialize_agent(\n",
    "    tools=[choose_model_tool],\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 运行 agent\n",
    "response = agent.run(\"帮我选择一个型号吧\", models=[\"型号A\", \"型号B\", \"型号C\"])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5001d6da-11d8-4079-bb8c-315b01ef5ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`run` supported with either positional arguments or keyword arguments but not both. Got args: ('帮我选择一个型号吧',) and kwargs: {'models': ['型号A', '型号B', '型号C']}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 41\u001b[0m\n\u001b[1;32m     33\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m     34\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[choose_model_tool],\n\u001b[1;32m     35\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m     36\u001b[0m     agent_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-react-description\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 运行 agent\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m帮我选择一个型号吧\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m型号A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m型号B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m型号C\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:615\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but not both. Got args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `run` supported with either positional arguments or keyword arguments but not both. Got args: ('帮我选择一个型号吧',) and kwargs: {'models': ['型号A', '型号B', '型号C']}."
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import random\n",
    "\n",
    "# 定义自定义的 tool a\n",
    "def choose_model(models):\n",
    "    return random.choice(models)\n",
    "\n",
    "# 包装自定义的 tool a\n",
    "choose_model_tool = Tool(\n",
    "    name=\"choose_model\",\n",
    "    description=\"从型号列表中随机选择一个型号\",\n",
    "    func=choose_model\n",
    ")\n",
    "\n",
    "# 定义一个提示模板\n",
    "template = \"\"\"你是一个帮助用户选择型号的助手。\n",
    "用户: {input}\n",
    "助手:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "# 创建一个 AzureChatOpenAI 实例\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "# 初始化 agent\n",
    "agent = initialize_agent(\n",
    "    tools=[choose_model_tool],\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 运行 agent\n",
    "response = agent.run(\"帮我选择一个型号吧\", models=[\"型号A\", \"型号B\", \"型号C\"])\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cfa9e6b-51e4-4609-bf63-353de658a237",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`run` supported with either positional arguments or keyword arguments but not both. Got args: ('帮我选择一个型号吧',) and kwargs: {'models': ['型号A', '型号B', '型号C']}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m帮我选择一个型号吧\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m context \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m型号A\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m型号B\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m型号C\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m---> 43\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/chains/base.py:615\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 615\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but not both. Got args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `run` supported with either positional arguments or keyword arguments but not both. Got args: ('帮我选择一个型号吧',) and kwargs: {'models': ['型号A', '型号B', '型号C']}."
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import random\n",
    "\n",
    "# 定义自定义的 tool a\n",
    "def choose_model(models):\n",
    "    return random.choice(models)\n",
    "\n",
    "# 包装自定义的 tool a\n",
    "choose_model_tool = Tool(\n",
    "    name=\"choose_model\",\n",
    "    description=\"从型号列表中随机选择一个型号。输入是一个型号列表。\",\n",
    "    func=choose_model\n",
    ")\n",
    "\n",
    "# 定义一个提示模板\n",
    "template = \"\"\"你是一个帮助用户选择型号的助手。\n",
    "用户: {input}\n",
    "助手:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "# 创建一个 AzureChatOpenAI 实例\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "# 初始化 agent\n",
    "agent = initialize_agent(\n",
    "    tools=[choose_model_tool],\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 运行 agent\n",
    "user_input = \"帮我选择一个型号吧\"\n",
    "context = {\"models\": [\"型号A\", \"型号B\", \"型号C\"]}\n",
    "response = agent.run(user_input, **context)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "14788fa7-f164-4ee9-af76-cce7a5977f7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m CustomOutputParser()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# 创建AgentExecutor\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m \u001b[43mAgentExecutor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool_a\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# 测试多轮对话\u001b[39;00m\n\u001b[1;32m     65\u001b[0m conversation_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/pydantic/v1/main.py:1048\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m validator \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39m__pre_root_validators__:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1048\u001b[0m         input_data \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}, \u001b[38;5;28mset\u001b[39m(), ValidationError([ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY)], cls_)\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/agents/agent.py:1008\u001b[0m, in \u001b[0;36mAgentExecutor.validate_runnable_agent\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m(pre\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_runnable_agent\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert runnable to agent if passed in.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1008\u001b[0m     agent \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agent, Runnable):\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'agent'"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool, AgentOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import random\n",
    "\n",
    "# 定义随机选择型号的工具\n",
    "def select_model(model_list):\n",
    "    return random.choice(model_list)\n",
    "\n",
    "# 创建工具实例\n",
    "tool_a = Tool(\n",
    "    name=\"select_model_tool\",\n",
    "    func=select_model,\n",
    "    description=\"从型号列表中随机选择一个型号\",\n",
    ")\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "# 创建AzureChatOpenAI实例\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "# 定义Prompt模板\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input\", \"history\"],\n",
    "    template=\"\"\"\n",
    "    你是一个智能助手，可以进行多轮对话。\n",
    "    用户输入: {input}\n",
    "    对话历史: {history}\n",
    "    根据用户的输入和对话历史，判断是否需要从型号列表中选择一个型号。\n",
    "    如果需要，请调用select_model_tool并返回结果。\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 创建LLMChain\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# 定义输出解析器\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, text):\n",
    "        # 解析LLM的输出，判断是否需要调用工具\n",
    "        if \"调用select_model_tool\" in text:\n",
    "            return {\"tool\": \"select_model_tool\", \"action_input\": [\"型号1\", \"型号2\", \"型号3\"]}\n",
    "        return {\"tool\": None, \"action_input\": None}\n",
    "\n",
    "output_parser = CustomOutputParser()\n",
    "\n",
    "# 创建AgentExecutor\n",
    "agent_executor = AgentExecutor(\n",
    "    llm_chain=llm_chain,\n",
    "    tools=[tool_a],\n",
    "    output_parser=output_parser,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 测试多轮对话\n",
    "conversation_history = \"\"\n",
    "user_input = \"我需要一个新的型号，能帮我选一个吗？\"\n",
    "\n",
    "while user_input.lower() != \"退出\":\n",
    "    response = agent_executor.execute(input=user_input, history=conversation_history)\n",
    "    conversation_history += f\"\\n用户: {user_input}\\n助手: {response['output']}\"\n",
    "    print(f\"助手: {response['output']}\")\n",
    "    user_input = input(\"用户: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f9168-6835-4943-a369-99a8ab4037cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f085d14-a85a-4037-8084-31b18776b87d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\ncallbacks -> 0\n  instance of BaseCallbackHandler expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackHandler)\ncallbacks\n  instance of BaseCallbackManager expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackManager)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tools[result\u001b[38;5;241m.\u001b[39mtool]\u001b[38;5;241m.\u001b[39mrun(result\u001b[38;5;241m.\u001b[39mtool_input)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Define the chain\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOpenAIFunctionsAgentOutputParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mroute\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Invoke the chain with an initial input\u001b[39;00m\n\u001b[1;32m     97\u001b[0m result \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m上海的天气现在怎么样？\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     emit_warning()\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMChain\ncallbacks -> 0\n  instance of BaseCallbackHandler expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackHandler)\ncallbacks\n  instance of BaseCallbackManager expected (type=type_error.arbitrary_type; expected_arbitrary_type=BaseCallbackManager)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "from langchain.agents import tool\n",
    "import requests\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import datetime\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.agent import AgentFinish\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'\n",
    "\n",
    "# Create function descriptions\n",
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        get_current_temperature\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Define LLM\n",
    "model = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ").bind(functions=functions)\n",
    "\n",
    "# Create prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Create memory for multi-turn conversations\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)\n",
    "\n",
    "# Define the chain\n",
    "chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    output_parser=OpenAIFunctionsAgentOutputParser(),\n",
    "    callbacks=[route]\n",
    ")\n",
    "\n",
    "# Invoke the chain with an initial input\n",
    "result = chain.invoke({\"input\": \"上海的天气现在怎么样？\"})\n",
    "\n",
    "# For subsequent inputs, continue to use the same chain instance\n",
    "# result = chain.invoke({\"input\": \"明天的天气怎么样？\"})\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba639528-7ff5-460f-a0f2-6011cf4970bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da86997-bdc3-44be-bfd4-86c8ce747d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain with an initial input\n",
    "result = chain.invoke({\"input\": \"上海的天气现在怎么样？\"})\n",
    "\n",
    "# For subsequent inputs, continue to use the same chain instance\n",
    "# result = chain.invoke({\"input\": \"明天的天气怎么样？\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfae4f-ad78-481d-aac9-57d230a6a825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88eb7a1b-a3d7-4b17-b8a3-331739b53bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U python-dotenv\n",
    " \n",
    "import os\n",
    "\n",
    " \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "73ee3819-fc0a-4691-a876-b1e5eabbe819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search.name:search\n",
      "search.description:Search for weather online\n",
      "search.args:{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import tool\n",
    " \n",
    "#添加tool装饰器\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for weather online\"\"\"\n",
    "    return \"42f\"\n",
    " \n",
    "print(f\"search.name:{search.name}\")\n",
    "print(f\"search.description:{search.description}\")\n",
    "print(f\"search.args:{search.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b90a9af5-ea32-4b25-82a0-53bcd311b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search.args:{'query': {'title': 'Query', 'description': 'Thing to search for', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")\n",
    "        \n",
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for the weather online.\"\"\"\n",
    "    return \"42f\"\n",
    " \n",
    "print(f\"search.args:{search.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc4af57c-1868-4583-858e-cb455cfdfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import datetime\n",
    " \n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    " \n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    " \n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    " \n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc3fa5da-17a8-40f0-8f13-ce9c23cd696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': {'title': 'Latitude', 'description': 'Latitude of the location to fetch weather data for', 'type': 'number'}, 'longitude': {'title': 'Longitude', 'description': 'Longitude of the location to fetch weather data for', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "print(get_current_temperature.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a376c13c-458d-4d96-ad87-9d4c64d88ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 30.4°C'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.run({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce0e41aa-ab0f-4355-a2c2-a964620f7580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': 'Fetch current temperature for given coordinates.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude']}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    " \n",
    "format_tool_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5025a493-9f8a-4f4f-ae44-31b3b550bf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"latitude\": 31.2304,\\n  \"longitude\": 121.4737\\n}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 94, 'total_tokens': 123}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'function_call', 'logprobs': None, 'content_filter_results': {}}, id='run-c2c39c42-3d23-40d3-9dd1-166f2f8f6d2f-0', usage_metadata={'input_tokens': 94, 'output_tokens': 29, 'total_tokens': 123})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    " \n",
    "#创建函数描述变量\n",
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        get_current_temperature\n",
    "    ]\n",
    "]\n",
    " \n",
    "#定义llm\n",
    "# model = ChatOpenAI(temperature=0).bind(functions=functions)\n",
    "model = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ").bind(functions=functions)\n",
    " \n",
    "#创建prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    " \n",
    "#定义chain\n",
    "chain = prompt | model\n",
    " \n",
    "#调用chain\n",
    "chain.invoke({\"input\": \"上海现在的天气怎么样？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57198d11-a2e6-4987-925b-e52a2bfdfff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好，有什么可以帮助你的吗？', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 83, 'total_tokens': 101}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-cd689602-579b-4b67-af5e-9024a116b3ba-0', usage_metadata={'input_tokens': 83, 'output_tokens': 18, 'total_tokens': 101})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"你好\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66fb41ed-f53d-4897-bb3c-6fdc95ba2fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentActionMessageLog(tool='get_current_temperature', tool_input={'latitude': 31.2304, 'longitude': 121.4737}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 31.2304, 'longitude': 121.4737}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"latitude\": 31.2304,\\n  \"longitude\": 121.4737\\n}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 94, 'total_tokens': 123}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'function_call', 'logprobs': None, 'content_filter_results': {}}, id='run-b1401fa4-8e39-4e3d-a63f-0fec9a98e79d-0', usage_metadata={'input_tokens': 94, 'output_tokens': 29, 'total_tokens': 123})])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    " \n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n",
    " \n",
    "result = chain.invoke({\"input\": \"上海现在的天气怎么样？\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "481e914b-c1e1-4d28-935d-686cf4d8cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    " \n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1bab5e29-6cd4-4276-ab54-cf95a248028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_weather(location):\n",
    "    # 假设这是你的查询天气 API 的 URL\n",
    "    api_url = f\"http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q={location}\"\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['current']['condition']['text']\n",
    "    else:\n",
    "        return \"无法获取天气信息\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac77af1a-d320-44fd-a429-77735b1700fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'is_single_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 初始化 agent\u001b[39;00m\n\u001b[1;32m     42\u001b[0m tools \u001b[38;5;241m=\u001b[39m [WeatherTool()]\n\u001b[0;32m---> 43\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero-shot-react-description\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 创建 agent 实例\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWeatherAgent\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/agents/initialize.py:67\u001b[0m, in \u001b[0;36minitialize_agent\u001b[0;34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     agent_cls \u001b[38;5;241m=\u001b[39m AGENT_TO_CLASS[agent]\n\u001b[1;32m     66\u001b[0m     agent_kwargs \u001b[38;5;241m=\u001b[39m agent_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m---> 67\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m \u001b[43magent_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm_and_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43magent_kwargs\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m agent_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     agent_obj \u001b[38;5;241m=\u001b[39m load_agent(\n\u001b[1;32m     72\u001b[0m         agent_path, llm\u001b[38;5;241m=\u001b[39mllm, tools\u001b[38;5;241m=\u001b[39mtools, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager\n\u001b[1;32m     73\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/agents/mrkl/base.py:104\u001b[0m, in \u001b[0;36mZeroShotAgent.from_llm_and_tools\u001b[0;34m(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, input_variables, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm_and_tools\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    102\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Agent:\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct an agent from an LLM and tools.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_prompt(\n\u001b[1;32m    106\u001b[0m         tools,\n\u001b[1;32m    107\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m         input_variables\u001b[38;5;241m=\u001b[39minput_variables,\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    113\u001b[0m         llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    114\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    115\u001b[0m         callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[1;32m    116\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/agents/mrkl/base.py:128\u001b[0m, in \u001b[0;36mZeroShotAgent._validate_tools\u001b[0;34m(cls, tools)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_tools\u001b[39m(\u001b[38;5;28mcls\u001b[39m, tools: Sequence[BaseTool]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[43mvalidate_tools_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tools) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot no tools for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. At least one tool must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m         )\n",
      "File \u001b[0;32m~/mambaforge/envs/python310_chatbot/lib/python3.10/site-packages/langchain/agents/utils.py:9\u001b[0m, in \u001b[0;36mvalidate_tools_single_input\u001b[0;34m(class_name, tools)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate tools for single input.\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_single_input\u001b[49m:\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support multi-input tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'is_single_input'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")\n",
    "\n",
    "# 创建一个简单的查询天气工具\n",
    "class WeatherTool(Tool):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"query_weather\",\n",
    "            description=\"查询指定位置的天气信息\",\n",
    "            func=query_weather\n",
    "        )\n",
    "\n",
    "# 创建一个简单的 prompt 模板\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"input\"],\n",
    "    template=\"\"\"\n",
    "    你是一个智能助手，能够进行多轮对话并自动判断是否需要查询天气信息。\n",
    "    当前对话上下文是：{context}\n",
    "    用户输入是：{input}\n",
    "    \n",
    "    如果用户询问天气，请调用查询天气工具。\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 创建一个 LLM Chain\n",
    "llm_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "# 初始化 agent\n",
    "tools = [WeatherTool()]\n",
    "agent = initialize_agent(llm_chain, tools, agent_type=\"zero-shot-react-description\")\n",
    "\n",
    "# 创建 agent 实例\n",
    "class WeatherAgent:\n",
    "    def __init__(self):\n",
    "        self.agent = agent\n",
    "        self.context = \"\"\n",
    "\n",
    "    def handle_input(self, user_input):\n",
    "        # 更新上下文\n",
    "        self.context += f\"\\n用户: {user_input}\"\n",
    "        \n",
    "        # 生成回复\n",
    "        response = self.agent.run(input=user_input)\n",
    "        \n",
    "        self.context += f\"\\n助手: {response}\"\n",
    "        return response\n",
    "\n",
    "# 创建 agent 实例\n",
    "weather_agent = WeatherAgent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c682a7-bc08-49e4-8fcf-413317170eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaffed7a-6e90-4f7e-b0d6-ee22097be648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa0d766-0fa1-4f81-95eb-07ac1c321376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8892a639-7bf1-47c6-82ea-3c4b22fd7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c965fdee-d013-4aa5-8487-cc2cf97c5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6c3d9e1-4966-4409-afa7-b845b7b0fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(model_list: list[str]) -> str:\n",
    "    \"当发现句子中有关于型号的东西的时候，从输入的型号的列表里面选择第一个\"\n",
    "    return model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6dd7cf3-d674-4f73-922f-92b7552615cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "tools = [add]\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "# Only certain models support this\n",
    "chat = AzureChatOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\",\n",
    "    deployment_name=\"gpt-4-8k\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94ba9f6b-a02a-4a97-928e-d5da1a0713cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Adapted from https://smith.langchain.com/hub/hwchase17/openai-tools-agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. You may not need to use tools for every query - the user may just want to chat!\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4890a3e-0796-47b2-b0fd-e7d8e5df156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "agent = create_openai_tools_agent(chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbb48559-b070-44a0-b584-1b101dc8e59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m你好！有什么可以帮助你的吗？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='你好')], 'output': '你好！有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent_executor.invoke({\"messages\": [HumanMessage(content=\"你好\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a76c8e51-17aa-454e-83ee-9a58ca699ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'model_list': ['a10', 'a11']}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3ma10\u001b[0m\u001b[32;1m\u001b[1;3m您选择的第一个型号是 'a10'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"我的型号列表是['a10', 'a11']\")],\n",
       " 'output': \"您选择的第一个型号是 'a10'.\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"我的型号列表是['a10', 'a11']\"\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd6e4dc-974d-47d0-a560-9bfcf608573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m对不起，我无法回答这个问题，因为我没有能力回溯到之前的对话。我是一款只能回应当前问题的人工智能助手。你可以再次提出你的问题或需求，我会很高兴为你服务。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='我刚才问了什么')],\n",
       " 'output': '对不起，我无法回答这个问题，因为我没有能力回溯到之前的对话。我是一款只能回应当前问题的人工智能助手。你可以再次提出你的问题或需求，我会很高兴为你服务。'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"我刚才问了什么\"\n",
    "            )\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deca18b9-f1ea-4281-8e0d-34afb3af82e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Nemo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"I'm Nemo!\"),\n",
       "  AIMessage(content='Hello Nemo! How can I assist you today?'),\n",
       "  HumanMessage(content='What is my name?')],\n",
       " 'output': 'Your name is Nemo.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"I'm Nemo!\"),\n",
    "            AIMessage(content=\"Hello Nemo! How can I assist you today?\"),\n",
    "            HumanMessage(content=\"What is my name?\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3c76a491-f838-409a-9968-b59428946275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://smith.langchain.com/hub/hwchase17/openai-tools-agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你是一个家庭服务机器人管理者，用户已经拥有的机器人型号列表为['a1','a2']，如果你发现用户在的句子是在涉及自己的机器型号但是没有明确说明型号名称的话你要明白用户实际上是在指代这个列表，并且把这个列表替换到句子中。You may not need to use tools for every query - the user may just want to chat!。\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_openai_tools_agent(chat, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "287227ab-76e9-4d1e-9c57-6a1b1a042a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "demo_ephemeral_chat_history_for_chain = ChatMessageHistory()\n",
    "\n",
    "conversational_agent_executor = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    lambda session_id: demo_ephemeral_chat_history_for_chain,\n",
    "    input_messages_key=\"input\",\n",
    "    output_messages_key=\"output\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e14122c4-7397-4dd6-9d74-10ab67b072ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m您好！请问有什么可以帮助您的吗？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '你好', 'chat_history': [], 'output': '您好！请问有什么可以帮助您的吗？'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"你好\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3f4e955-19ae-40f0-83a8-d672a068b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'model_list': ['a1', 'a2']}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3ma1\u001b[0m\u001b[32;1m\u001b[1;3m您的机器型号a1和c9, c10的主要区别在于...（此处应详细解释不同型号的区别）。至于后缀，a1的后缀是1，c9的后缀是9，而c10的后缀是10。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '我的机器型号和c9, c10有什么区别，后面两个型号它们的后缀是什么（型号后缀就是英文字符后面跟的数字）',\n",
       " 'chat_history': [HumanMessage(content='你好'),\n",
       "  AIMessage(content='您好！请问有什么可以帮助您的吗？')],\n",
       " 'output': '您的机器型号a1和c9, c10的主要区别在于...（此处应详细解释不同型号的区别）。至于后缀，a1的后缀是1，c9的后缀是9，而c10的后缀是10。'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"我的机器型号和c9, c10有什么区别，后面两个型号它们的后缀是什么（型号后缀就是英文字符后面跟的数字）\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4725237-0789-4a04-b9a1-7c8e06ffda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m对于c9和c10这两个型号，他们的具体功能我需要查证一下。但是通常，有些机器人型号确实具备拖地的功能。我会尽快为您确认。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '后面两个型号可以拖地吗',\n",
       " 'chat_history': [HumanMessage(content='你好'),\n",
       "  AIMessage(content='您好！请问有什么可以帮助您的吗？'),\n",
       "  HumanMessage(content='我的机器型号和c9, c10有什么区别，后面两个型号它们的后缀是什么（型号后缀就是英文字符后面跟的数字）'),\n",
       "  AIMessage(content='您的机器型号a1和c9, c10的主要区别在于...（此处应详细解释不同型号的区别）。至于后缀，a1的后缀是1，c9的后缀是9，而c10的后缀是10。')],\n",
       " 'output': '对于c9和c10这两个型号，他们的具体功能我需要查证一下。但是通常，有些机器人型号确实具备拖地的功能。我会尽快为您确认。'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"后面两个型号可以拖地吗\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "954c0638-f9f5-4b8d-a1ff-57404a7ccfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m是的，现在已经很晚了。还有什么我可以帮助您的吗？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '今天是不是很晚了',\n",
       " 'chat_history': [HumanMessage(content='你好'),\n",
       "  AIMessage(content='您好！请问有什么可以帮助您的吗？'),\n",
       "  HumanMessage(content='我的机器型号和c9, c10有什么区别，后面两个型号它们的后缀是什么（型号后缀就是英文字符后面跟的数字）'),\n",
       "  AIMessage(content='您的机器型号a1和c9, c10的主要区别在于...（此处应详细解释不同型号的区别）。至于后缀，a1的后缀是1，c9的后缀是9，而c10的后缀是10。'),\n",
       "  HumanMessage(content='后面两个型号可以拖地吗'),\n",
       "  AIMessage(content='对于c9和c10这两个型号，他们的具体功能我需要查证一下。但是通常，有些机器人型号确实具备拖地的功能。我会尽快为您确认。')],\n",
       " 'output': '是的，现在已经很晚了。还有什么我可以帮助您的吗？'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"今天是不是很晚了\",\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a4f5a-2899-4d60-b337-6be2dd55b0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
