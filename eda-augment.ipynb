{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0d6751-c093-4c78-ae49-fc4107852e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T11:06:10.026714214Z",
     "start_time": "2024-04-29T11:06:09.984375950Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "import numpy as np \n",
    "import joblib\n",
    "import re  \n",
    "import jieba \n",
    "import json\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "from pandasql import sqldf\n",
    "from preprocessing import extract_versions, extract_models, WordCut\n",
    "\n",
    "from datasets import Dataset \n",
    "from datasets import Features, ClassLabel, Sequence, Value\n",
    "from datasets import load_from_disk, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a46b3955067fa79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T11:06:10.437085278Z",
     "start_time": "2024-04-29T11:06:10.431104945Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# pandasql查询函数需要的环境\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0377b93d-b87b-4aa0-8181-fbdaef8edd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(question, all_model_list, wc):\n",
    "    original_question = question\n",
    "    model_list, question = extract_models(question, all_model_list)\n",
    "    version_list, question = extract_versions(question)\n",
    "    key_words = wc.cut(question)\n",
    "    key_words = [i for i in key_words if ((i.find(\"model\")<0) and (i.find(\"version\")<0))]\n",
    "    return {\"question\": original_question, \"model\": model_list, \"version\": version_list, \"keywords\": key_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdb2287519920465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T11:06:10.760443187Z",
     "start_time": "2024-04-29T11:06:10.743542231Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 原始数据处理\n",
    "def format_model(x):\n",
    "    model_list = x.split(',')\n",
    "    model_list = [i.strip().lower().replace(\" \", \"\") for i in model_list]\n",
    "    new_list = [model_list[0]]\n",
    "    i = 1\n",
    "    while i < len(model_list):\n",
    "        if (i != len(model_list) - 1) and (model_list[i-1] == model_list[i]):\n",
    "            new_list.append(model_list[i]+model_list[i+1])\n",
    "            if i < len(model_list) - 1:\n",
    "                i += 2\n",
    "            else:\n",
    "                break\n",
    "        elif (i != len(model_list) - 1) and (model_list[i-1] != model_list[i]):\n",
    "            new_list.append(model_list[i])\n",
    "            i += 1\n",
    "        elif (model_list[i] == \"上下水\") or (model_list[i] == \"air\"):\n",
    "            for j in range(len(new_list)):\n",
    "                if model_list[i-1] == new_list[j]:\n",
    "                    new_list.pop(j)\n",
    "                    break\n",
    "            new_list.append(model_list[i-1]+model_list[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            new_list.append(model_list[i])\n",
    "            break\n",
    "    return new_list\n",
    "\n",
    "# 原始数据处理\n",
    "def format_model2(x):\n",
    "    model_list = x.split(',')\n",
    "    model_list = [i.strip().lower() for i in model_list]\n",
    "    new_list = [model_list[0]]\n",
    "    i = 1\n",
    "    while i < len(model_list):\n",
    "        if (i != len(model_list) - 1) and (model_list[i-1] == model_list[i]):\n",
    "            new_list.append(model_list[i]+model_list[i+1])\n",
    "            if i < len(model_list) - 1:\n",
    "                i += 2\n",
    "            else:\n",
    "                break\n",
    "        elif (model_list[i][:3] == \"上下水\") or (model_list[i][:3] == \"air\") or (model_list[i][:3] == \"pro\") or (model_list[i][:4] == \"pure\"):\n",
    "            for j in range(len(new_list)-1, -1, -1):\n",
    "                if model_list[i-1] == new_list[j]:\n",
    "                    new_list.pop(j)\n",
    "                    break\n",
    "            new_list.append(model_list[i-1]+model_list[i])\n",
    "            i += 1\n",
    "        elif (i != len(model_list) - 1) and (model_list[i-1] != model_list[i]):\n",
    "            new_list.append(model_list[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            new_list.append(model_list[i])\n",
    "            break\n",
    "    return new_list\n",
    "\n",
    "def format_all_models(x, dim_df):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"全型号\") >= 0:\n",
    "            end_idx = i.find(\"全型号\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[dim_df['cat_name'] == name].model.tolist() if j not in x]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "def format_series(x, dim_df):\n",
    "    def contains_chinese(s):\n",
    "        return re.search('[\\u4e00-\\u9fff]', s) is not None\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"系列\") >= 0:\n",
    "            end_idx = i.find(\"系列\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[(dim_df.model.str.find(name)>=0) & (\n",
    "                dim_df.model.apply(lambda x: not contains_chinese(x)))].model.tolist() if j not in x]\n",
    "            new_list += [i]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c313d44fac87ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T11:06:11.584453395Z",
     "start_time": "2024-04-29T11:06:11.580777532Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def count_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x.split(\",\"))  \n",
    "    \n",
    "def find_non_chinese_substrings(s):\n",
    "    # 正则表达式解释：\n",
    "    # [^\\u4e00-\\u9fff\\W]+ 匹配非中文字符和非ASCII标点的连续字符\n",
    "    # 但这样会排除空格，所以我们需要允许空格存在\n",
    "    # 我们使用(?:[^\\u4e00-\\u9fff\\W]| )+ 来实现这一点，(?:) 是非捕获组，用于匹配模式但不作为捕获结果返回\n",
    "    # [^\\u4e00-\\u9fff\\W] 匹配非中文且非标点的字符，| 表示或，空格 ' ' 被显式允许\n",
    "    pattern = r'(?:[^\\u4e00-\\u9fff\\W]| )+'\n",
    "    \n",
    "    # 使用findall方法查找所有匹配项\n",
    "    matches = re.findall(pattern, s)\n",
    "    \n",
    "    # 过滤掉只包含空格的字符串\n",
    "    matches = [match for match in matches if not match.isspace()]\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.replace(\" \", \"\").lower()\n",
    "    return s\n",
    "\n",
    "def find_model(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    x = find_non_chinese_substrings(x)\n",
    "    result = [clean_string(s) for s in x]\n",
    "    return [model for model in all_model_list if model in result]\n",
    "\n",
    "def find_cat(x, all_cat_list):\n",
    "    return [name for name in all_cat_list if name in x]   \n",
    "\n",
    "def filter_model(x, model_list):\n",
    "    x = x.split(\",\")\n",
    "    for model in model_list:\n",
    "        if model in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_error_with_reason(a):\n",
    "    # 第一次匹配“错误xxx”\n",
    "    pattern1 = r\"错误\\s*\\d+\"\n",
    "    matches1 = re.findall(pattern1, a)\n",
    "    \n",
    "    # 第二次匹配“错误原因xxx”\n",
    "    pattern2 = r\"错误原因\\s*\\d+\"\n",
    "    matches2 = re.findall(pattern2, a)\n",
    "\n",
    "    # 合并两次匹配的结果\n",
    "    matches = matches1 + matches2\n",
    "    \n",
    "    return [name.replace(\" \", \"\").replace(\"原因\", \"\") for name in matches]\n",
    "\n",
    "def filter_reason(x, query_reason_list):\n",
    "    reason_list = find_error_with_reason(x)\n",
    "    for name in query_reason_list:\n",
    "        if name in reason_list:\n",
    "            return True \n",
    "    return False\n",
    "\n",
    "def transform_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        cleaned_name = clean_string(name)\n",
    "        for model in all_model_list:\n",
    "            if cleaned_name == model:\n",
    "                x = x.replace(name, model)\n",
    "                break\n",
    "    return x \n",
    "\n",
    "def remove_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        if clean_string(name) in all_model_list:\n",
    "            x = x.replace(name, \"\")\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9861749-9b8d-43b8-9d66-21334e32d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_chinese_substrings_v2(s):\n",
    "    pattern = r'(?:[^\\u4e00-\\u9fff\\W]| )+(?:上下水(?:版(?:本)?)?)?'\n",
    "    matches = re.finditer(pattern, s)\n",
    "\n",
    "    substrings_with_positions = []\n",
    "    for match in matches:\n",
    "        start, end = match.span()\n",
    "        substring = match.group()\n",
    "\n",
    "        # 去除左右两边的空格并调整位置\n",
    "        stripped_substring = substring.strip()\n",
    "        start += len(substring) - len(substring.lstrip())\n",
    "        end -= len(substring) - len(substring.rstrip())\n",
    "\n",
    "        if stripped_substring and not stripped_substring.isspace():\n",
    "            substrings_with_positions.append((stripped_substring, start, end))\n",
    "\n",
    "    return substrings_with_positions\n",
    "\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.replace(\" \", \"\").lower()\n",
    "    return s\n",
    "\n",
    "def find_model_v2(x, all_model_dict):\n",
    "    substrings_with_positions = find_non_chinese_substrings_v2(x)\n",
    "    results = []\n",
    "\n",
    "    for substring, start, end in substrings_with_positions:\n",
    "        cleaned_substring = clean_string(substring)\n",
    "        cleaned_substring = cleaned_substring.replace(\"版本\", \"\").replace(\"版\", \"\")\n",
    "        if cleaned_substring in all_model_dict:\n",
    "            results.append((cleaned_substring, start, end))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1873856a-15e0-4182-b511-4c30b5b77a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_tagging(texts, labels):\n",
    "    bio_words = []\n",
    "    bio_tags = []\n",
    "    texts = texts.lower()\n",
    "    for i, char in enumerate(texts):\n",
    "        tag = \"O\"  # 默认为 Outside\n",
    "\n",
    "        for entity_type, spans in labels.items():\n",
    "            for span in spans.values():\n",
    "                for ind in span:\n",
    "                    if i == int(ind[0]):\n",
    "                        tag = \"B-\" + entity_type\n",
    "                        break\n",
    "                    elif int(ind[0]) < i <= int(ind[1]):\n",
    "                        tag = \"I-\" + entity_type\n",
    "                        break\n",
    "\n",
    "        bio_words.append(char)\n",
    "        bio_tags.append(tag)\n",
    "\n",
    "    return bio_words, bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24087d4-51c4-4b6d-a875-1c3430aecfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义NER数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89099c8b5609671b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T01:56:42.794901015Z",
     "start_time": "2024-04-28T01:56:41.663211436Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/data/dataset/kefu/database_with_emb20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79693cce64b935cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T01:59:36.896064386Z",
     "start_time": "2024-04-28T01:59:35.736723322Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "oot = pd.read_excel(\"/data/dataset/kefu/国内客服助手（生产环境）_中转栈.xlsx\")\n",
    "oot = oot.rename(columns={\"编号\": \"qa_id\",\n",
    " \"问题\": \"question\",\n",
    " \"回复1\": \"answer1_all\",\n",
    " \"回复1标题\": \"answer1\",\n",
    " \"回复2\": \"answer2_all\",\n",
    " \"回复2标题\": \"answer2\",\n",
    " \"是否解决\": \"if_solved\",\n",
    " \"提问者\": \"requester\",\n",
    " \"提问者所在组别\": \"requester_group\",\n",
    " \"提问日期\": \"request_time\",\n",
    " \"类型\": \"data_type\", \n",
    " \"正确回复\": \"gt_answer\"})\n",
    "oot = oot.drop([\"回复1附件\", \"回复2附件\", \"提问日期(供统计用)\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b88123839a502a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T01:59:41.213093995Z",
     "start_time": "2024-04-28T01:59:40.896097394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# oot = oot[oot.if_solved.notnull()]\n",
    "# oot = oot[oot.answer1_all.notnull()]\n",
    "oot[\"if_solved\"] = oot[\"if_solved\"].map({\"已解决\": 1, \"未解决\": 0})\n",
    "oot.loc[oot.qa_id==\"ICASK202308010583\", \"gt_answer\"] = \"ICWIKI202307243975\"\n",
    "oot.loc[oot.qa_id==\"ICASK202308010582\", \"gt_answer\"] = \"ICWIKI202308210081\"\n",
    "# oot = oot[oot['gt_answer'].str.find(\"ICW\")>=0]\n",
    "oot = oot.rename(columns={\"gt_answer\": \"gt_qa_id\"})\n",
    "oot = oot[oot.question.notnull()]\n",
    "\n",
    "temp = oot.copy()\n",
    "temp[\"gt_qa_id\"] = temp[\"gt_qa_id\"].astype(str).apply(lambda x: x.split(','))\n",
    "temp_exploded = temp.explode(\"gt_qa_id\")\n",
    "temp_right = df2[['qa_id', \n",
    "                               'question', \n",
    "                               'answer', \n",
    "                               'model', \n",
    "                               'qa_type', \n",
    "                               'model_list', \n",
    "                               'cat_name']].copy()\n",
    "query = f\"\"\"\n",
    "select \n",
    "    a.*\n",
    "    ,b.question as question_kg\n",
    "    ,b.answer as answer_kg\n",
    "    ,b.model as model\n",
    "    ,b.qa_type\n",
    "    ,b.model_list\n",
    "    ,b.cat_name\n",
    "from \n",
    "    temp_exploded a \n",
    "left join \n",
    "    temp_right b\n",
    "on \n",
    "    a.gt_qa_id = b.qa_id\n",
    "\"\"\"\n",
    "\n",
    "# 使用pysqldf执行SQL查询\n",
    "temp_exploded = pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71096899a84dc835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T01:59:41.457923317Z",
     "start_time": "2024-04-28T01:59:41.336686126Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "select \n",
    "    qa_id\n",
    "    ,group_concat(question_kg) as question_kg\n",
    "    ,group_concat(answer_kg) as answer_kg\n",
    "    ,group_concat(model) as model\n",
    "    ,group_concat(qa_type) as qa_type\n",
    "    ,group_concat(model_list) as model_list\n",
    "    ,group_concat(cat_name) as cat_name\n",
    "from \n",
    "    temp_exploded\n",
    "group by \n",
    "    qa_id\n",
    "\"\"\"\n",
    "\n",
    "# 使用pysqldf执行SQL查询\n",
    "temp_exploded = pysqldf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce8d032a1415a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T01:59:42.165957893Z",
     "start_time": "2024-04-28T01:59:41.950818359Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "select \n",
    "    a.*\n",
    "    ,b.question_kg\n",
    "    ,b.answer_kg\n",
    "    ,b.model\n",
    "    ,b.qa_type\n",
    "    ,b.model_list\n",
    "    ,b.cat_name\n",
    "from \n",
    "    oot a \n",
    "left join \n",
    "    temp_exploded b\n",
    "on\n",
    "    a.qa_id = b.qa_id\n",
    "\"\"\"\n",
    "\n",
    "# 使用pysqldf执行SQL查询\n",
    "oot = pysqldf(query)\n",
    "\n",
    "oot['gt_num'] = oot['gt_qa_id'].astype(str).apply(lambda x: count_gt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17bd1de0082896ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T02:14:55.794165425Z",
     "start_time": "2024-04-23T02:14:55.770553239Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/dataset/kefu/oot20240422.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(oot[[\"qa_id\", \n",
    "     \"question\",\t\n",
    "     \"gt_qa_id\",\n",
    "     \"gt_num\",\n",
    "     \"question_kg\",\n",
    "     \"answer_kg\",\n",
    "     \"model\",\n",
    "     \"qa_type\",\n",
    "     \"model_list\",\n",
    "     \"cat_name\",\n",
    "     ]], \"/data/dataset/kefu/oot20240422.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed91dc93dc98b4e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T02:00:04.604315108Z",
     "start_time": "2024-04-28T02:00:04.576956929Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "oot = joblib.load(\"/data/dataset/kefu/oot20240422.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77e7cf7b82cdbcb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T11:06:26.894658940Z",
     "start_time": "2024-04-29T11:06:26.884394630Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c02e41c40f9721ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:06:49.226822526Z",
     "start_time": "2024-04-30T06:06:49.187334074Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# wc = WordCut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cd6a12216117425",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:06:51.879045616Z",
     "start_time": "2024-04-30T06:06:51.197991383Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# oot[\"keywords\"] = oot[\"question\"].apply(\n",
    "#     lambda x: extract_keywords(x, all_model_list, wc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7936940469990b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T04:02:07.456290967Z",
     "start_time": "2024-04-23T04:02:07.418266531Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oot[oot.version_keywords.apply(lambda x: len(x)>0)][[\"question\", \"keywords\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28804a45-c17c-4e16-b1b0-667c9b161651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义知识库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3a6dd7feda66898",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:31.559771881Z",
     "start_time": "2024-04-28T05:40:31.382932816Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_sweeping = pd.read_excel(\"/data/dataset/kefu/产品知识整理资料.xlsx\", sheet_name=\"扫地机\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65eb06f7-0a38-488b-9715-bf3f1d124039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:31.719786114Z",
     "start_time": "2024-04-28T05:40:31.684857469Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sweeping.loc[df_sweeping[\"上市时间\"]==45323, \"上市时间\"] = datetime.datetime(2024, 2, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2cdef4-1219-49a0-bbda-f88f84b80294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:32.147602568Z",
     "start_time": "2024-04-28T05:40:31.925684954Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mopping = pd.read_excel(\"/data/dataset/kefu/产品知识整理资料.xlsx\", sheet_name=\"洗地机\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fff9bc0-73f0-4052-89f4-3c4b6af69d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:32.394020413Z",
     "start_time": "2024-04-28T05:40:32.276702462Z"
    }
   },
   "outputs": [],
   "source": [
    "df_washing = pd.read_excel(\"/data/dataset/kefu/产品知识整理资料.xlsx\", sheet_name=\"洗衣机\")\n",
    "df_washing = df_washing.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20a23557-c6ca-4d13-96fa-c8e459064853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:35.379055088Z",
     "start_time": "2024-04-28T05:40:35.368009814Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in [\"商品编码\", \"平台ID\", \"商品id\"]:\n",
    "    df_sweeping[col] = df_sweeping[col].astype(str)\n",
    "    df_sweeping.loc[df_sweeping[col]=='nan', col] = np.nan\n",
    "    df_mopping[col] = df_mopping[col].astype(str)\n",
    "    df_mopping.loc[df_mopping[col]=='nan', col] = np.nan\n",
    "    df_washing[col] = df_washing[col].astype(np.int64).astype(str)\n",
    "    df_washing.loc[df_washing[col]=='nan', col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbd7b7a15be929e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:37.584660528Z",
     "start_time": "2024-04-28T05:40:37.576537848Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 73)\n",
      "(7, 87)\n",
      "(14, 91)\n"
     ]
    }
   ],
   "source": [
    "print(df_washing.shape)\n",
    "print(df_mopping.shape)\n",
    "print(df_sweeping.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ecd42f8-48c4-42e2-a195-01a3b4edf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_dict = {}\n",
    "for i in range(df_sweeping.shape[0]):\n",
    "    model_name = format_model(df_sweeping.iloc[i].商品型号)[0]\n",
    "    all_model_dict[model_name] = \"扫地机\"\n",
    "    all_model_dict[model_name+\"上下水版\"] = \"扫地机\"\n",
    "    all_model_dict[model_name+\"上下水\"] = \"扫地机\"\n",
    "for i in range(df_mopping.shape[0]):\n",
    "    model_name = format_model(df_mopping.iloc[i].商品型号)[0]\n",
    "    all_model_dict[model_name] = \"洗地机\"\n",
    "for i in range(df_washing.shape[0]):\n",
    "    model_name = format_model(df_washing.iloc[i].商品型号)[0]\n",
    "    all_model_dict[model_name] = \"洗衣机\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceb71a95-58b9-456e-be46-eda82ef10c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "dim_df.model = dim_df.model.apply(lambda x: x.replace(\"版本\", \"\").replace(\"版\", \"\"))\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e1807a1-9609-4ad2-bbb4-dbff2e0fbd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h6\n",
      "h7\n",
      "u10\n",
      "洗地机全型号\n",
      "智能烘干套件\n",
      "智能集尘充电座\n",
      "自动集尘充电座\n",
      "p5\n",
      "s5\n",
      "t6\n",
      "t7\n",
      "t7pro\n",
      "t7s\n",
      "t7splus\n",
      "g10\n",
      "g10plus\n",
      "t8\n",
      "t8plus\n",
      "米家扫地机\n",
      "智能上下水及烘干套件（g10s、pro、auto的上下水）\n",
      "智能上下水套件（g10spure的上下水）\n",
      "g10s系列\n"
     ]
    }
   ],
   "source": [
    "for i in all_model_list:\n",
    "    if i not in all_model_dict:\n",
    "        print(i)\n",
    "        assert dim_df.loc[dim_df[\"model\"]==i, \"cat_name\"].shape[0] == 1\n",
    "        all_model_dict[i] = dim_df.loc[dim_df[\"model\"]==i, \"cat_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a54174c-23ee-4068-88c1-26281ce4fefd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'g20': '扫地机',\n",
       " 'g20上下水版': '扫地机',\n",
       " 'g20上下水': '扫地机',\n",
       " 'p10s': '扫地机',\n",
       " 'p10s上下水版': '扫地机',\n",
       " 'p10s上下水': '扫地机',\n",
       " 'p10spro': '扫地机',\n",
       " 'p10spro上下水版': '扫地机',\n",
       " 'p10spro上下水': '扫地机',\n",
       " 'g10spure': '扫地机',\n",
       " 'g10spure上下水版': '扫地机',\n",
       " 'g10spure上下水': '扫地机',\n",
       " 'g10spro': '扫地机',\n",
       " 'g10spro上下水版': '扫地机',\n",
       " 'g10spro上下水': '扫地机',\n",
       " 'p10': '扫地机',\n",
       " 'p10上下水版': '扫地机',\n",
       " 'p10上下水': '扫地机',\n",
       " 'g10s': '扫地机',\n",
       " 'g10s上下水版': '扫地机',\n",
       " 'g10s上下水': '扫地机',\n",
       " 'p10pro': '扫地机',\n",
       " 'p10pro上下水版': '扫地机',\n",
       " 'p10pro上下水': '扫地机',\n",
       " 'g10sauto': '扫地机',\n",
       " 'g10sauto上下水版': '扫地机',\n",
       " 'g10sauto上下水': '扫地机',\n",
       " 'a10ultra': '洗地机',\n",
       " 'a10ultrae': '洗地机',\n",
       " 'a10': '洗地机',\n",
       " 'a10plus': '洗地机',\n",
       " 'a20': '洗地机',\n",
       " 'a20pro': '洗地机',\n",
       " 'a20air': '洗地机',\n",
       " 'h1': '洗衣机',\n",
       " 'h1neo': '洗衣机',\n",
       " 'm1': '洗衣机',\n",
       " 'h6': '吸尘器',\n",
       " 'h7': '吸尘器',\n",
       " 'u10': '洗地机',\n",
       " '洗地机全型号': '洗地机',\n",
       " '智能烘干套件': '扫地机',\n",
       " '智能集尘充电座': '扫地机',\n",
       " '自动集尘充电座': '扫地机',\n",
       " 'p5': '扫地机',\n",
       " 's5': '扫地机',\n",
       " 't6': '扫地机',\n",
       " 't7': '扫地机',\n",
       " 't7pro': '扫地机',\n",
       " 't7s': '扫地机',\n",
       " 't7splus': '扫地机',\n",
       " 'g10': '扫地机',\n",
       " 'g10plus': '扫地机',\n",
       " 't8': '扫地机',\n",
       " 't8plus': '扫地机',\n",
       " '米家扫地机': '扫地机',\n",
       " '智能上下水及烘干套件（g10s、pro、auto的上下水）': '扫地机',\n",
       " '智能上下水套件（g10spure的上下水）': '扫地机',\n",
       " 'g10s系列': '扫地机'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87dd0138-9384-4ea4-9edf-83e2743d1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter =  {}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66fd335-8e1e-4de3-9095-50f970a31474",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_washing.columns:\n",
    "    if col in filter:\n",
    "        filter[col] = filter[col] | set([\"washing\"])\n",
    "    else:\n",
    "        filter[col] = set([\"washing\"])\n",
    "for col in df_mopping.columns:\n",
    "    if col in filter:\n",
    "        filter[col] = filter[col] | set([\"mopping\"])\n",
    "    else:\n",
    "        filter[col] = set([\"mopping\"])\n",
    "for col in df_sweeping.columns:\n",
    "    if col in filter:\n",
    "        filter[col] = filter[col] | set([\"sweeping\"])\n",
    "    else:\n",
    "        filter[col] = set([\"sweeping\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67f553a3-4602-4f56-b620-ff15aea3d08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'商品编码': {'mopping', 'sweeping', 'washing'},\n",
       " '平台ID': {'mopping', 'sweeping', 'washing'},\n",
       " '商品id': {'mopping', 'sweeping', 'washing'},\n",
       " '商品型号': {'mopping', 'sweeping', 'washing'},\n",
       " '商品名字': {'mopping', 'sweeping', 'washing'},\n",
       " '商品分类': {'mopping', 'sweeping', 'washing'},\n",
       " '商品链接': {'mopping', 'sweeping', 'washing'},\n",
       " '平台': {'mopping', 'sweeping', 'washing'},\n",
       " '店铺名称': {'mopping', 'sweeping', 'washing'},\n",
       " '服务别名': {'mopping', 'sweeping', 'washing'},\n",
       " '产地': {'washing'},\n",
       " '使用方式': {'washing'},\n",
       " '颜色分类': {'sweeping', 'washing'},\n",
       " '能效等级': {'washing'},\n",
       " '排水方式': {'washing'},\n",
       " '控制方式': {'washing'},\n",
       " '开合方式': {'washing'},\n",
       " '产品类型': {'washing'},\n",
       " '电机类型': {'washing'},\n",
       " '显示屏类型': {'washing'},\n",
       " '毛重': {'washing'},\n",
       " '机器尺寸': {'washing'},\n",
       " '净重': {'washing'},\n",
       " '上市时间': {'mopping', 'sweeping', 'washing'},\n",
       " '烘干方式': {'sweeping', 'washing'},\n",
       " '烘干公斤量': {'washing'},\n",
       " '洗涤公斤量': {'washing'},\n",
       " '包装尺寸': {'mopping', 'sweeping', 'washing'},\n",
       " '烘干功率': {'washing'},\n",
       " '建议摆放尺寸': {'washing'},\n",
       " '洗衣液容量': {'washing'},\n",
       " '柔顺剂容量': {'washing'},\n",
       " '内筒': {'washing'},\n",
       " '耗水': {'washing'},\n",
       " '耗电': {'washing'},\n",
       " '洗净比': {'washing'},\n",
       " '最高脱水转速': {'washing'},\n",
       " '洗涤噪音': {'washing'},\n",
       " '脱水噪音': {'washing'},\n",
       " '烘干噪音': {'mopping', 'washing'},\n",
       " '工作水压': {'washing'},\n",
       " '电源线长度': {'washing'},\n",
       " '进水管长度': {'washing'},\n",
       " '排水管长度': {'washing'},\n",
       " '水龙头类型': {'washing'},\n",
       " '控制面板程序': {'washing'},\n",
       " 'APP程序': {'washing'},\n",
       " '面板操作流程': {'washing'},\n",
       " '标配': {'mopping', 'washing'},\n",
       " '洗烘程序时间': {'washing'},\n",
       " '洗涤程序时间': {'washing'},\n",
       " '烘干程序时间': {'washing'},\n",
       " 'APP远程预约': {'washing'},\n",
       " '桶自洁': {'washing'},\n",
       " '小件程序时长': {'washing'},\n",
       " '运行提示音': {'washing'},\n",
       " '智能投放量': {'washing'},\n",
       " '干衣度': {'washing'},\n",
       " '浸泡功能': {'washing'},\n",
       " '烘干时长': {'sweeping', 'washing'},\n",
       " 'UVC紫外线除菌': {'washing'},\n",
       " '多维除菌作用': {'washing'},\n",
       " '多维除菌程序': {'washing'},\n",
       " '内筒照明': {'washing'},\n",
       " '断电记忆': {'washing'},\n",
       " '童锁功能': {'washing'},\n",
       " '中途添衣': {'washing'},\n",
       " '紧急开门': {'washing'},\n",
       " '机门锁定/解锁': {'washing'},\n",
       " '额定洗涤输入功率': {'washing'},\n",
       " '额定脱水输入功率': {'washing'},\n",
       " '额定加热输入功率': {'washing'},\n",
       " '防水等级': {'washing'},\n",
       " '烘干类型': {'mopping'},\n",
       " '颜色分类(销售属性)': {'mopping'},\n",
       " '自清洁需要用水量': {'mopping'},\n",
       " '墙边漏扫': {'mopping'},\n",
       " '工作噪音': {'mopping'},\n",
       " '电源线': {'mopping'},\n",
       " 'Wi-Fi连接': {'mopping'},\n",
       " '机身尺寸': {'mopping', 'sweeping'},\n",
       " '整体高度': {'mopping'},\n",
       " '刷头尺寸': {'mopping'},\n",
       " '地板刷尺寸': {'mopping'},\n",
       " '床刷尺寸': {'mopping'},\n",
       " '缝隙刷尺寸': {'mopping'},\n",
       " '延长杆长度': {'mopping'},\n",
       " '充电座尺寸': {'mopping'},\n",
       " '洗地风机电功率': {'mopping'},\n",
       " '吸尘风机电功率': {'mopping'},\n",
       " '最大吸力': {'mopping', 'sweeping'},\n",
       " '吸尘工作噪音': {'mopping'},\n",
       " '滚刷自清洁率': {'mopping'},\n",
       " '烘干效率': {'mopping'},\n",
       " '重量': {'mopping'},\n",
       " '清水箱容量': {'mopping', 'sweeping'},\n",
       " '污水箱容量': {'mopping', 'sweeping'},\n",
       " '尘桶容量': {'mopping'},\n",
       " '电池容量': {'mopping', 'sweeping'},\n",
       " '充电时长': {'mopping', 'sweeping'},\n",
       " '充电功率': {'mopping'},\n",
       " '清水箱续航': {'mopping'},\n",
       " '污水箱续航': {'mopping'},\n",
       " '耗电量': {'mopping'},\n",
       " '电池续航': {'mopping', 'sweeping'},\n",
       " '吸尘续航': {'mopping'},\n",
       " '插头类型': {'mopping'},\n",
       " '可清理垃圾': {'mopping'},\n",
       " '不可清理垃圾': {'mopping'},\n",
       " '助力方式': {'mopping'},\n",
       " '贴边': {'mopping'},\n",
       " '风机转速': {'mopping'},\n",
       " '滚刷方式': {'mopping'},\n",
       " '清洁模式': {'mopping'},\n",
       " '自清洁': {'mopping'},\n",
       " '烘干模式': {'mopping'},\n",
       " '智能屏幕显示': {'mopping'},\n",
       " '智能污渍检测': {'mopping'},\n",
       " '智能化体验': {'mopping'},\n",
       " '固件升级': {'mopping'},\n",
       " '吸尘模式': {'mopping'},\n",
       " '设备共享': {'mopping'},\n",
       " '自清洁模式选择': {'mopping'},\n",
       " '洗地设置': {'mopping'},\n",
       " '烘干模式选择': {'mopping'},\n",
       " '基座设置': {'mopping'},\n",
       " '智能定时洗烘': {'mopping'},\n",
       " '直立解锁自动运行': {'mopping'},\n",
       " '勿扰模式': {'mopping'},\n",
       " '刷头探照灯': {'mopping'},\n",
       " '语音及音量': {'mopping'},\n",
       " '部件与耗材': {'mopping'},\n",
       " '产品信息': {'mopping'},\n",
       " '机身维护': {'mopping', 'sweeping'},\n",
       " '吸尘组件维护': {'mopping'},\n",
       " '耗材\\n更换周期': {'mopping'},\n",
       " '整机质保': {'mopping'},\n",
       " '风机质保': {'mopping'},\n",
       " '耗材质保': {'mopping'},\n",
       " '主机额定功率': {'mopping', 'sweeping'},\n",
       " '额定输入功率（热水洗布）': {'mopping', 'sweeping'},\n",
       " '额定输入功率（充电 + 烘干状态）': {'mopping', 'sweeping'},\n",
       " '充电座额定功率': {'mopping'},\n",
       " '额定输入': {'mopping'},\n",
       " '洗地机类型': {'mopping'},\n",
       " '品牌': {'mopping', 'sweeping'},\n",
       " '版本': {'sweeping'},\n",
       " '产品重量': {'sweeping'},\n",
       " '产品毛重': {'sweeping'},\n",
       " '上下水套件额定功率': {'sweeping'},\n",
       " '额定输入(电压)': {'sweeping'},\n",
       " '额定输入功率（集尘状态）': {'sweeping'},\n",
       " '最大进水压力': {'sweeping'},\n",
       " '热水洗布': {'sweeping'},\n",
       " '动态复洗拖布': {'sweeping'},\n",
       " '耗材更换周期': {'sweeping'},\n",
       " '如何关闭/开启语音助手': {'sweeping'},\n",
       " '吸力大小': {'sweeping'},\n",
       " '导航类型': {'sweeping'},\n",
       " '机载水箱容量': {'sweeping'},\n",
       " '地毯模式': {'sweeping'},\n",
       " '是否支持自动集尘': {'sweeping'},\n",
       " '基座水箱容量': {'sweeping'},\n",
       " '清洁液储存盒': {'sweeping'},\n",
       " '套餐类型': {'sweeping'},\n",
       " '整体尺寸': {'sweeping'},\n",
       " '水箱续航': {'sweeping'},\n",
       " '机载尘盒容量': {'sweeping'},\n",
       " '尘袋容量': {'sweeping'},\n",
       " '标配清单': {'sweeping'},\n",
       " '支持APP': {'sweeping'},\n",
       " '回洗方式': {'sweeping'},\n",
       " '清洗模式': {'sweeping'},\n",
       " '热水洗布.1': {'sweeping'},\n",
       " '集尘模式': {'sweeping'},\n",
       " '集尘频率': {'sweeping'},\n",
       " '烘干温度': {'sweeping'},\n",
       " '扫拖模式': {'sweeping'},\n",
       " '充电模式': {'sweeping'},\n",
       " '是否有定时预约功能': {'sweeping'},\n",
       " '最大噪音': {'sweeping'},\n",
       " '拖地方式': {'sweeping'},\n",
       " '适用面积': {'sweeping'},\n",
       " '电器基站功能': {'sweeping'},\n",
       " '避障方式': {'sweeping'},\n",
       " '软件算法': {'sweeping'},\n",
       " '是否支持上下水': {'sweeping'},\n",
       " '最高高度': {'sweeping'},\n",
       " '水箱类型': {'sweeping'},\n",
       " '是否支持烘干': {'sweeping'},\n",
       " '悬崖传感器': {'sweeping'},\n",
       " '升降模组': {'sweeping'},\n",
       " '扫地机类型': {'sweeping'},\n",
       " '采购地': {'sweeping'},\n",
       " '型号': {'sweeping'},\n",
       " '附加功能': {'sweeping'},\n",
       " '实时视频': {'sweeping'},\n",
       " '质保年限': {'sweeping'},\n",
       " '是否带遥控器': {'sweeping'},\n",
       " '生产企业': {'sweeping'},\n",
       " '主刷转速': {'sweeping'},\n",
       " '有无虚拟墙': {'sweeping'},\n",
       " '电源线长': {'sweeping'},\n",
       " '是否支持银离子抑菌': {'sweeping'},\n",
       " '功能': {'sweeping'},\n",
       " '清扫模式': {'sweeping'},\n",
       " '有无地毯自动增压模式': {'sweeping'},\n",
       " '清扫路线': {'sweeping'},\n",
       " '是否支持自动回洗拖布': {'sweeping'},\n",
       " '保修期': {'sweeping'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12f70f61b1159bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:39.943262001Z",
     "start_time": "2024-04-28T05:40:39.734765199Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df_washing.to_csv(\"/data/dataset/kefu/washing.csv\", index=None)\n",
    "# df_mopping.to_csv(\"/data/dataset/kefu/mopping.csv\", index=None)\n",
    "# df_sweeping.to_csv(\"/data/dataset/kefu/sweeping.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec4a52a475a53ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:42.897943465Z",
     "start_time": "2024-04-28T05:40:42.872806032Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_washing, df_mopping, df_sweeping], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2be9a4e2-814f-4e3a-a408-60fa25f104f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"商品型号\"] = df_all[\"商品型号\"].apply(lambda x: find_model_v2(x, all_model_dict)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8d0d3375d35e365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T05:40:45.497813123Z",
     "start_time": "2024-04-28T05:40:45.493861648Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# df_all.to_csv(\"/data/dataset/kefu/model_params20240620.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358bb9b2-f678-40c6-8533-2eb104aaac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"/data/dataset/kefu/model_params20240620.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84b5a7f4-a672-4451-889b-0570d5cef0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用csv2qa.py从模板收集数据表格问答数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ea6a1c26-b8b8-44da-93fc-aa4c788f4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file='/data/dataset/kefu/gen_different_keywords_different_models.jsonl'):\n",
    "    df = []\n",
    "    # 打开文件进行读取\n",
    "    with open(json_file, 'r') as file:\n",
    "        # 逐行读取\n",
    "        for line in file:\n",
    "            # 将每行的内容从JSON字符串转换为Python字典\n",
    "            data = json.loads(line.strip())\n",
    "            # 现在可以处理这个字典了\n",
    "            df.append(data)\n",
    "    return df \n",
    "\n",
    "def extract_json(x):\n",
    "    result = {\"template\": x[\"template\"]}\n",
    "    result[\"replace\"] = x[\"gen\"][\"replace\"]\n",
    "    return json.dumps(result, ensure_ascii=False)\n",
    "\n",
    "file_list = ['/data/dataset/kefu/gen_same_keywords_for_models_v2.jsonl',\n",
    "             '/data/dataset/kefu/gen_different_keywords_different_models_v2.jsonl']\n",
    "df = []\n",
    "for file in file_list:\n",
    "    temp = pd.DataFrame(read_json(file))\n",
    "    temp['type'] = file.split('/')[-1].split(\".\")[0]\n",
    "    df.append(temp)\n",
    "df = pd.concat(df, axis=0).reset_index(drop=True)\n",
    "\n",
    "df[\"final_prompt\"] = df.apply(lambda x: extract_json(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fcdabde4-52b6-46a3-87e6-5b55806b4df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>gen</th>\n",
       "      <th>template</th>\n",
       "      <th>cat_num</th>\n",
       "      <th>type</th>\n",
       "      <th>final_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mopping,sweeping</td>\n",
       "      <td>{'question': 'g20和p10pro的服务别名是什么？', 'prompt': ...</td>\n",
       "      <td>[问询词0]和[问询词1]的[关键词0]是什么？</td>\n",
       "      <td>2</td>\n",
       "      <td>gen_same_keywords_for_models_v2</td>\n",
       "      <td>{\"template\": \"[问询词0]和[问询词1]的[关键词0]是什么？\", \"repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mopping,sweeping</td>\n",
       "      <td>{'question': 'p10pro标准版和g10sauto标准版的清水箱续航和额定输入...</td>\n",
       "      <td>[问询词0]和[问询词1]的[关键词0]和[关键词1]是什么？</td>\n",
       "      <td>2</td>\n",
       "      <td>gen_same_keywords_for_models_v2</td>\n",
       "      <td>{\"template\": \"[问询词0]和[问询词1]的[关键词0]和[关键词1]是什么？\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mopping,sweeping</td>\n",
       "      <td>{'question': 'g10sauto和g20上下水版的清扫模式和烘干时长和标配是什么...</td>\n",
       "      <td>[问询词0]和[问询词1]的[关键词0]和[关键词1]和[关键词2]是什么？</td>\n",
       "      <td>2</td>\n",
       "      <td>gen_same_keywords_for_models_v2</td>\n",
       "      <td>{\"template\": \"[问询词0]和[问询词1]的[关键词0]和[关键词1]和[关键词...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mopping,sweeping</td>\n",
       "      <td>{'question': 'a20pro和p10上下水版和a10plus的自清洁模式选择是什...</td>\n",
       "      <td>[问询词0]和[问询词1]和[问询词2]的[关键词0]是什么？</td>\n",
       "      <td>2</td>\n",
       "      <td>gen_same_keywords_for_models_v2</td>\n",
       "      <td>{\"template\": \"[问询词0]和[问询词1]和[问询词2]的[关键词0]是什么？\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mopping,sweeping</td>\n",
       "      <td>{'question': 'a10plus和g10sauto标准版和a10ultrae的助力...</td>\n",
       "      <td>[问询词0]和[问询词1]和[问询词2]的[关键词0]和[关键词1]是什么？</td>\n",
       "      <td>2</td>\n",
       "      <td>gen_same_keywords_for_models_v2</td>\n",
       "      <td>{\"template\": \"[问询词0]和[问询词1]和[问询词2]的[关键词0]和[关键词...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cat                                                gen  \\\n",
       "6   mopping,sweeping  {'question': 'g20和p10pro的服务别名是什么？', 'prompt': ...   \n",
       "7   mopping,sweeping  {'question': 'p10pro标准版和g10sauto标准版的清水箱续航和额定输入...   \n",
       "8   mopping,sweeping  {'question': 'g10sauto和g20上下水版的清扫模式和烘干时长和标配是什么...   \n",
       "9   mopping,sweeping  {'question': 'a20pro和p10上下水版和a10plus的自清洁模式选择是什...   \n",
       "10  mopping,sweeping  {'question': 'a10plus和g10sauto标准版和a10ultrae的助力...   \n",
       "\n",
       "                                  template  cat_num  \\\n",
       "6                 [问询词0]和[问询词1]的[关键词0]是什么？        2   \n",
       "7          [问询词0]和[问询词1]的[关键词0]和[关键词1]是什么？        2   \n",
       "8   [问询词0]和[问询词1]的[关键词0]和[关键词1]和[关键词2]是什么？        2   \n",
       "9          [问询词0]和[问询词1]和[问询词2]的[关键词0]是什么？        2   \n",
       "10  [问询词0]和[问询词1]和[问询词2]的[关键词0]和[关键词1]是什么？        2   \n",
       "\n",
       "                               type  \\\n",
       "6   gen_same_keywords_for_models_v2   \n",
       "7   gen_same_keywords_for_models_v2   \n",
       "8   gen_same_keywords_for_models_v2   \n",
       "9   gen_same_keywords_for_models_v2   \n",
       "10  gen_same_keywords_for_models_v2   \n",
       "\n",
       "                                         final_prompt  \n",
       "6   {\"template\": \"[问询词0]和[问询词1]的[关键词0]是什么？\", \"repl...  \n",
       "7   {\"template\": \"[问询词0]和[问询词1]的[关键词0]和[关键词1]是什么？\"...  \n",
       "8   {\"template\": \"[问询词0]和[问询词1]的[关键词0]和[关键词1]和[关键词...  \n",
       "9   {\"template\": \"[问询词0]和[问询词1]和[问询词2]的[关键词0]是什么？\"...  \n",
       "10  {\"template\": \"[问询词0]和[问询词1]和[问询词2]的[关键词0]和[关键词...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cat_num==2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "607b8e03-22bb-4b02-bdd8-8e80518e0713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"primary_key_num\"] = df[\"template\"].apply(lambda x: x.count(\"问询\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "541f8089-8c05-4ba7-b337-a8962dbb9b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>gen</th>\n",
       "      <th>template</th>\n",
       "      <th>final_prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>cat_num</th>\n",
       "      <th>primary_key_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">gen_different_keywords_different_models_v2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">gen_same_keywords_for_models_v2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    cat  gen  \\\n",
       "type                                       cat_num primary_key_num             \n",
       "gen_different_keywords_different_models_v2 1       4                  3    3   \n",
       "                                                   6                  3    3   \n",
       "                                           2       4                  3    3   \n",
       "                                                   6                  3    3   \n",
       "                                           3       4                  3    3   \n",
       "                                                   6                  3    3   \n",
       "gen_same_keywords_for_models_v2            1       2                  3    3   \n",
       "                                                   3                  3    3   \n",
       "                                           2       2                  3    3   \n",
       "                                                   3                  3    3   \n",
       "                                           3       2                  3    3   \n",
       "                                                   3                  3    3   \n",
       "\n",
       "                                                                    template  \\\n",
       "type                                       cat_num primary_key_num             \n",
       "gen_different_keywords_different_models_v2 1       4                       3   \n",
       "                                                   6                       3   \n",
       "                                           2       4                       3   \n",
       "                                                   6                       3   \n",
       "                                           3       4                       3   \n",
       "                                                   6                       3   \n",
       "gen_same_keywords_for_models_v2            1       2                       3   \n",
       "                                                   3                       3   \n",
       "                                           2       2                       3   \n",
       "                                                   3                       3   \n",
       "                                           3       2                       3   \n",
       "                                                   3                       3   \n",
       "\n",
       "                                                                    final_prompt  \n",
       "type                                       cat_num primary_key_num                \n",
       "gen_different_keywords_different_models_v2 1       4                           3  \n",
       "                                                   6                           3  \n",
       "                                           2       4                           3  \n",
       "                                                   6                           3  \n",
       "                                           3       4                           3  \n",
       "                                                   6                           3  \n",
       "gen_same_keywords_for_models_v2            1       2                           3  \n",
       "                                                   3                           3  \n",
       "                                           2       2                           3  \n",
       "                                                   3                           3  \n",
       "                                           3       2                           3  \n",
       "                                                   3                           3  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"type\", \"cat_num\", \"primary_key_num\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0081148d-9e90-416d-9c53-1f36640a7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模板收集数据的转义表达和扩增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "f70cccafc28cb5cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T07:10:11.693120013Z",
     "start_time": "2024-04-29T07:10:11.646822268Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "输入json含义如下：\n",
    "1. template是一个问句，问句里面用[]符号括起来的部分是命名实体，其中“问询词”开头的是家庭扫拖机器人或者洗衣机\n",
    "2. replace是上述每个命名实体的具体值\n",
    "\n",
    "请你按以下步骤操作：\n",
    "1. 将template里面的每个命名实体替换成replace里面对应的值，当要替换“关键词”开头的所有命名实体的时候先把/()等特殊符号先去除再替换\n",
    "2. 再替换后的句子中去除标记实体的[]符号，然后把整个句子改写得语法通顺但是语义不能改变，改写中请保持“问询词”开头的命名实体作为整体不变\n",
    "3. 检查改写后的句子，如果句子不通顺则重新改写使句子通顺\n",
    "4. 在新生成的句子中，提取与原始“关键词”开头的所有命名实体对应的关键词并用括号[]括起来，每个关键词在语义上应该能代表它对应的原始实体的语义，所有关键词的数量要与原始“关键词”开头的命名实体数量一致\n",
    "\n",
    "请理解以下几个例子：\n",
    "例子1：\n",
    "输入：\n",
    "{{\"template\": \"[问询词0]的[关键词0]是多少？\", \"replace\": {{\"[问询词0]\": \"g20\", \"[关键词0]\": \"是否支持上下水\"}}}}\n",
    "输出：\n",
    "{{\"sentence\": \"请问g20是否[有上下水功能]？\", \"replace\": {{\"是否支持上下水\": \"有上下水功能\"}}}}\n",
    "\n",
    "例子2：\n",
    "输入：\n",
    "{{\"template\": \"[问询词0-0]和[问询词0-1]的[关键词0-0]是什么、[问询词1-0]的[关键词1-0]和[关键词1-1]是多少？\", \"replace\": {{\"[问询词0-0]\": \"g20\", \"[问询词0-1]\": \"a10\", \"[关键词0-0]\": \"是否支持银离子抑菌\", \"[问询词1-0]\": \"a10\", \"[关键词1-0]\": \"是否带遥控器\", \"[关键词1-1]\": \"水箱容量\"}}}}\n",
    "输出：\n",
    "{{\"sentence\": \"请问g20和a10是否[可以对银离子抑菌]，另外a10[带遥控器]吗、它[水箱有多大]？\", \"replace\": {{\"是否支持银离子抑菌\": \"可以对银离子抑菌\", \"是否带遥控器\": \"带遥控器\", \"水箱容量\": \"水箱有多大\"}}}}\n",
    "\n",
    "例子3：\n",
    "输入：\n",
    "{{\"template\": \"[问询词0]的[关键词0]是多少？\", \"replace\": {{\"[问询词0]\": \"g20\", \"[关键词0]\": \"浸泡功能\"}}}}\n",
    "绝对避免的输出(提取的实体包含不必要的东西，不简洁)包括：\n",
    "{{\"sentence\": \"请问g20[有哪些浸泡功能]？\", \"replace\": {{\"浸泡功能\": \"有哪些浸泡功能\"}}}}\n",
    "{{\"sentence\": \"g20[浸泡功能都有什么]？\", \"replace\": {{\"浸泡功能\": \"浸泡功能都有什么\"}}}}\n",
    "希望的输出：\n",
    "{{\"sentence\": \"请问g20有何[浸泡功能]？\", \"replace\": {{\"浸泡功能\": \"浸泡功能\"}}}}\n",
    "\n",
    "\n",
    "参考上面的例子，请对每个输入给出{}种不同的说法, 每种说法都要按照上述4个步骤依次做一遍，每种说法对应一个json，放在列表里面返回, 除此之外不要给出任务其他的信息，即如果要求给出n种说法，则输出\n",
    "[json_0, json_1, json_2, ..., json_n-1]，如果要给出1种说法，则输出[json_0]\n",
    "\n",
    "输入：\n",
    "{}\n",
    "输出：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "46a127af932566b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T08:49:19.696828430Z",
     "start_time": "2024-04-29T08:49:19.655087163Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"https://csagent.openai.azure.com/\",\n",
    "    api_key=\"346ac6661e314a9d8b91b6a99202ba42\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "8a3ad74c82cc7445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T08:49:21.188647167Z",
     "start_time": "2024-04-29T08:49:21.181983065Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_answer(prompt, input_json, n, model=\"gpt-4-8k\"): # model = \"deployment_name\"\n",
    "    response = client.chat.completions.create(\n",
    "    model=model, # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt.format(n, input_json)},\n",
    "    ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f60eba6868225aa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T10:05:08.321120636Z",
     "start_time": "2024-04-29T08:52:05.011602364Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0004031658172607422\n",
      "10\n",
      "535.0191197395325\n",
      "20\n",
      "438.8204011917114\n",
      "30\n",
      "921.7273585796356\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "prev_time = time.time()\n",
    "for i in range(df.shape[0]):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        cur_time = time.time()\n",
    "        print(cur_time-prev_time)\n",
    "        prev_time = cur_time\n",
    "    if df[\"cat_num\"].iloc[i] == 1:\n",
    "        n = 12\n",
    "    else:\n",
    "        n = 4\n",
    "    item = generate_answer(prompt, df[\"final_prompt\"].iloc[i], n)\n",
    "    result.append(item)\n",
    "    joblib.dump(item, \"/data/dataset/kefu/gpt4_template_v2/{}.jsonl\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc30531b-1c59-426b-ba46-2074e800983c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 7)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f5e5cdf3625ed945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T10:34:02.334714813Z",
     "start_time": "2024-04-29T10:34:02.302279898Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(df.shape[0]):\n",
    "    item = joblib.load(\"/data/dataset/kefu/gpt4_template_v2/{}.jsonl\".format(i))\n",
    "    result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f11ca0ce-4c14-4436-9da3-b6a66abd9f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d043f9d0-d33c-4a92-8133-c67b44fb47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for i in range(df.shape[0]):\n",
    "    if (df.iloc[i][\"type\"]==\"gen_different_keywords_different_models_v2\"\n",
    "            )&(df.iloc[i][\"cat_num\"]==1)|(df.iloc[i][\"type\"]==\"gen_different_keywords_different_models_v2\"\n",
    "            )&(df.iloc[i][\"cat_num\"]==2):\n",
    "        error_list.append(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "939465c9-a8d8-4ec6-8569-f395575263db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.000255584716796875\n",
      "10\n",
      "615.4492988586426\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "prev_time = time.time()\n",
    "for index, i in enumerate(error_list):\n",
    "    if index % 10 == 0:\n",
    "        print(index)\n",
    "        cur_time = time.time()\n",
    "        print(cur_time-prev_time)\n",
    "        prev_time = cur_time\n",
    "    if df[\"cat_num\"].iloc[i] == 1:\n",
    "        n = 12\n",
    "    else:\n",
    "        n = 4\n",
    "    item = generate_answer(prompt, df[\"final_prompt\"].iloc[i], n)\n",
    "    result.append(item)\n",
    "    joblib.dump(item, \"/data/dataset/kefu/gpt4_template_v2_2/{}.jsonl\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "994d32ef-128b-4926-a0ef-6c16c9ed44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(df.shape[0]):\n",
    "    if i not in error_list:\n",
    "        item = joblib.load(\"/data/dataset/kefu/gpt4_template_v2/{}.jsonl\".format(i))\n",
    "    else:\n",
    "        item = joblib.load(\"/data/dataset/kefu/gpt4_template_v2_2/{}.jsonl\".format(i))\n",
    "    result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "406d63f4-b694-428d-b4e9-1ad7c2e336fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "11f7e95e1bcb4a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T10:50:43.954440541Z",
     "start_time": "2024-04-29T10:50:43.942216149Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process(raw_string):\n",
    "    processed_string = raw_string.replace('\\n', '').replace('\\'', '').replace(\n",
    "        '\"{sentence\"', '{\"sentence\"'\n",
    "    ).replace('\"{', '{').replace('}\"', '}').replace('\"\"', '\"')\n",
    "    \n",
    "    # 加上外层的双引号\n",
    "    # processed_string = processed_string[1:-1]\n",
    "    return processed_string\n",
    "    \n",
    "new_result = []\n",
    "for i in range(len(result)):\n",
    "    # print(i)\n",
    "    item = result[i]\n",
    "    \n",
    "    try:\n",
    "        item = json.loads(item)\n",
    "    except:\n",
    "        try:\n",
    "            item = json.loads(process(item))\n",
    "        except:\n",
    "            p = re.compile(r'\\{(.*?)\\}')\n",
    "            matches = p.findall(item)\n",
    "            item = [json.loads('{'+m+'}}') for m in matches]\n",
    "    item = [json.loads(i) if isinstance(i, str) else i for i in item]\n",
    "    new_result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2d2860ed-1ba7-4c11-8978-2820e95eb7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "727c13bd01758905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T10:53:54.655844648Z",
     "start_time": "2024-04-29T10:53:54.650815469Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[\"augment\"] = new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c6683fbd-0ffc-45dd-b7a8-f1d559fb634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 8)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cff5a682da2c1a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T05:42:05.776482590Z",
     "start_time": "2024-04-30T05:42:05.735320914Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_exploded = df.explode(\"augment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "30a6827556022f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T05:42:06.299762326Z",
     "start_time": "2024-04-30T05:42:06.285857640Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d7d40872fa1b98a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T05:42:06.794510400Z",
     "start_time": "2024-04-30T05:42:06.778186750Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_exploded['question'] =  df_exploded['augment'].apply(lambda x: x[\"sentence\"].replace(\"[\", \"\").replace(\"]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4ac56769d47fcdae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T05:42:18.694347340Z",
     "start_time": "2024-04-30T05:42:18.678199754Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "error_indices = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment'].iloc[i][\"replace\"]\n",
    "    for key in replace:\n",
    "        if key.find(\"[\")>=0:\n",
    "            error_indices.append(i)\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d6463a7-92f0-4908-aabd-0389a3156299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 9)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3b39a077891262d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T05:42:19.157183934Z",
     "start_time": "2024-04-30T05:42:19.138461121Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.drop([df_exploded.index[i] for i in error_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "eb334afc-a964-4af1-b39b-6a99ff10761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 9)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b727eb06-d182-4b8f-b5b5-5e042e27438c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'm1和h1的面板操作流程是什么？',\n",
       " 'prompt': [{'primary_value': 'm1',\n",
       "   'key': '面板操作流程',\n",
       "   '面板操作流程': '①选择模式：洗烘/洗涤/烘干\\n②选定程序：混合/快速/自定义等\\n③调节程序状态：转速/漂洗次数/温度\\n④启动程序'},\n",
       "  {'primary_value': 'h1',\n",
       "   'key': '面板操作流程',\n",
       "   '面板操作流程': '①选择模式：洗烘/洗涤/烘干\\n②选定程序：标准/快速等\\n③调节程序状态：干衣度/转速/漂洗次数/温度\\n④启动程序'}],\n",
       " 'replace': {'[问询词0]': 'm1', '[问询词1]': 'h1', '[关键词0]': '面板操作流程'}}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.gen.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5292cdbccefceda3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T09:07:06.939059736Z",
     "start_time": "2024-04-30T09:07:06.817160181Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ner_list = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment'].iloc[i][\"replace\"]\n",
    "    primaries = [j['primary_value'] for j in df_exploded['gen'].iloc[i]['prompt']]\n",
    "    flag = False\n",
    "    entity = []\n",
    "    for key in replace:\n",
    "        if replace[key] in primaries:\n",
    "            print(i)\n",
    "            flag = True\n",
    "            break \n",
    "        entity.append(replace[key])\n",
    "    if flag:\n",
    "        print(i, 'type1 error')\n",
    "        ner_list.append(np.nan)\n",
    "        continue\n",
    "    question =  df_exploded['question'].iloc[i]\n",
    "    ner = {}\n",
    "    for item in entity:\n",
    "        matches = list(re.finditer(item, question))\n",
    "        loc = [[j.start(), j.end()-1] for j in matches]\n",
    "        ner[item] = loc \n",
    "    ner_list.append({\"name\": ner})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "00f99f6c-19f7-4a71-a1db-567f8a2d3c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat                                                          washing\n",
       "gen                {'question': 'm1和h1的面板操作流程是什么？', 'prompt': [{'...\n",
       "template                                    [问询词0]和[问询词1]的[关键词0]是什么？\n",
       "cat_num                                                            1\n",
       "type                                 gen_same_keywords_for_models_v2\n",
       "final_prompt       {\"template\": \"[问询词0]和[问询词1]的[关键词0]是什么？\", \"repl...\n",
       "primary_key_num                                                    2\n",
       "augment            {'sentence': '关于m1和h1的[操作过程]可以介绍一下吗？', 'replac...\n",
       "question                                        关于m1和h1的操作过程可以介绍一下吗？\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f388b270-1490-4644-b24b-e0e04f76f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"ner_list\"] = ner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6454a6bd-f5a5-410d-8fa5-c09d7678d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 10)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3d060bc8-eb22-469e-9ac7-0f318c155832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded[df_exploded[\"ner_list\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4db63580-fab3-45a5-a885-1ba117432951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 10)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8d87b082-265b-4752-9271-454f83804277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ner_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>请问m1和h1的操作方法是怎样的？</td>\n",
       "      <td>{'name': {'操作方法': [[8, 11]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你能告诉我m1和h1的操作面板流程吗？</td>\n",
       "      <td>{'name': {'操作面板流程': [[11, 16]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>我想知道m1和h1的操作方式？</td>\n",
       "      <td>{'name': {'操作方式': [[10, 13]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>可以介绍一下m1和h1的面板操控过程吗？</td>\n",
       "      <td>{'name': {'面板操控过程': [[12, 17]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m1和h1的操控操作步骤是怎样的？</td>\n",
       "      <td>{'name': {'操控操作步骤': [[6, 11]]}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               question                          ner_list\n",
       "0     请问m1和h1的操作方法是怎样的？     {'name': {'操作方法': [[8, 11]]}}\n",
       "1   你能告诉我m1和h1的操作面板流程吗？  {'name': {'操作面板流程': [[11, 16]]}}\n",
       "2       我想知道m1和h1的操作方式？    {'name': {'操作方式': [[10, 13]]}}\n",
       "3  可以介绍一下m1和h1的面板操控过程吗？  {'name': {'面板操控过程': [[12, 17]]}}\n",
       "4     m1和h1的操控操作步骤是怎样的？   {'name': {'操控操作步骤': [[6, 11]]}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_exploded[[\"question\", \"ner_list\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "524a642b-2519-4de9-9a70-b461735918c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '请问m1和h1有多少[浸泡功能]，h1neo和h1的[控制方式]是什么？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '能介绍一下m1和h1所含的[浸泡功能]，以及h1neo和h1的[控制方式]吗？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': 'm1和h1的[浸泡功能]、h1neo和h1的[控制方式]是什么呢？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': 'm1和h1的[浸泡功能]，以及h1neo和h1的[控制方式]能告诉我吗？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '我想了解一下m1和h1的[浸泡功能]以及h1neo和h1的[控制方式]。', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '请告诉我m1和h1有什么[浸泡功能]以及h1neo和h1的[控制方式]。', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '我能了解一下m1和h1的[浸泡功能]，以及h1neo和h1的[控制方式]吗？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '可以告诉我m1和h1的[浸泡功能]，还有h1neo和h1的[控制方式]是什么吗？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '能否告知m1和h1的具备哪些[浸泡功能]，以及h1neo和h1的[控制方式]？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '请介绍一下m1和h1的[浸泡功能]以及h1neo和h1的[控制方式]。', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '请问m1和h1的[浸泡功能]是什么，h1neo和h1又是如何[控制]的？', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制'}}\n",
      "{'sentence': '我想了解m1和h1的[浸泡功能]及h1neo和h1的[控制方式]。', 'replace': {'浸泡功能': '浸泡功能', '控制方式': '控制方式'}}\n",
      "{'sentence': '请问h1和m1的[APP程序]有哪些、它们[都有哪些标配的产品]，另外h1neo和m1的[UVC紫外线除菌功能]如何、他们属于[哪种产品类型]？', 'replace': {'APP程序': 'APP程序', '标配': '都有哪些标配的产品', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '哪种产品类型'}}\n",
      "{'sentence': '能否告知h1和m1所使用的[APP程序]和[标配设备]，以及h1neo和m1支持的[UVC紫外线除菌功能]，他们被归到[哪一类产品]？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '哪一类产品'}}\n",
      "{'sentence': '想了解一下h1与m1的[APP程序]和[标配物品]，还有h1neo与m1的[UVC紫外线除菌能力]，它们是[什么样的产品类型]？', 'replace': {'APP程序': 'APP程序', '标配': '标配物品', 'UVC紫外线除菌': 'UVC紫外线除菌能力', '产品类型': '什么样的产品类型'}}\n",
      "{'sentence': '请问h1、m1的[APP程序]和[标配设备]，以及h1neo、m1的[UVC紫外线除菌功能]和它们的[产品类型]具体是什么？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '产品类型'}}\n",
      "{'sentence': '想问下h1和m1的[APP程序]是什么、它们的[标配]有哪些，还有h1neo和m1的[UVC紫外线除菌功能]怎样，它们都是[哪种产品类型]的？', 'replace': {'APP程序': 'APP程序', '标配': '标配', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '哪种产品类型'}}\n",
      "{'sentence': '请问h1和m1使用的[APP程序]具体是什么、他们的[标配设备]有哪些,同时我也想了解h1neo、m1的[UVC紫外线除菌功能]如何，以及他们的[产品类型]是什么类型的？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '产品类型'}}\n",
      "{'sentence': '请问h1、m1所使用的[APP程序]和他们的[标配设备]有哪些？另外对于h1neo、m1的[UVC紫外线除菌功能]以及他们的[产品类型]，我也非常感兴趣，能告知一下吗？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '产品类型'}}\n",
      "{'sentence': '我希望了解h1和m1关于[APP程序]以及它们的[标配设备]，另外还想了解下h1neo和m1的[UVC紫外线除菌功能]，他们属于[什么类型的产品]？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '什么类型的产品'}}\n",
      "{'sentence': '我想了解一下h1、m1所具备的[APP程序]以及他们的[标配设备]，同时对于h1neo和m1的[UVC紫外线除菌功能]以及他们的[产品类型]，我也非常感兴趣，能详细告知一下吗？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '产品类型'}}\n",
      "{'sentence': '我想知道h1和m1使用的[APP程序]是什么、他们的[标配设备]都有哪些，同样也很对h1neo、m1的[UVC紫外线除菌功能]以及他们的[产品类型]感兴趣，您能告知一下吗？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '产品类型'}}\n",
      "{'sentence': '请问h1和m1所使用的[APP程序]是什么，他们的[标配设备]有哪些。同时，h1neo和m1的[UVC紫外线除菌功能]如何，他们的[产品类型]是什么？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '产品类型'}}\n",
      "{'sentence': '我想知道h1和m1的[APP程序]以及他们的[标配设备]有哪些，还有h1neo和m1的[UVC紫外线除菌功能]是什么样的，它们是属于[哪种产品类型]的？', 'replace': {'APP程序': 'APP程序', '标配': '标配设备', 'UVC紫外线除菌': 'UVC紫外线除菌功能', '产品类型': '哪种产品类型'}}\n",
      "{'sentence': '请问m1和h1neo的[电机类型]、[开关方式]以及[洗涣液容量]是什么？同样地，h1neo和h1的[脱水噪音]、[洗涤程序时间]以及[小件程序时长]分别是多少？', 'replace': {'电机类型': '电机类型', '开合方式': '开关方式', '洗衣液容量': '洗涣液容量', '脱水噪音': '脱水噪音', '洗涤程序时间': '洗涤程序时间', '小件程序时长': '小件程序时长'}}\n",
      "{'sentence': 'm1和h1neo都[使用什么电机]、[开关的方式]和[洗涣液的容量]是多少？而h1neo和h1在[脱水时的噪音]、[洗涤过程所需的时间]和[小件程序的时长]上有何不同？', 'replace': {'电机类型': '使用什么电机', '开合方式': '开关的方式', '洗衣液容量': '洗涣液的容量', '脱水噪音': '脱水时的噪音', '洗涤程序时间': '洗涤过程所需的时间', '小件程序时长': '小件程序的时长'}}\n",
      "{'sentence': '你能告诉我m1和h1neo的[电机是什么类型]、[开关如何操作]和[洗涣液的容量]吗？另外，h1neo和h1的[脱水时的噪音]、[洗涤程序需要多少时间]以及[小件程序的时长]分别是多少？', 'replace': {'电机类型': '电机是什么类型', '开合方式': '开关如何操作', '洗衣液容量': '洗涣液的容量', '脱水噪音': '脱水时的噪音', '洗涤程序时间': '洗涤程序需要多少时间', '小件程序时长': '小件程序的时长'}}\n",
      "{'sentence': '我想了解一下m1和h1neo的[电机种类]、[开关操作方法]以及[能装多少洗涣液]？同时，h1neo和h1的[在脱水时的噪音]、[洗涤过程大约需要多少时间]以及[小件程序时长]可以告诉我吗？', 'replace': {'电机类型': '电机种类', '开合方式': '开关操作方法', '洗衣液容量': '能装多少洗涣液', '脱水噪音': '在脱水时的噪音', '洗涤程序时间': '洗涤过程大约需要多少时间', '小件程序时长': '小件程序时长'}}\n",
      "{'sentence': '能告诉我m1和h1neo[电机采用的是什么类型]、[如何操作开关]和[洗涣液的容量]是多少吗？同样地，h1neo和h1的[脱水过程中的噪音]、[整个洗涤程序需要多久]以及[小件程序的时长]有何区别？', 'replace': {'电机类型': '电机采用的是什么类型', '开合方式': '如何操作开关', '洗衣液容量': '洗涣液的容量', '脱水噪音': '脱水过程中的噪音', '洗涤程序时间': '整个洗涤程序需要多久', '小件程序时长': '小件程序的时长'}}\n",
      "{'sentence': '关于m1和h1neo，我想知道它们的[电机是何种类型]、[开关操作是怎样的]以及[洗涣液容量有多少]；对于h1neo和h1，我想询问[脱水时会产生多少噪音]、[一个洗涤程序需要多少时间]以及[小件程序会持续多久]。', 'replace': {'电机类型': '电机是何种类型', '开合方式': '开关操作是怎样的', '洗衣液容量': '洗涣液容量有多少', '脱水噪音': '脱水时会产生多少噪音', '洗涤程序时间': '一个洗涤程序需要多少时间', '小件程序时长': '小件程序会持续多久'}}\n",
      "{'sentence': '对于m1和h1neo，我想了解它们的[电机是什么类型]、[开关操作方式]以及[洗涣液的装载量]；与此同时，我也对h1neo和h1的[脱水过程的噪音]、[洗涤程序所需的时间]以及[小件清洗的程序时长]感兴趣。', 'replace': {'电机类型': '电机是什么类型', '开合方式': '开关操作方式', '洗衣液容量': '洗涣液的装载量', '脱水噪音': '脱水过程的噪音', '洗涤程序时间': '洗涤程序所需的时间', '小件程序时长': '小件清洗的程序时长'}}\n",
      "{'sentence': '我想对m1和h1neo的[电机类型]、[开关操作]以及[洗涣液的存储容量]有个了解，还有h1neo和h1的[脱水时产生的噪音]、[做一次洗涤程序需要的时间]以及[小件程序的运行时长]是多少。', 'replace': {'电机类型': '电机类型', '开合方式': '开关操作', '洗衣液容量': '洗涣液的存储容量', '脱水噪音': '脱水时产生的噪音', '洗涤程序时间': '做一次洗涤程序需要的时间', '小件程序时长': '小件程序的运行时长'}}\n",
      "{'sentence': 'm1和h1neo的[电机类别]、[开关如何启动]以及[洗涣液的装载量]是多少？而在h1neo和h1中，你知道[在脱水时的噪音大小]、[进行一次洗涤所需要的时间]以及[小件程序所需的时长]吗？', 'replace': {'电机类型': '电机类别', '开合方式': '开关如何启动', '洗衣液容量': '洗涣液的装载量', '脱水噪音': '在脱水时的噪音大小', '洗涤程序时间': '进行一次洗涤所需要的时间', '小件程序时长': '小件程序所需的时长'}}\n",
      "{'sentence': '能否告诉我m1和h1neo所采用的[电机类型]、[开关如何使用]以及[洗涣液的装载容量]是多少？另外，h1neo和h1在[脱水时的噪音水平]、[整个洗涤程序所花费的时间]以及[小件程序的运行时间]各是什么？', 'replace': {'电机类型': '电机类型', '开合方式': '开关如何使用', '洗衣液容量': '洗涣液的装载容量', '脱水噪音': '脱水时的噪音水平', '洗涤程序时间': '整个洗涤程序所花费的时间', '小件程序时长': '小件程序的运行时间'}}\n",
      "{'sentence': '你能告诉我关于m1和h1neo的[电机是怎样的]、[如何进行开关操作]，还有[洗涣液的总容量]吗？此外，h1neo和h1在[脱水阶段的噪音]、[进行一次洗涤的所需时间]以及[小件程序所需要的时长]你有了解吗？', 'replace': {'电机类型': '电机是怎样的', '开合方式': '如何进行开关操作', '洗衣液容量': '洗涣液的总容量', '脱水噪音': '脱水阶段的噪音', '洗涤程序时间': '进行一次洗涤的所需时间', '小件程序时长': '小件程序所需要的时长'}}\n",
      "{'sentence': '关于m1和h1neo，它们的[电机是何种类型]、[开关怎样操作]以及[洗涣液可以装多少]我很想知道；同样，h1neo和h1[脱水时会有多大噪音]、[一个洗涤程序需要多长时间]以及[小件程序持续多久]，你能告诉我吗？', 'replace': {'电机类型': '电机是何种类型', '开合方式': '开关怎样操作', '洗衣液容量': '洗涣液可以装多少', '脱水噪音': '脱水时会有多大噪音', '洗涤程序时间': '一个洗涤程序需要多长时间', '小件程序时长': '小件程序持续多久'}}\n",
      "{'sentence': '请问h1neo、m1、h1的[水龙头是什么类型]？另外，h1、m1、h1neo的[电源线有多长]？', 'replace': {'水龙头类型': '水龙头是什么类型', '电源线长度': '电源线有多长'}}\n",
      "{'sentence': '能告诉我h1neo、m1、h1[使用的是什么样的水龙头]，以及h1、m1、h1neo的[电源线的长度是多少]吗？', 'replace': {'水龙头类型': '使用的是什么样的水龙头', '电源线长度': '电源线的长度是多少'}}\n",
      "{'sentence': '对于h1neo、m1和h1，它们的[水龙头是何种类型]？而h1、m1、h1neo的[电源线长多少]呢？', 'replace': {'水龙头类型': '水龙头是何种类型', '电源线长度': '电源线长多少'}}\n",
      "{'sentence': 'h1neo、m1、h1都[使用哪一种水龙头]？以及，h1、m1、h1neo的[电源线长度有多长]？', 'replace': {'水龙头类型': '使用哪一种水龙头', '电源线长度': '电源线长度有多长'}}\n",
      "{'sentence': 'h1neo、m1和h1是[使用哪种类型的水龙头]，h1、m1、h1neo的[电源线长度具体是多少]呢？', 'replace': {'水龙头类型': '使用哪种类型的水龙头', '电源线长度': '电源线长度具体是多少'}}\n",
      "{'sentence': '你能告诉我h1neo、m1、h1[采用什么类型的水龙头]，并且h1、m1、h1neo的[电源线有多长]吗？', 'replace': {'水龙头类型': '采用什么类型的水龙头', '电源线长度': '电源线有多长'}}\n",
      "{'sentence': '关于h1neo、m1、h1请问它们的[水龙头是何类型]，h1、m1、h1neo的[电源线长度是多少]呢？', 'replace': {'水龙头类型': '水龙头是何类型', '电源线长度': '电源线长度是多少'}}\n",
      "{'sentence': '可以知道h1neo、m1、h1分别[采用何种类型的水龙头]么？以及h1、m1、h1neo的[电源线长度具体有多长]？', 'replace': {'水龙头类型': '采用何种类型的水龙头', '电源线长度': '电源线长度具体有多长'}}\n",
      "{'sentence': '对于h1neo、m1、h1它们[使用的是哪一类的水龙头]，另外h1、m1、h1neo的[电源线是多长]？', 'replace': {'水龙头类型': '使用的是哪一类的水龙头', '电源线长度': '电源线是多长'}}\n",
      "{'sentence': 'h1neo、m1和h1[是使用哪种类型的水龙头]？h1、m1、h1neo的[电源线具体长多少]呢？', 'replace': {'水龙头类型': '是使用哪种类型的水龙头', '电源线长度': '电源线具体长多少'}}\n",
      "{'sentence': 'h1neo、m1、h1采用的[水龙头是什么类型]？h1、m1和h1neo的[电源线长有多少]？', 'replace': {'水龙头类型': '水龙头是什么类型', '电源线长度': '电源线长有多少'}}\n",
      "{'sentence': '请问h1neo、m1和h1的[水龙头类型是什么]，h1、m1和h1neo的[电源线有多长]呢？', 'replace': {'水龙头类型': '水龙头类型是什么', '电源线长度': '电源线有多长'}}\n",
      "{'sentence': '我想了解一下h1、h1neo、m1各自[洗涤时间]多长、[耗电情况如何]，另外h1、h1neo、m1的[重量]是多少、[有哪些颜色]？', 'replace': {'洗涤程序时间': '洗涤时间', '耗电': '耗电情况如何', '毛重': '重量', '颜色分类': '有哪些颜色'}}\n",
      "{'sentence': 'h1、h1neo、m1[洗涤所需时间]是多少、[消耗电量]多少，以及h1、h1neo、m1[具体重量]和[颜色选择]有哪些？', 'replace': {'洗涤程序时间': '洗涤所需时间', '耗电': '消耗电量', '毛重': '具体重量', '颜色分类': '颜色选择'}}\n",
      "{'sentence': '请问h1、h1neo、m1[洗涤时间长短]、[电量消耗]分别是多少，并且h1、h1neo、m1的[总重量]、[颜色种类]是什么？', 'replace': {'洗涤程序时间': '洗涤时间长短', '耗电': '电量消耗', '毛重': '总重量', '颜色分类': '颜色种类'}}\n",
      "{'sentence': '您能告诉我h1、h1neo、m1[洗涤过程时间]、[电力消耗]吗，以及h1、h1neo、m1的[实际重量]、[颜色选项]呢？', 'replace': {'洗涤程序时间': '洗涤过程时间', '耗电': '电力消耗', '毛重': '实际重量', '颜色分类': '颜色选项'}}\n",
      "{'sentence': '我想了解一下h1、h1neo、m1[洗涤所需时长]、[用电量]，还有h1、h1neo、m1的[净重]、[颜色类别]可以吗？', 'replace': {'洗涤程序时间': '洗涤所需时长', '耗电': '用电量', '毛重': '净重', '颜色分类': '颜色类别'}}\n",
      "{'sentence': '能否提供一些关于h1、h1neo、m1的[洗涤程序所需时间]、[电量耗费]，以及h1、h1neo、m1的[产品重量]、[颜色版本]的信息？', 'replace': {'洗涤程序时间': '洗涤程序所需时间', '耗电': '电量耗费', '毛重': '产品重量', '颜色分类': '颜色版本'}}\n",
      "{'sentence': '请问h1、h1neo、m1的[洗涤流程时长]、[电量使用]是多少，对于h1、h1neo、m1的[产品毛重]、[颜色系列]方面有何了解？', 'replace': {'洗涤程序时间': '洗涤流程时长', '耗电': '电量使用', '毛重': '产品毛重', '颜色分类': '颜色系列'}}\n",
      "{'sentence': '关于h1、h1neo、m1[洗涤周期时间]、[电量损耗]能了解一下吗，同样的h1、h1neo、m1的[产品重]、[颜色分布]也想了解？', 'replace': {'洗涤程序时间': '洗涤周期时间', '耗电': '电量损耗', '毛重': '产品重', '颜色分类': '颜色分布'}}\n",
      "{'sentence': '请提供h1、h1neo、m1的[洗涤步骤时间]、[电力使用]，以及h1、h1neo、m1的[质量]、[可选颜色]的相关信息。', 'replace': {'洗涤程序时间': '洗涤步骤时间', '耗电': '电力使用', '毛重': '质量', '颜色分类': '可选颜色'}}\n",
      "{'sentence': '想了解一下h1、h1neo、m1的[洗涤时长]、[电源消耗]，h1、h1neo、m1的[产品质量]、[颜色种类]是怎么样的？', 'replace': {'洗涤程序时间': '洗涤时长', '耗电': '电源消耗', '毛重': '产品质量', '颜色分类': '颜色种类'}}\n",
      "{'sentence': '可否告知h1、h1neo、m1的[洗涤时间]、[用电情况]是如何，以及h1、h1neo、m1[重量如何]、[颜色选择]有哪些？', 'replace': {'洗涤程序时间': '洗涤时间', '耗电': '用电情况', '毛重': '重量如何', '颜色分类': '颜色选择'}}\n",
      "{'sentence': '我想查询一下h1、h1neo、m1的[洗涤程序耗时]、[电力花费]以及h1、h1neo、m1的[重量]、[可供选择的颜色]。', 'replace': {'洗涤程序时间': '洗涤程序耗时', '耗电': '电力花费', '毛重': '重量', '颜色分类': '可供选择的颜色'}}\n",
      "{'sentence': '请问m1、h1与h1neo的[的颜色分类]，[整体包装尺寸]及[机器尺寸]是什么？另外，h1、m1、h1neo是否[支持断电记忆]，[电源线有多长]，以及具有多少[额定加热输入功率]?', 'replace': {'颜色分类': '的颜色分类', '包装尺寸': '整体包装尺寸', '机器尺寸': '机器尺寸', '断电记忆': '支持断电记忆', '电源线长度': '电源线有多长', '额定加热输入功率': '额定加热输入功率'}}\n",
      "{'sentence': '想了解一下m1、h1和h1neo的[颜色分类]，[包装尺寸]以及[具体机器尺寸]是如何的？还有，h1、m1和h1neo的[断电记忆功能]，[电源线的长度]，[额定的加热输入功率]具体是多少？', 'replace': {'颜色分类': '颜色分类', '包装尺寸': '包装尺寸', '机器尺寸': '具体机器尺寸', '断电记忆': '断电记忆功能', '电源线长度': '电源线的长度', '额定加热输入功率': '额定的加热输入功率'}}\n",
      "{'sentence': '能不能告诉我m1、h1和h1neo的[颜色分类]、[包装的尺寸]、[机器的尺寸]是什么？还有h1、m1和h1neo是否[支持断电记忆]，[电源线有多长]，以及[额定加热输入功率]是多少？', 'replace': {'颜色分类': '颜色分类', '包装尺寸': '包装的尺寸', '机器尺寸': '机器的尺寸', '断电记忆': '支持断电记忆', '电源线长度': '电源线有多长', '额定加热输入功率': '额定加热输入功率'}}\n",
      "{'sentence': '我想知道m1、h1和h1neo的[颜色有哪些]，[占用的包装空间有多大]，[机器本身有多大]。还有h1、m1和h1neo有没有[断电记忆功能]，[电源线有多长]，以及[额定加热的输入功率]具体有多少？', 'replace': {'颜色分类': '颜色有哪些', '包装尺寸': '占用的包装空间有多大', '机器尺寸': '机器本身有多大', '断电记忆': '断电记忆功能', '电源线长度': '电源线有多长', '额定加热输入功率': '额定加热的输入功率'}}\n",
      "{'sentence': '我有点好奇m1、h1和h1neo的[颜色有什么样的分类]，[包装的大小]，以及[机器的大小]是多少呢？另外，h1、m1、h1neo[是否支持断电记忆]，[电源线长多少]，以及[额定加热的输入功率]具体是多少？', 'replace': {'颜色分类': '颜色有什么样的分类', '包装尺寸': '包装的大小', '机器尺寸': '机器的大小', '断电记忆': '是否支持断电记忆', '电源线长度': '电源线长多少', '额定加热输入功率': '额定加热的输入功率'}}\n",
      "{'sentence': '我很想知道m1、h1和h1neo的[颜色有几种]、[包装盒尺寸]及[实际的机器尺寸]有多大。另外，h1、m1、h1neo是否能[实现断电记忆]，[电源线是多长]，以及它们的[额定加热输入功率]是多少呢？', 'replace': {'颜色分类': '颜色有几种', '包装尺寸': '包装盒尺寸', '机器尺寸': '实际的机器尺寸', '断电记忆': '实现断电记忆', '电源线长度': '电源线是多长', '额定加热输入功率': '额定加热输入功率'}}\n",
      "{'sentence': '想这样了解下，m1、h1和h1neo他们的[颜色分类有几种]，[盒子的尺寸]，以及[机器的实际尺寸]具体有多大。h1、m1、h1neo是否有[断电记忆的功能]，现在[电源线有多长]，以及他们的[温差能力有多大]?', 'replace': {'颜色分类': '颜色分类有几种', '包装尺寸': '盒子的尺寸', '机器尺寸': '机器的实际尺寸', '断电记忆': '断电记忆的功能', '电源线长度': '电源线有多长', '额定加热输入功率': '温差能力有多大'}}\n",
      "{'sentence': '想请教下，m1、h1和h1neo分别有哪些[颜色分类]，他们[包装的尺寸]和[机器本身的尺寸]是多少呢？还有，h1、m1、h1neo他们[有断电记忆功能吗]，[电源线有多长]，他们的[额定加热输入功率要多少]呢？', 'replace': {'颜色分类': '颜色分类', '包装尺寸': '包装的尺寸', '机器尺寸': '机器本身的尺寸', '断电记忆': '有断电记忆功能吗', '电源线长度': '电源线有多长', '额定加热输入功率': '额定加热输入功率要多少'}}\n",
      "{'sentence': '请问下，m1、h1和h1neo的[颜色分类]，[包装占用的空间大小]，以及[机器实际的尺寸]是多少呢？并且，他们的[断电记忆能力]，[电源线的长度]，以及[额定的加热输入功率]具体要多少？', 'replace': {'颜色分类': '颜色分类', '包装尺寸': '包装占用的空间大小', '机器尺寸': '机器实际的尺寸', '断电记忆': '断电记忆能力', '电源线长度': '电源线的长度', '额定加热输入功率': '额定的加热输入功率'}}\n",
      "{'sentence': '可以告诉我m1、h1和h1neo的[有什么颜色分类]，[包装尺寸有多大]，[机器的尺寸是多少]吗？另外他们是否有[断电记忆的功能]，[电源线长度是多少]，以及[额定加热输入功率是多大]？', 'replace': {'颜色分类': '有什么颜色分类', '包装尺寸': '包装尺寸有多大', '机器尺寸': '机器的尺寸是多少', '断电记忆': '断电记忆的功能', '电源线长度': '电源线长度是多少', '额定加热输入功率': '额定加热输入功率是多大'}}\n",
      "{'sentence': '我想询问m1、h1和h1neo的[颜色分类有些什么]，[它们的包装尺寸]，以及[机器尺寸是多大]？再加上h1、m1、h1neo的[是否支持断电记忆功能]，[电源线长度的问题]以及[额定加热输入功率是多少]？', 'replace': {'颜色分类': '颜色分类有些什么', '包装尺寸': '它们的包装尺寸', '机器尺寸': '机器尺寸是多大', '断电记忆': '是否支持断电记忆功能', '电源线长度': '电源线长度的问题', '额定加热输入功率': '额定加热输入功率是多少'}}\n",
      "{'sentence': 'g10spure和p10spro上下水版是如何[拖地]的，而p10和g10spro的[最大高度]是多少？', 'replace': {'拖地方式': '拖地', '最高高度': '最大高度'}}\n",
      "{'sentence': '可以问一下g10spure和p10spro上下水版的[拖地模式]，以及p10和g10spro的[高度上限]吗？', 'replace': {'拖地方式': '拖地模式', '最高高度': '高度上限'}}\n",
      "{'sentence': '关于g10spure和p10spro上下水版的[拖地策略]，以及p10和g10spro的[高度最大限制]，你能告诉我吗？', 'replace': {'拖地方式': '拖地策略', '最高高度': '高度最大限制'}}\n",
      "{'sentence': '请问你知道g10spure和p10spro上下水版的[擦拭地面的方式]，以及p10和g10spro的[高度峰值]吗？', 'replace': {'拖地方式': '擦拭地面的方式', '最高高度': '高度峰值'}}\n",
      "{'sentence': '请问m1和g20标准版是否[配备遥控器]，[他们的套餐类型]是什么，另外p10spro和h1neo的[打算摆放在多大的地方]和[基座水箱的体积]？', 'replace': {'是否带遥控器': '配备遥控器', '套餐类型': '他们的套餐类型', '建议摆放尺寸': '打算摆放在多大的地方', '基座水箱容量': '基座水箱的体积'}}\n",
      "{'sentence': '想了解一下m1和g20标准版是否[带有遥控器]，他们[的套餐类型]是什么，以及p10spro和h1neo的[合适的摆放尺寸]有多大、他们[基座的水箱容量]有多少？', 'replace': {'是否带遥控器': '带有遥控器', '套餐类型': '的套餐类型', '建议摆放尺寸': '合适的摆放尺寸', '基座水箱容量': '基座的水箱容量'}}\n",
      "{'sentence': 'm1和g20标准版是否[有遥控器]，他们的[套餐]是什么，同样p10spro和h1neo的[需要摆放的尺寸]有多大，他们[基座里的水箱容量]有多少？', 'replace': {'是否带遥控器': '有遥控器', '套餐类型': '套餐', '建议摆放尺寸': '需要摆放的尺寸', '基座水箱容量': '基座里的水箱容量'}}\n",
      "{'sentence': '我想咨询m1和g20标准版是否[含有遥控器]，他们的[套餐种类]是什么，以及p10spro和h1neo的[适合放置的尺寸]，和他们[基座的水箱大小]？', 'replace': {'是否带遥控器': '含有遥控器', '套餐类型': '套餐种类', '建议摆放尺寸': '适合放置的尺寸', '基座水箱容量': '基座的水箱大小'}}\n",
      "{'sentence': '请问g10s和g20的[摆放尺寸建议]、[尘袋可以装多少]、[维护方法]，同时g10spure标准版和p10pro的[水龙头是什么类型]、[小件程序需要多长时间]、[商品链接在哪里]?', 'replace': {'建议摆放尺寸': '摆放尺寸建议', '尘袋容量': '尘袋可以装多少', '机身维护': '维护方法', '水龙头类型': '水龙头是什么类型', '小件程序时长': '小件程序需要多长时间', '商品链接': '商品链接在哪里'}}\n",
      "{'sentence': '可以告知g10s和g20的[建议摆放大小]、[尘袋能装的量]、[如何维护机身]，以及g10spure标准版和p10pro的[水龙头的类型]、[小件程序运行时长]、[产品链接在哪]吗？', 'replace': {'建议摆放尺寸': '建议摆放大小', '尘袋容量': '尘袋能装的量', '机身维护': '如何维护机身', '水龙头类型': '水龙头的类型', '小件程序时长': '小件程序运行时长', '商品链接': '产品链接在哪'}}\n",
      "{'sentence': '我想知道g10s和g20的[适合摆放尺寸]、[尘袋能装多少尘土]、[保养机身的方法]，还有g10spure标准版和p10pro的[哪种水龙头适用]、[小件这个程序需要的时间]、[商品的链接是什么]？', 'replace': {'建议摆放尺寸': '适合摆放尺寸', '尘袋容量': '尘袋能装多少尘土', '机身维护': '保养机身的方法', '水龙头类型': '哪种水龙头适用', '小件程序时长': '小件这个程序需要的时间', '商品链接': '商品的链接是什么'}}\n",
      "{'sentence': '想询问g10s和g20[理想的摆放尺寸]、[尘袋载量]、[机身保养方式]，以及g10spure标准版和p10pro的[适宜的水龙头类型]、[小件程序时长有多久]、[商品的链接可以提供下]？', 'replace': {'建议摆放尺寸': '理想的摆放尺寸', '尘袋容量': '尘袋载量', '机身维护': '机身保养方式', '水龙头类型': '适宜的水龙头类型', '小件程序时长': '小件程序时长有多久', '商品链接': '商品的链接可以提供下'}}\n",
      "{'sentence': '能告诉我p10、g10s标准版、p10pro的[水箱有多大]，以及p10s上下水版、g10spro标准版、h1neo所在的[是哪个平台]吗？', 'replace': {'基座水箱容量': '水箱有多大', '平台': '是哪个平台'}}\n",
      "{'sentence': '你知道p10、g10s标准版、p10pro的[水箱容量]多少，和p10s上下水版、g10spro标准版、h1neo所基于的[平台]是什么吗？', 'replace': {'基座水箱容量': '水箱容量', '平台': '平台'}}\n",
      "{'sentence': '请问p10、g10s标准版、p10pro的[水箱可以装多少]，另外p10s上下水版、g10spro标准版、h1neo用的是哪个[平台]？', 'replace': {'基座水箱容量': '水箱可以装多少', '平台': '平台'}}\n",
      "{'sentence': '我想了解一下p10、g10s标准版、p10pro的[水箱容量]是多少，并且p10s上下水版、g10spro标准版、h1neo运行在什么[平台]上？', 'replace': {'基座水箱容量': '水箱容量', '平台': '平台'}}\n",
      "{'sentence': '请问p10标准版、p10s标准版以及h1是否[支持上下水功能]，[它们的销售店铺名称]分别是什么？同样地，g10s、p10及p10pro上下水版分别[能否中途加衣]，它们[怎样操作语音助手]呢？', 'replace': {'是否支持上下水': '支持上下水功能', '店铺名称': '它们的销售店铺名称', '中途添衣': '能否中途加衣', '如何关闭/开启语音助手': '怎样操作语音助手'}}\n",
      "{'sentence': 'p10标准版、p10s标准版和h1的[上下水功能]以及[售卖店名]是什么？另外，g10s、p10和p10pro上下水版的[中途添加衣物功能]和[语音助手操作]是怎样的？', 'replace': {'是否支持上下水': '上下水功能', '店铺名称': '售卖店名', '中途添衣': '中途添加衣物功能', '如何关闭/开启语音助手': '语音助手操作'}}\n",
      "{'sentence': '我想了解下，p10标准版、p10s标准版以及h1是否有[上下水能力]，以及它们[在哪个店铺销售]？而对于g10s、p10、p10pro上下水版，它们是否支持[中间加入衣物]，以及[如何调整语音助手]呢？', 'replace': {'是否支持上下水': '上下水能力', '店铺名称': '在哪个店铺销售', '中途添衣': '中间加入衣物', '如何关闭/开启语音助手': '如何调整语音助手'}}\n",
      "{'sentence': '对于p10标准版、p10s标准版和h1，我想知道他们是否[有上下水的功能]以及他们[销售的店铺名称]。同时，我也想了解g10s、p10和p10pro上下水版是否[可以在中途添加衣物]以及他们[如何操作语音助手]？', 'replace': {'是否支持上下水': '有上下水的功能', '店铺名称': '销售的店铺名称', '中途添衣': '可以在中途添加衣物', '如何关闭/开启语音助手': '如何操作语音助手'}}\n",
      "{'sentence': '关于p10s、g20和p10spro，你能告诉我他们[使用的导航类型]、[显示屏的类型]、以及[主刷的转速]是什么吗？另外，g10spro、p10pro和p10spro标准版的[排水管有多长]、[热水洗布需要的输入功率]、和[尘袋能装多少尘土]又是怎样的？', 'replace': {'导航类型': '使用的导航类型', '显示屏类型': '显示屏的类型', '主刷转速': '主刷的转速', '排水管长度': '排水管有多长', '额定输入功率（热水洗布）': '热水洗布需要的输入功率', '尘袋容量': '尘袋能装多少尘土'}}\n",
      "{'sentence': '我想知道p10s、g20和p10spro[采用的导航方式]、[内置的显示屏种类]、以及[主刷的转动速度]，且对于g10spro、p10pro和p10spro标准版的[排水管长度]、[热水洗布模式的输入功率]、和[尘袋的容量]也感到好奇。', 'replace': {'导航类型': '采用的导航方式', '显示屏类型': '内置的显示屏种类', '主刷转速': '主刷的转动速度', '排水管长度': '排水管长度', '额定输入功率（热水洗布）': '热水洗布模式的输入功率', '尘袋容量': '尘袋的容量'}}\n",
      "{'sentence': '能否告知p10s、g20和p10spro使用的[导航方式]、[显示屏的种类]以及[主刷的转速是多少]？另外对于g10spro、p10pro和p10spro标准版，我想了解[排水管的长度]、[热水洗布模式需要的输入功率]、和[尘袋的容纳量]。', 'replace': {'导航类型': '导航方式', '显示屏类型': '显示屏的种类', '主刷转速': '主刷的转速是多少', '排水管长度': '排水管的长度', '额定输入功率（热水洗布）': '热水洗布模式需要的输入功率', '尘袋容量': '尘袋的容纳量'}}\n",
      "{'sentence': '我想了解p10s、g20和p10spro的[导航方式]、[显示屏类型]和[主刷的转速]，此外也对g10spro、p10pro和p10spro标准版的[排水管长度]、[热水洗布的输入功率]、以及他们的[尘袋容量]感兴趣。', 'replace': {'导航类型': '导航方式', '显示屏类型': '显示屏类型', '主刷转速': '主刷的转速', '排水管长度': '排水管长度', '额定输入功率（热水洗布）': '热水洗布的输入功率', '尘袋容量': '尘袋容量'}}\n"
     ]
    }
   ],
   "source": [
    "a = df_exploded[(df_exploded[\"type\"]==\"gen_different_keywords_different_models_v2\"\n",
    "            )&(df_exploded[\"cat_num\"]==1)|(df_exploded[\"type\"]==\"gen_different_keywords_different_models_v2\"\n",
    "            )&(df_exploded[\"cat_num\"]==2)].augment\n",
    "for i in range(a.shape[0]):\n",
    "    print(a.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bddb3d56-d4e2-48c1-8b02-e17b0c46cf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.augment.apply(lambda x: len(x[\"replace\"])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d3b779a2-306d-45a3-b191-5427968b649b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.augment.apply(lambda x: x[\"sentence\"].find(\"[\")<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ec3dcc8-03e3-44b4-bf0c-a2d2981d860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def wrap_b_in_brackets(a, b):\n",
    "    # 使用re.escape来处理特殊字符\n",
    "    b_escaped = re.escape(b)\n",
    "    # 使用正则表达式替换所有的b为[b]\n",
    "    result = re.sub(b_escaped, f'[{b}]', a)\n",
    "    return result\n",
    "\n",
    "def wrap(x):\n",
    "    sentence = x[\"sentence\"]\n",
    "    do_set = set()\n",
    "    for key in x[\"replace\"]:\n",
    "        if x[\"replace\"][key] not in do_set:\n",
    "            do_set.add(x[\"replace\"][key])\n",
    "            sentence = wrap_b_in_brackets(sentence, x[\"replace\"][key])\n",
    "    return {\"sentence\": sentence, \"replace\": x[\"replace\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "4f013131-07a4-4762-a9cc-f757128660fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '请问h1neo, m1和h1的[柔顺剂容量]和[电机类型]是什么？', 'replace': {'柔顺剂容量': '柔顺剂容量', '电机类型': '电机类型'}}\n"
     ]
    }
   ],
   "source": [
    "a = df_exploded.loc[df_exploded.augment.apply(lambda x: x[\"sentence\"].find(\"[\")<0), \"augment\"\n",
    "].apply(lambda x: wrap(x))\n",
    "for i in range(a.shape[0]):\n",
    "    print(a.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69bfd568-c00d-482c-a8e6-ba4b6aa62bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.loc[df_exploded.augment.apply(lambda x: x[\"sentence\"].find(\"[\")<0), \"augment\"\n",
    "] = df_exploded.loc[df_exploded.augment.apply(lambda x: x[\"sentence\"].find(\"[\")<0), \"augment\"\n",
    "].apply(lambda x: wrap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b5e350f-79bd-4ba3-b621-6a56f25cab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"question_raw\"] = df_exploded['augment'].apply(lambda x: x[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fce16e1e-b9c3-4f71-a0b7-7a095b211f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.reset_index(drop=True)\n",
    "df_exploded[\"index\"] = range(df_exploded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "3a5c4078-b681-4df5-8dd5-9fc39a1d3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = [\"gen\", \"augment\", \"ner_list\"]\n",
    "for col in json_list:\n",
    "    df_exploded[col] = df_exploded[col].apply(lambda x: json.dumps(x, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "a35b6c61-1992-4599-9538-2f9a87e08789",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = [col for col in df_exploded.columns if col != \"ner_list\"]\n",
    "df_exploded[output_cols].to_csv(\"/data/dataset/kefu/gpt4_template_v2/generated.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "8d081f57-09cf-4dbd-9aa2-3c42f209f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有模板收集的数据放在一起，形成测试集合\n",
    "# 1. v1版本的所有单一品类\n",
    "# 2. v2版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "dc0161e6-3d5b-4908-8fea-e6df240a03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_v1 = pd.read_csv(\"/data/dataset/kefu/gpt4_template/generated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "0afa2ba3-220f-4797-ad38-e930427f0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_v2 = pd.read_csv(\"/data/dataset/kefu/gpt4_template_v2/generated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "20c05c1c-c871-4fbd-b28e-cfd7e8da607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_all = pd.concat([df_exploded_v1, df_exploded_v2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "97590208-b827-43aa-9755-cd220c621e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded_all.copy()\n",
    "df_exploded[\"augment\"] = df_exploded[\"augment\"].apply(lambda x: json.loads(x))\n",
    "df_exploded[\"final_prompt\"] = df_exploded[\"final_prompt\"].apply(lambda x: json.loads(x))\n",
    "df_exploded['gen'] = df_exploded[\"gen\"].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8839f2da-a99b-4ead-8386-c46e7b864e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 11)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "91e5876e-b6ac-4048-a755-1cf44b06281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"augment\"].apply(lambda x: len(x[\"replace\"])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "f6cba3a0-b202-4ac3-a24a-3c2182874938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"augment\"].apply(lambda x: x[\"sentence\"].find(\"[\")<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "92d30e69-eb03-4e37-8748-c9def129e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_indices = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment'].iloc[i][\"replace\"]\n",
    "    for key in replace:\n",
    "        if key.find(\"[\")>=0:\n",
    "            error_indices.append(i)\n",
    "            break \n",
    "df_exploded = df_exploded.drop([df_exploded.index[i] for i in error_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "6e0ed0fc-da19-468f-a785-8b5d7ae6d35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 11)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "256f0c59-58d1-4ff7-be79-40a1feee8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment'].iloc[i][\"replace\"]\n",
    "    primaries = [j['primary_value'] for j in df_exploded['gen'].iloc[i]['prompt']]\n",
    "    flag = False\n",
    "    entity = []\n",
    "    for key in replace:\n",
    "        if replace[key] in primaries:\n",
    "            print(i)\n",
    "            flag = True\n",
    "            break \n",
    "        entity.append(replace[key])\n",
    "    if flag:\n",
    "        print(i, 'type1 error')\n",
    "        ner_list.append(np.nan)\n",
    "        continue\n",
    "    question =  df_exploded['question'].iloc[i]\n",
    "    ner = {}\n",
    "    for item in entity:\n",
    "        matches = list(re.finditer(item, question))\n",
    "        loc = [[j.start(), j.end()-1] for j in matches]\n",
    "        ner[item] = loc \n",
    "    ner_list.append({\"name\": ner})\n",
    "df_exploded[\"ner_list\"] = ner_list\n",
    "df_exploded = df_exploded[df_exploded[\"ner_list\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "a9a2d106-df2a-4578-be7f-508faf38d879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 12)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "f7c140cb-bd01-44ca-951b-215723eff86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 g20标准版有哪些[热水洗布]的功能？ {'热水洗布': '热水洗布的功能'}\n",
      "43 您能告诉我g20标准版的[热水洗布]操作流程吗？ {'热水洗布': '热水洗布操作流程'}\n",
      "44 我想了解一下g20标准版的[热水洗布]特性。 {'热水洗布': '热水洗布特性'}\n",
      "63 你能告诉我g20标准版的[机身维护]事宜吗？ {'机身维护': '机身维护事宜'}\n",
      "133 你能告诉我g20标准版的[烘干功能]的温度是怎样的吗？ {'烘干温度': '烘干功能的温度'}\n",
      "134 请问g20标准版的[烘干模式]下的温度是什么？ {'烘干温度': '烘干模式下的温度'}\n",
      "159 能否告诉我[g20标准版]软件算法是怎样的？ {'软件算法': '软件算法'}\n",
      "234 g20标准版是由哪个[品牌]制作的？ {'品牌': '制作品牌'}\n",
      "235 你能告诉我g20标准版是哪个[品牌]出品的吗？ {'品牌': '出品品牌'}\n",
      "236 g20标准版的制造[品牌]是哪家？ {'品牌': '制造品牌'}\n",
      "420 a10ultra具备何种[设备共享]能力？ {'设备共享': '设备共享能力'}\n",
      "675 h1的[中途添衣]功能具体是怎样的？ {'中途添衣': '中途添衣功能'}\n",
      "678 请问h1有[急救开门]功能吗？ {'紧急开门': '急救开门功能'}\n",
      "680 h1是否配备了[紧急开启门]功能？ {'紧急开门': '紧急开启门功能'}\n",
      "727 您能告诉我g20标准版在充电和烘干状态下的[额定功率]，以及p10s标准版在集尘状态下的[额定功率]分别是什么吗？ {'额定输入功率（充电 + 烘干状态）': '在充电和烘干状态下的额定功率', '额定输入功率（集尘状态）': '在集尘状态下的额定功率'}\n",
      "728 你能告诉我g20标准版在充电烘干的状态下[功率]和p10s标准版在开启集尘状态的时候的[功率]吗？ {'额定输入功率（充电 + 烘干状态）': '在充电烘干的状态下功率', '额定输入功率（集尘状态）': '在开启集尘状态的时候的功率'}\n",
      "829 请问g20标准版的[烘干功能的温度]和p10s标准版[的漫扫和拖地模式]分别是什么样的？ {'烘干温度': '烘干功能的温度', '扫拖模式': '漫扫和拖地模式'}\n",
      "835 能否告知一下，g20标准版的充电方式和p10s标准版的[预约功能]到底如何？ {'充电模式': '充电方式', '是否有定时预约功能': '预约功能'}\n",
      "897 g20标准版有哪些附加功能，以及p10s标准版的[实时视频]功能是怎样的？ {'附加功能': '附加功能', '实时视频': '实时视频功能'}\n",
      "898 关于g20标准版的附加功能和p10s标准版的[实时视频播放]能力，能详细介绍一下吗？ {'附加功能': '附加功能', '实时视频': '实时视频播放'}\n",
      "899 我想知道g20标准版的附加功能和p10s标准版支持的[实时视频流技术]的具体情况。 {'附加功能': '附加功能', '实时视频': '实时视频流技术'}\n",
      "901 g20标准版是否拥有实时视频，另外，p10s标准版的[保修期限]又是如何的呢？ {'实时视频': '实时视频', '质保年限': '保修期限'}\n",
      "902 您能告诉我g20标准版的实时视频和p10s标准版的[质保服务期限]吗？ {'实时视频': '实时视频', '质保年限': '质保服务期限'}\n",
      "909 能告诉我[g20标准版]的生产者和[p10s标准版]的主刷旋转速度吗？ {'生产企业': '生产者', '主刷转速': '主刷旋转速度'}\n",
      "910 请问，哪家公司生产了[g20标准版]？另外，[p10s标准版]设备的刷子转动速度如何？ {'生产企业': '哪家公司生产了', '主刷转速': '刷子转动速度'}\n",
      "911 你知道[g20标准版]是哪家公司制造的吗？也想询问[p10s标准版]的刷子旋转速率。 {'生产企业': '哪家公司制造的', '主刷转速': '刷子旋转速率'}\n",
      "936 请问，对于g20标准版，它的清扫路线如何，同时p10s标准版是否有[自动回洗拖布]功能呢？ {'清扫路线': '清扫路线', '是否支持自动回洗拖布': '自动回洗拖布'}\n",
      "937 我想了解g20标准版的清扫路线，再加上p10s标准版是否具备[自动回洗拖布]的功能？ {'清扫路线': '清扫路线', '是否支持自动回洗拖布': '自动回洗拖布'}\n",
      "1059 能不能告诉我a10ultra的[清理模式的续航能力]和a10ultrae的[预设的标配包括]什么？ {'吸尘续航': '清理模式的续航能力', '标配': '预设的标配'}\n",
      "1095 你能告诉我a10ultra的[智能污渍检测]技术与a10ultrae的[智能化体验]是怎样的吗？ {'智能污渍检测': '智能污渍检测技术', '智能化体验': '智能化体验'}\n",
      "1145 a10ultra的吸尘组件如何维护，而a10ultrae的[耗材更换期]是多久？ {'吸尘组件维护': '吸尘组件如何维护', '耗材\\n更换周期': '耗材更换期'}\n",
      "1146 请问a10ultra的吸尘组件应该如何保养，对比之下，a10ultrae的[耗材更替时间]又是多长时间呢？ {'吸尘组件维护': '吸尘组件应该如何保养', '耗材\\n更换周期': '耗材更替时间'}\n",
      "1147 关于a10ultra，我们怎么去维护它的吸尘部分呢？同时，对a10ultrae来说，[耗材替换周期]应该是多久？ {'吸尘组件维护': '怎么去维护它的吸尘部分', '耗材\\n更换周期': '耗材替换周期'}\n",
      "1148 a10ultra的耗材更换周期与a10ultrae的[质保期]有什么区别？ {'耗材\\n更换周期': '耗材更换周期', '整机质保': '质保期'}\n",
      "1150 我想了解下a10ultra的耗材更换周期和a10ultrae的[保质期]？ {'耗材\\n更换周期': '耗材更换周期', '整机质保': '保质期'}\n",
      "1154 a10ultra的风机怎么样，质保期是多久呢？a10ultrae的[耗材质量]有保障吗？ {'风机质保': '风机怎么样，质保期是多久', '耗材质保': '耗材质量'}\n",
      "1155 可以告诉我a10ultra的风机有什么质保措施吗？还有，a10ultrae的消耗品都是哪些，它们的[质保政策]是怎样的？ {'风机质保': '风机有什么质保措施', '耗材质保': '质保政策'}\n",
      "1156 您能详述一下a10ultra的风机的保修期限及规范吗？另外，a10ultrae的耗材的[质保服务]又是如何的呢？ {'风机质保': '风机的保修期限及规范', '耗材质保': '质保服务'}\n",
      "1158 请问a10ultra的[保质期有多久?]，a10ultrae的[额定功率大概是多少]？ {'耗材质保': '保质期有多久', '主机额定功率': '额定功率大概是多少'}\n",
      "1165 我想了解一下，a10ultra的热水洗布功率需要多少，以及a10ultrae在[充电并烘干]状态下需要的功率是多少？ {'额定输入功率（热水洗布）': '热水洗布功率需求', '额定输入功率（充电 + 烘干状态）': '充电并烘干'}\n",
      "1264 h1的洗涤效果（[洗净比]）和h1neo的脱水效率（[最高脱水转速]）各是多少？ {'洗净比': '洗涤效果', '最高脱水转速': '脱水效率'}\n",
      "1265 你知道h1的[洗净比]和h1neo的脱水效能（[最高脱水转速]）是怎样的吗？ {'洗净比': '洗净比', '最高脱水转速': '脱水效能'}\n",
      "1266 能提供h1的清洁度（[洗净比]）和h1neo的最大脱水能力（[最高脱水转速]）的相关信息吗？ {'洗净比': '清洁度', '最高脱水转速': '最大脱水能力'}\n",
      "1594 a20air和g10spro的推荐安装大小、[是否配备遥控器]以及g20标准版和p10spro的[充电能力]、[使用方法]是什么？ {'建议摆放尺寸': '推荐安装大小', '是否带遥控器': '是否配备遥控器', '充电功率': '充电能力', '使用方式': '使用方法'}\n",
      "1595 能告诉我a20air和g10spro的适合放置规格、[遥控器配置]以及g20标准版和p10spro的[充电容量]、[操作方式]吗？ {'建议摆放尺寸': '适合放置规格', '是否带遥控器': '遥控器配置', '充电功率': '充电容量', '使用方式': '操作方式'}\n",
      "1596 a20air和g10spro的理想放置尺寸、[配备遥控器否]和g20标准版和p10spro的[电源能力]、[操作模式]是什么？ {'建议摆放尺寸': '理想放置尺寸', '是否带遥控器': '配备遥控器否', '充电功率': '电源能力', '使用方式': '操作模式'}\n",
      "1597 请问a20air和g10spro的推荐设立大小、[是否有遥控器]与g20标准版和p10spro的[供电能力]、[如何使用]是多少？ {'建议摆放尺寸': '推荐设立大小', '是否带遥控器': '是否有遥控器', '充电功率': '供电能力', '使用方式': '如何使用'}\n"
     ]
    }
   ],
   "source": [
    "error_indices = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded.augment.iloc[i][\"replace\"]\n",
    "    question_raw =  df_exploded.augment.iloc[i][\"sentence\"]\n",
    "    for key in replace:\n",
    "        if \"[\"+replace[key]+\"]\" not in question_raw:\n",
    "            print(i, question_raw, replace)\n",
    "            error_indices.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "2aa79838-c868-4ae2-973a-7d36843ca8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.drop([df_exploded.index[i] for i in error_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "485408d5-9209-444d-b6ac-4235e20347dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"index_all\"] = range(df_exploded.shape[0])\n",
    "df_exploded[\"index_all\"] = df_exploded[\"index_all\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "0695e925-f82c-4339-a139-df2029f4153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging(x, tag2id):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        new_list.append(tag2id[i])\n",
    "    return new_list\n",
    "\n",
    "df_exploded[\"bio\"] = df_exploded[[\"question\", \"ner_list\"]].apply(lambda x: bio_tagging(x[\"question\"], x[\"ner_list\"]), axis=1)\n",
    "df_exploded[\"bio_words\"] = df_exploded[\"bio\"].apply(lambda x: x[0])\n",
    "df_exploded[\"bio_tags\"] = df_exploded[\"bio\"].apply(lambda x: x[1])\n",
    "df_exploded = df_exploded.drop(\"bio\", axis=1)\n",
    "tag2id = {'O': 0, 'B-name': 1, 'I-name': 2}\n",
    "df_exploded[\"bio_tags_id\"] = df_exploded[\"bio_tags\"].apply(lambda x:tagging(x, tag2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b4e38708-bd97-41c8-a959-f009eb789c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'template': '[问询词0]的[关键词0]是什么？',\n",
       " 'replace': {'[问询词0]': 'g20标准版', '[关键词0]': '商品链接'}}"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.final_prompt.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "0c64dcc8-e529-4d74-a809-1307c8535d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个是用来做embedding召回模型的测试集\n",
    "# true_entity_list = []\n",
    "# pred_entity_list = []\n",
    "# for i in range(df_exploded.shape[0]):\n",
    "#     for true_entity in df_exploded[\"augment\"].iloc[i][\"replace\"]:\n",
    "#         true_entity_list.append(true_entity)\n",
    "#         pred_entity_list.append(df_exploded[\"augment\"].iloc[i][\"replace\"][true_entity])\n",
    "# df_entity = pd.DataFrame()\n",
    "# df_entity[\"true_entity\"] = true_entity_list\n",
    "# df_entity[\"pred_entity\"] = pred_entity_list\n",
    "# df_entity.to_csv(\"/data/dataset/kefu/entity_link_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "e1287a3e-e8db-4b58-bdbd-6df1120c53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个是给业务人员打标用的测试集\n",
    "# df_exploded[\"crafted_question\"] = df_exploded[\"augment\"].apply(lambda x: x[\"sentence\"])\n",
    "# df_exploded[\"real_entities\"] = df_exploded[\"augment\"].apply(lambda x: x[\"replace\"])\n",
    "# df_exploded[\"set_name\"] = \"test\"\n",
    "# output_cols = [\"set_name\", \"index_all\", \"cat\", \"template\", \"crafted_question\", \"real_entities\"]\n",
    "# df_exploded[output_cols].to_excel(\"/data/dataset/kefu/for_label_test.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "7731cea0-a0cf-4bde-80d4-6182824abe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({'ner_tags': Sequence(ClassLabel(num_classes=3, names=['O', 'B-name', 'I-name'])),\n",
    "                     'tokens': Sequence(Value(dtype='string')),\n",
    "                     \"cat_num\": ClassLabel(num_classes=4, names=[0,1,2,3]),\n",
    "                     \"index_all\": Value(dtype='string')})\n",
    "raw_datasets = Dataset.from_pandas(df_exploded[[\"bio_words\", \"bio_tags_id\", \"cat_num\", \"index_all\"]].rename(columns={\"bio_words\": \"tokens\", \"bio_tags_id\": \"ner_tags\"}),\n",
    "                    features=features, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "018cca50-2087-482b-acfb-3e624fada4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41648a540dc4a5eb2cea573b563f2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1567 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets.save_to_disk(\"/data/dataset/kefu/ner_from_template_augment_test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "33dfcbf7-a432-4c41-a898-22ceb29dec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个是csv形式的测试集\n",
    "# json_list = [\"gen\", \"final_prompt\", \"augment\", \"ner_list\", \"bio_words\", \"bio_tags\", \"bio_tags_id\"]\n",
    "# for col in json_list:\n",
    "#     df_exploded[col] = df_exploded[col].apply(lambda x: json.dumps(x, ensure_ascii=False))\n",
    "# df_exploded.to_csv(\"/data/dataset/kefu/table_qa.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9b0d6b50-3764-484c-84b7-70dfd92df021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集制作\n",
    "# 由于所有转义表达的词语都很少有重复的，这样划分的train test会过拟合，\n",
    "# 因此尝试尽量不改变实体，只改句子结构，形成训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "b685cb45-ca83-4081-a79e-a56a56a4c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded_v1 = pd.read_csv(\"/data/dataset/kefu/gpt4_template/generated.csv\")\n",
    "df_exploded_v2 = pd.read_csv(\"/data/dataset/kefu/gpt4_template_v2/generated.csv\")\n",
    "df_exploded = pd.concat([df_exploded_v1, df_exploded_v2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "be0d81e3-b91b-427a-bca3-0a2881878ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded.augment = df_exploded.augment.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "45cb5214-a89e-4961-a1a7-1ce1228211ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.augment.apply(lambda x: len(x[\"replace\"])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "8d26b117-16c6-471a-8835-2696a405d7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.question_raw.apply(lambda x: x.find(\"[\")<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "6ce11336-136b-4b14-856e-b090953d020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_exploded[df_exploded.augment.apply(lambda x: x[\"sentence\"].find(\"[\")<0)].shape[0]):\n",
    "    print(df_exploded[df_exploded.augment.apply(lambda x: x[\"sentence\"].find(\"[\")<0)].iloc[i].augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "6154b8b1-1445-4c82-ac5f-6c8cb66da988",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "输入的句子中用[]符号括起来的部分是命名实体，请按照以下步骤执行：\n",
    "1. 对整个句子调整句子结构并保持意思不变且新句子语法通顺，上述调整中，用[]符号括起来的部分作为一个整体参与调整，内部保持不变\n",
    "2. 对于调整后的句子，去除[]符号，然后检查语法是否通顺，如果是则还原[]符号来标记命名实体，否则转到步骤3\n",
    "3. 重新对原始输入的句子做转义表达以保证语法通顺，最后提取与原始输入的句子中[]符号括起来的命名实体对应的新实体，并用[]符号括起来\n",
    "\n",
    "最好的例子（步骤1执行完后保持原始命名实体不变且句子语法通顺）：\n",
    "输入：\n",
    "请问g20是否有[上下水功能]？\n",
    "输出：\n",
    "{{\"sentence\": \"我想了解下g20的[上下水功能]？\", \"replace\": {{\"上下水功能\": \"上下水功能\"}}}}\n",
    "\n",
    "次好的例子（步骤1执行完后，由于句子语法不通顺而对原始命名实体做了转义，但是最后句子是通顺的）：\n",
    "输入：\n",
    "g20[是否支持上下水]？\n",
    "输出：\n",
    "{{\"sentence\": \"g20[支持上下水]吗？\", \"replace\": {{\"是否支持上下水\": \"支持上下水\"}}}}\n",
    "\n",
    "不好的例子（保持原始命名实体不变但句子语法不通顺）：\n",
    "输入：\n",
    "g20的[操作方法]是怎么的？\n",
    "输出：\n",
    "{{\"sentence\": \"m1和h1的[操作方法]具体是怎么操作的？\", \"replace\": {{\"操作方法\": \"操作方法\"}}}}\n",
    "\n",
    "\n",
    "请对每个输入给出{}种不同的说法, 每种说法都要按照上述3个步骤依次做一遍，每种说法对应一个json，放在列表里面返回, 除此之外不要给出任务其他的信息，即如果要求给出n种说法，则输出\n",
    "[json_0, json_1, json_2, ..., json_n-1]，如果要给出1种说法，则输出[json_0]\n",
    "\n",
    "输入：\n",
    "{}\n",
    "输出：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8df5f1a3-f1e6-4ae6-af0e-3095d194bfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "gen_same_keywords_for_models                  696\n",
       "gen_different_keywords_different_models       679\n",
       "gen_same_keywords_for_models_v2               120\n",
       "gen_different_keywords_different_models_v2    119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "7879e586-7c35-4f9e-87d0-ff48ea629794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.00029277801513671875\n",
      "10\n",
      "30.172164916992188\n",
      "20\n",
      "21.10416555404663\n",
      "30\n",
      "30.362523317337036\n",
      "40\n",
      "46.01581001281738\n",
      "50\n",
      "31.858498573303223\n",
      "60\n",
      "28.333003520965576\n",
      "70\n",
      "23.805840969085693\n",
      "80\n",
      "25.66316795349121\n",
      "90\n",
      "28.82840919494629\n",
      "100\n",
      "24.411174774169922\n",
      "110\n",
      "28.753122568130493\n",
      "120\n",
      "28.996712923049927\n",
      "130\n",
      "30.84315299987793\n",
      "140\n",
      "29.060205459594727\n",
      "150\n",
      "30.57560110092163\n",
      "160\n",
      "24.969565868377686\n",
      "170\n",
      "23.712473392486572\n",
      "180\n",
      "26.84784245491028\n",
      "190\n",
      "28.322980165481567\n",
      "200\n",
      "24.32093834877014\n",
      "210\n",
      "21.717167139053345\n",
      "220\n",
      "26.594087600708008\n",
      "230\n",
      "28.41340970993042\n",
      "240\n",
      "24.618606090545654\n",
      "250\n",
      "28.30187201499939\n",
      "260\n",
      "25.46821093559265\n",
      "270\n",
      "27.963725805282593\n",
      "280\n",
      "31.466816663742065\n",
      "290\n",
      "29.47443389892578\n",
      "300\n",
      "22.322694301605225\n",
      "310\n",
      "23.533947944641113\n",
      "320\n",
      "28.271371841430664\n",
      "330\n",
      "29.30790948867798\n",
      "340\n",
      "27.0170841217041\n",
      "350\n",
      "29.732333183288574\n",
      "360\n",
      "33.33962845802307\n",
      "370\n",
      "37.092719316482544\n",
      "380\n",
      "31.706613063812256\n",
      "390\n",
      "31.172128677368164\n",
      "400\n",
      "25.46167826652527\n",
      "410\n",
      "25.534046411514282\n",
      "420\n",
      "25.431107997894287\n",
      "430\n",
      "25.74759006500244\n",
      "440\n",
      "28.764384031295776\n",
      "450\n",
      "26.376360416412354\n",
      "460\n",
      "26.025831937789917\n",
      "470\n",
      "22.512786865234375\n",
      "480\n",
      "26.339490175247192\n",
      "490\n",
      "34.13607668876648\n",
      "500\n",
      "29.376495361328125\n",
      "510\n",
      "23.94931149482727\n",
      "520\n",
      "20.896177768707275\n",
      "530\n",
      "20.907421827316284\n",
      "540\n",
      "21.76071858406067\n",
      "550\n",
      "31.309009790420532\n",
      "560\n",
      "30.782994747161865\n",
      "570\n",
      "31.43088388442993\n",
      "580\n",
      "23.49413752555847\n",
      "590\n",
      "26.489206075668335\n",
      "600\n",
      "26.656319856643677\n",
      "610\n",
      "20.640031337738037\n",
      "620\n",
      "24.598528146743774\n",
      "630\n",
      "24.458627939224243\n",
      "640\n",
      "23.29944157600403\n",
      "650\n",
      "22.367079496383667\n",
      "660\n",
      "27.113364219665527\n",
      "670\n",
      "29.831858158111572\n",
      "680\n",
      "29.997917413711548\n",
      "690\n",
      "26.22958779335022\n",
      "700\n",
      "28.127537965774536\n",
      "710\n",
      "35.40870404243469\n",
      "720\n",
      "46.077879905700684\n",
      "730\n",
      "50.25470566749573\n",
      "740\n",
      "51.663891315460205\n",
      "750\n",
      "49.97228193283081\n",
      "760\n",
      "39.69667196273804\n",
      "770\n",
      "44.834970235824585\n",
      "780\n",
      "47.850520610809326\n",
      "790\n",
      "43.851407051086426\n",
      "800\n",
      "38.261252880096436\n",
      "810\n",
      "38.89478421211243\n",
      "820\n",
      "44.877150774002075\n",
      "830\n",
      "48.54486322402954\n",
      "840\n",
      "43.55268430709839\n",
      "850\n",
      "39.5627338886261\n",
      "860\n",
      "40.62146186828613\n",
      "870\n",
      "43.3093421459198\n",
      "880\n",
      "47.11790347099304\n",
      "890\n",
      "39.48751521110535\n",
      "900\n",
      "31.386574029922485\n",
      "910\n",
      "31.423588037490845\n",
      "920\n",
      "40.60995626449585\n",
      "930\n",
      "31.086047887802124\n",
      "940\n",
      "31.626833200454712\n",
      "950\n",
      "29.141894578933716\n",
      "960\n",
      "37.504926443099976\n",
      "970\n",
      "35.90396165847778\n",
      "980\n",
      "46.76342988014221\n",
      "990\n",
      "38.65889024734497\n",
      "1000\n",
      "41.065754413604736\n",
      "1010\n",
      "52.72607970237732\n",
      "1020\n",
      "58.09743070602417\n",
      "1030\n",
      "48.39106583595276\n",
      "1040\n",
      "41.9462366104126\n",
      "1050\n",
      "42.0291690826416\n",
      "1060\n",
      "48.59473466873169\n",
      "1070\n",
      "38.976781368255615\n",
      "1080\n",
      "48.42233848571777\n",
      "1090\n",
      "40.93894147872925\n",
      "1100\n",
      "44.940348625183105\n",
      "1110\n",
      "30.102928400039673\n",
      "1120\n",
      "43.61340641975403\n",
      "1130\n",
      "43.64347982406616\n",
      "1140\n",
      "43.23302888870239\n",
      "1150\n",
      "41.959102392196655\n",
      "1160\n",
      "34.340946674346924\n",
      "1170\n",
      "51.68542504310608\n",
      "1180\n",
      "32.50781869888306\n",
      "1190\n",
      "25.50028133392334\n",
      "1200\n",
      "30.45986557006836\n",
      "1210\n",
      "29.888323545455933\n",
      "1220\n",
      "31.35602641105652\n",
      "1230\n",
      "29.500719785690308\n",
      "1240\n",
      "39.76737689971924\n",
      "1250\n",
      "38.262529134750366\n",
      "1260\n",
      "37.747413873672485\n",
      "1270\n",
      "45.50014400482178\n",
      "1280\n",
      "48.74951720237732\n",
      "1290\n",
      "31.720040798187256\n",
      "1300\n",
      "35.154715061187744\n",
      "1310\n",
      "43.55589246749878\n",
      "1320\n",
      "38.907071352005005\n",
      "1330\n",
      "42.164719343185425\n",
      "1340\n",
      "43.480748891830444\n",
      "1350\n",
      "37.60049033164978\n",
      "1360\n",
      "37.10374188423157\n",
      "1370\n",
      "47.08136248588562\n",
      "1380\n",
      "47.45878577232361\n",
      "1390\n",
      "78.2596185207367\n",
      "1400\n",
      "91.06320333480835\n",
      "1410\n",
      "114.88202500343323\n",
      "1420\n",
      "69.20276355743408\n",
      "1430\n",
      "96.35916686058044\n",
      "1440\n",
      "108.04188680648804\n",
      "1450\n",
      "79.8035638332367\n",
      "1460\n",
      "99.33741426467896\n",
      "1470\n",
      "93.46488809585571\n",
      "1480\n",
      "97.36392903327942\n",
      "1490\n",
      "102.63741064071655\n",
      "1500\n",
      "102.6614773273468\n",
      "1510\n",
      "103.87488675117493\n",
      "1520\n",
      "164.5545892715454\n",
      "1530\n",
      "275.2706444263458\n",
      "1540\n",
      "121.7746787071228\n",
      "1550\n",
      "131.06569480895996\n",
      "1560\n",
      "217.13418555259705\n",
      "1570\n",
      "233.024108171463\n",
      "1580\n",
      "221.13303232192993\n",
      "1590\n",
      "232.5117802619934\n",
      "1600\n",
      "134.349764585495\n",
      "1610\n",
      "214.5796422958374\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "prev_time = time.time()\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        cur_time = time.time()\n",
    "        print(cur_time-prev_time)\n",
    "        prev_time = cur_time\n",
    "    if df_exploded[\"type\"].iloc[i].find(\"_v2\")>=0:\n",
    "        n = 3\n",
    "    else:\n",
    "        n = 1\n",
    "    item = generate_answer(prompt, df_exploded[\"question_raw\"].iloc[i], n)\n",
    "    result.append(item)\n",
    "    joblib.dump(item, \"/data/dataset/kefu/gpt4_template_all_2/{}.jsonl\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "aeee93b6-9d20-4b2d-9867-63fdf6823c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 11)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "23cff411-692d-47e7-a930-98d964452bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    item = joblib.load(\"/data/dataset/kefu/gpt4_template_all_2/{}.jsonl\".format(i))\n",
    "    result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "09ae65e6-9901-49a7-9ceb-bbb330a86930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "6960fc91-2e8e-49ee-b00c-b0025f0da28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"sentence\": \"能否给我一个g20标准版的[商品访问链接]？\", \"replace\": {\"商品访问链接\": \"商品访问链接\"}}]'"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "0b140425-4414-4bd6-af90-78118d636457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': '关于g10spure和p10spro上下水版的[拖地]方法和p10以及g10spro的[最大高度]能到达多少，你能告诉我吗？',\n",
       "  'replace': {'拖地': '拖地', '最大高度': '最大高度'}},\n",
       " {'sentence': '我想知道g10spure和p10spro上下水版是如何进行[拖地]，还有p10和g10spro的[最大高度]达到了多少？',\n",
       "  'replace': {'拖地': '拖地', '最大高度': '最大高度'}},\n",
       " {'sentence': '你能告诉我g10spure和p10spro上下水版的[拖地]操作方式，以及p10和g10spro的[最大高度]具体数值吗？',\n",
       "  'replace': {'拖地': '拖地', '最大高度': '最大高度'}}]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(result[1566])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "681c6413-c13e-4aa1-a7e7-4a1a984dbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(raw_string):\n",
    "    processed_string = raw_string.replace('\\n', '').replace('\\'', '').replace(\n",
    "        '\"{sentence\"', '{\"sentence\"'\n",
    "    ).replace('\"{', '{').replace('}\"', '}').replace('\"\"', '\"')\n",
    "    \n",
    "    # 加上外层的双引号\n",
    "    # processed_string = processed_string[1:-1]\n",
    "    return processed_string\n",
    "\n",
    "def preprocess(x):\n",
    "    if (x.find(\"[\") >= 0) and (x[x.find(\"[\")+1] != \"{\"):\n",
    "        return \"[{\"+x[1:-1]+\"}]\"\n",
    "    else:\n",
    "        return x \n",
    "    \n",
    "new_result = []\n",
    "error_list = []\n",
    "for i in range(len(result)):\n",
    "    item = result[i]\n",
    "    try:\n",
    "        try:\n",
    "            item = json.loads(item)\n",
    "        except:\n",
    "            try:\n",
    "                item = json.loads(process(item))\n",
    "            except:\n",
    "                item = json.loads(preprocess(item))\n",
    "        item = [json.loads(i) if isinstance(i, str) else i for i in item]\n",
    "    except:\n",
    "        item = np.nan\n",
    "        error_list.append(i)\n",
    "    new_result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "b3e2b80a-f9a2-4cc3-9d6e-4fead58c7c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1614"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "0f635f5b-a4d5-4a89-b952-9ca4f577722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"augment_sentence_only\"] = new_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "ce43aa27-9550-4eab-9b29-4200101efea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded[df_exploded[\"augment_sentence_only\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "c73c5354-f241-446f-8727-a1585f66bbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1613, 12)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "ebb88df4-002a-4d98-b7fe-93fea1ef80ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[[\"type\", \"index\"]].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "b7632bb4-30d2-4fbd-ab3a-0e0e4f10b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.explode(\"augment_sentence_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "2fbd4879-9ac5-49c8-88cb-08102209fdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2091, 12)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "ce831d3e-4bb6-4d3d-bb1d-e85553a7e398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded['augment_sentence_only'].apply(lambda x: len(x[\"replace\"])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "2c030f37-93a0-4a35-b0da-b913d33cd801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded['augment_sentence_only'].apply(lambda x: x[\"sentence\"].find(\"[\")<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "935028aa-97da-4dd8-9a34-ba398ec5e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': '关于电器基站的功能，g20标准版有什么？', 'replace': {'关于电器基站的功能': '关于电器基站的功能'}}\n"
     ]
    }
   ],
   "source": [
    "a = df_exploded.loc[df_exploded.augment_sentence_only.apply(lambda x: x[\"sentence\"].find(\"[\")<0), \"augment_sentence_only\"\n",
    "]\n",
    "for i in range(a.shape[0]):\n",
    "    print(a.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "c5d9036c-2a3c-420d-a9c7-1812090c1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.loc[df_exploded.augment_sentence_only.apply(lambda x: x[\"sentence\"].find(\"[\")>=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "95d88db9-4e5c-4604-ab37-4d575fcf6591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 12)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "86fdd9a9-c3fe-45f6-bb05-1a28d3a11f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.reset_index(drop=True)\n",
    "error_indices = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment_sentence_only'].iloc[i][\"replace\"]\n",
    "    for key in replace:\n",
    "        if key.find(\"[\")>=0:\n",
    "            error_indices.append(i)\n",
    "            break \n",
    "df_exploded = df_exploded.drop([df_exploded.index[i] for i in error_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "424ea30c-37b2-47dd-9caf-084f9c6a48cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 12)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "1004d507-de2f-4a7b-8dab-ffec8c809430",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"augment_question\"] = df_exploded['augment_sentence_only'].apply(lambda x: x[\"sentence\"].replace('[', \"\").replace(']', \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "bebbb045-e47f-4ab4-bd6d-1fc71b35c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_list = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment_sentence_only'].iloc[i][\"replace\"]\n",
    "    entity = []\n",
    "    for key in replace:\n",
    "        entity.append(replace[key])\n",
    "    question =  df_exploded['augment_question'].iloc[i]\n",
    "    ner = {}\n",
    "    for item in entity:\n",
    "        matches = list(re.finditer(item, question))\n",
    "        loc = [[j.start(), j.end()-1] for j in matches]\n",
    "        ner[item] = loc \n",
    "    ner_list.append({\"name\": ner})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "66414b0e-1e8b-4c07-845a-932fcb3aea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"ner_list\"] = ner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "5c47ab1f-b429-4602-9d51-dff923a82e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded[df_exploded[\"ner_list\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "88661b86-d043-4e73-b976-955b4b7d7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 14)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "60a20062-3b5f-46ed-ba2f-2b79c1caa557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>augment_question</th>\n",
       "      <th>ner_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>能否给我一个g20标准版的商品访问链接？</td>\n",
       "      <td>{'name': {'商品访问链接': [[13, 18]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>你能提供g20标准版的购买链接吗？</td>\n",
       "      <td>{'name': {'购买链接': [[11, 14]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>你知道在哪里我可以找到g20标准版的在线购买页面链接吗？</td>\n",
       "      <td>{'name': {'在线购买页面链接': [[18, 25]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你能解答下g20标准版的平台是什么吗？</td>\n",
       "      <td>{'name': {'平台': [[12, 13]]}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你能告诉我g20标准版使用的系统平台是什么吗？</td>\n",
       "      <td>{'name': {'系统平台': [[14, 17]]}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               augment_question                            ner_list\n",
       "0          能否给我一个g20标准版的商品访问链接？    {'name': {'商品访问链接': [[13, 18]]}}\n",
       "1             你能提供g20标准版的购买链接吗？      {'name': {'购买链接': [[11, 14]]}}\n",
       "2  你知道在哪里我可以找到g20标准版的在线购买页面链接吗？  {'name': {'在线购买页面链接': [[18, 25]]}}\n",
       "3           你能解答下g20标准版的平台是什么吗？        {'name': {'平台': [[12, 13]]}}\n",
       "4       你能告诉我g20标准版使用的系统平台是什么吗？      {'name': {'系统平台': [[14, 17]]}}"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[[\"augment_question\", \"ner_list\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "243833b7-9e6a-4342-8db0-aefc5b2a1553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"ner_list\"].apply(lambda x: len(x[\"name\"])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "8195d444-1eba-4264-a762-b5a3914b1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded[df_exploded[\"ner_list\"].apply(lambda x: len(x[\"name\"])>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "d3384890-65b3-49de-bbda-dcc29131b69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 14)"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "566a68c0-550b-4f78-a418-db291dc96586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"bio\"] = df_exploded[[\"augment_question\", \"ner_list\"]].apply(\n",
    "    lambda x: bio_tagging(x[\"augment_question\"], x[\"ner_list\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "4c670262-1040-462c-b728-8c756f086ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"bio_words\"] = df_exploded[\"bio\"].apply(lambda x: x[0])\n",
    "df_exploded[\"bio_tags\"] = df_exploded[\"bio\"].apply(lambda x: x[1])\n",
    "df_exploded = df_exploded.drop(\"bio\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "1414e789-5347-4f18-a57f-a493dededcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2id = {'O': 0, 'B-name': 1, 'I-name': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "3326c591-348e-4d84-864d-919e03e57438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging(x, tag2id):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        new_list.append(tag2id[i])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "4453aa7d-d17e-45f1-8518-8dba00ec372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"bio_tags_id\"] = df_exploded[\"bio_tags\"].apply(lambda x:tagging(x, tag2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "5b9d0503-c816-41bb-abdf-9b1eb724b45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 g20标准版有哪些[热水洗布]的功能？ {'热水洗布': '热水洗布的功能'}\n",
      "43 您能告诉我g20标准版的[热水洗布]操作流程吗？ {'热水洗布': '热水洗布操作流程'}\n",
      "44 我想了解一下g20标准版的[热水洗布]特性。 {'热水洗布': '热水洗布特性'}\n",
      "63 你能告诉我g20标准版的[机身维护]事宜吗？ {'机身维护': '机身维护事宜'}\n",
      "133 你能告诉我g20标准版的[烘干功能]的温度是怎样的吗？ {'烘干温度': '烘干功能的温度'}\n",
      "134 请问g20标准版的[烘干模式]下的温度是什么？ {'烘干温度': '烘干模式下的温度'}\n",
      "158 能否告诉我[g20标准版]软件算法是怎样的？ {'软件算法': '软件算法'}\n",
      "233 g20标准版是由哪个[品牌]制作的？ {'品牌': '制作品牌'}\n",
      "234 你能告诉我g20标准版是哪个[品牌]出品的吗？ {'品牌': '出品品牌'}\n",
      "235 g20标准版的制造[品牌]是哪家？ {'品牌': '制造品牌'}\n",
      "420 a10ultra具备何种[设备共享]能力？ {'设备共享': '设备共享能力'}\n",
      "675 h1的[中途添衣]功能具体是怎样的？ {'中途添衣': '中途添衣功能'}\n",
      "678 请问h1有[急救开门]功能吗？ {'紧急开门': '急救开门功能'}\n",
      "680 h1是否配备了[紧急开启门]功能？ {'紧急开门': '紧急开启门功能'}\n",
      "727 您能告诉我g20标准版在充电和烘干状态下的[额定功率]，以及p10s标准版在集尘状态下的[额定功率]分别是什么吗？ {'额定输入功率（充电 + 烘干状态）': '在充电和烘干状态下的额定功率', '额定输入功率（集尘状态）': '在集尘状态下的额定功率'}\n",
      "728 你能告诉我g20标准版在充电烘干的状态下[功率]和p10s标准版在开启集尘状态的时候的[功率]吗？ {'额定输入功率（充电 + 烘干状态）': '在充电烘干的状态下功率', '额定输入功率（集尘状态）': '在开启集尘状态的时候的功率'}\n",
      "829 请问g20标准版的[烘干功能的温度]和p10s标准版[的漫扫和拖地模式]分别是什么样的？ {'烘干温度': '烘干功能的温度', '扫拖模式': '漫扫和拖地模式'}\n",
      "835 能否告知一下，g20标准版的充电方式和p10s标准版的[预约功能]到底如何？ {'充电模式': '充电方式', '是否有定时预约功能': '预约功能'}\n",
      "897 g20标准版有哪些附加功能，以及p10s标准版的[实时视频]功能是怎样的？ {'附加功能': '附加功能', '实时视频': '实时视频功能'}\n",
      "898 关于g20标准版的附加功能和p10s标准版的[实时视频播放]能力，能详细介绍一下吗？ {'附加功能': '附加功能', '实时视频': '实时视频播放'}\n",
      "899 我想知道g20标准版的附加功能和p10s标准版支持的[实时视频流技术]的具体情况。 {'附加功能': '附加功能', '实时视频': '实时视频流技术'}\n",
      "901 g20标准版是否拥有实时视频，另外，p10s标准版的[保修期限]又是如何的呢？ {'实时视频': '实时视频', '质保年限': '保修期限'}\n",
      "902 您能告诉我g20标准版的实时视频和p10s标准版的[质保服务期限]吗？ {'实时视频': '实时视频', '质保年限': '质保服务期限'}\n",
      "909 能告诉我[g20标准版]的生产者和[p10s标准版]的主刷旋转速度吗？ {'生产企业': '生产者', '主刷转速': '主刷旋转速度'}\n",
      "910 请问，哪家公司生产了[g20标准版]？另外，[p10s标准版]设备的刷子转动速度如何？ {'生产企业': '哪家公司生产了', '主刷转速': '刷子转动速度'}\n",
      "911 你知道[g20标准版]是哪家公司制造的吗？也想询问[p10s标准版]的刷子旋转速率。 {'生产企业': '哪家公司制造的', '主刷转速': '刷子旋转速率'}\n",
      "936 请问，对于g20标准版，它的清扫路线如何，同时p10s标准版是否有[自动回洗拖布]功能呢？ {'清扫路线': '清扫路线', '是否支持自动回洗拖布': '自动回洗拖布'}\n",
      "937 我想了解g20标准版的清扫路线，再加上p10s标准版是否具备[自动回洗拖布]的功能？ {'清扫路线': '清扫路线', '是否支持自动回洗拖布': '自动回洗拖布'}\n",
      "1059 能不能告诉我a10ultra的[清理模式的续航能力]和a10ultrae的[预设的标配包括]什么？ {'吸尘续航': '清理模式的续航能力', '标配': '预设的标配'}\n",
      "1096 你能告诉我a10ultra的[智能污渍检测]技术与a10ultrae的[智能化体验]是怎样的吗？ {'智能污渍检测': '智能污渍检测技术', '智能化体验': '智能化体验'}\n",
      "1146 a10ultra的吸尘组件如何维护，而a10ultrae的[耗材更换期]是多久？ {'吸尘组件维护': '吸尘组件如何维护', '耗材\\n更换周期': '耗材更换期'}\n",
      "1147 请问a10ultra的吸尘组件应该如何保养，对比之下，a10ultrae的[耗材更替时间]又是多长时间呢？ {'吸尘组件维护': '吸尘组件应该如何保养', '耗材\\n更换周期': '耗材更替时间'}\n",
      "1148 关于a10ultra，我们怎么去维护它的吸尘部分呢？同时，对a10ultrae来说，[耗材替换周期]应该是多久？ {'吸尘组件维护': '怎么去维护它的吸尘部分', '耗材\\n更换周期': '耗材替换周期'}\n",
      "1149 a10ultra的耗材更换周期与a10ultrae的[质保期]有什么区别？ {'耗材\\n更换周期': '耗材更换周期', '整机质保': '质保期'}\n",
      "1151 我想了解下a10ultra的耗材更换周期和a10ultrae的[保质期]？ {'耗材\\n更换周期': '耗材更换周期', '整机质保': '保质期'}\n",
      "1155 a10ultra的风机怎么样，质保期是多久呢？a10ultrae的[耗材质量]有保障吗？ {'风机质保': '风机怎么样，质保期是多久', '耗材质保': '耗材质量'}\n",
      "1156 可以告诉我a10ultra的风机有什么质保措施吗？还有，a10ultrae的消耗品都是哪些，它们的[质保政策]是怎样的？ {'风机质保': '风机有什么质保措施', '耗材质保': '质保政策'}\n",
      "1157 您能详述一下a10ultra的风机的保修期限及规范吗？另外，a10ultrae的耗材的[质保服务]又是如何的呢？ {'风机质保': '风机的保修期限及规范', '耗材质保': '质保服务'}\n",
      "1159 请问a10ultra的[保质期有多久?]，a10ultrae的[额定功率大概是多少]？ {'耗材质保': '保质期有多久', '主机额定功率': '额定功率大概是多少'}\n",
      "1166 我想了解一下，a10ultra的热水洗布功率需要多少，以及a10ultrae在[充电并烘干]状态下需要的功率是多少？ {'额定输入功率（热水洗布）': '热水洗布功率需求', '额定输入功率（充电 + 烘干状态）': '充电并烘干'}\n",
      "1265 h1的洗涤效果（[洗净比]）和h1neo的脱水效率（[最高脱水转速]）各是多少？ {'洗净比': '洗涤效果', '最高脱水转速': '脱水效率'}\n",
      "1266 你知道h1的[洗净比]和h1neo的脱水效能（[最高脱水转速]）是怎样的吗？ {'洗净比': '洗净比', '最高脱水转速': '脱水效能'}\n",
      "1267 能提供h1的清洁度（[洗净比]）和h1neo的最大脱水能力（[最高脱水转速]）的相关信息吗？ {'洗净比': '清洁度', '最高脱水转速': '最大脱水能力'}\n",
      "2030 a20air和g10spro的推荐安装大小、[是否配备遥控器]以及g20标准版和p10spro的[充电能力]、[使用方法]是什么？ {'建议摆放尺寸': '推荐安装大小', '是否带遥控器': '是否配备遥控器', '充电功率': '充电能力', '使用方式': '使用方法'}\n",
      "2031 a20air和g10spro的推荐安装大小、[是否配备遥控器]以及g20标准版和p10spro的[充电能力]、[使用方法]是什么？ {'建议摆放尺寸': '推荐安装大小', '是否带遥控器': '是否配备遥控器', '充电功率': '充电能力', '使用方式': '使用方法'}\n",
      "2032 a20air和g10spro的推荐安装大小、[是否配备遥控器]以及g20标准版和p10spro的[充电能力]、[使用方法]是什么？ {'建议摆放尺寸': '推荐安装大小', '是否带遥控器': '是否配备遥控器', '充电功率': '充电能力', '使用方式': '使用方法'}\n",
      "2033 能告诉我a20air和g10spro的适合放置规格、[遥控器配置]以及g20标准版和p10spro的[充电容量]、[操作方式]吗？ {'建议摆放尺寸': '适合放置规格', '是否带遥控器': '遥控器配置', '充电功率': '充电容量', '使用方式': '操作方式'}\n",
      "2034 能告诉我a20air和g10spro的适合放置规格、[遥控器配置]以及g20标准版和p10spro的[充电容量]、[操作方式]吗？ {'建议摆放尺寸': '适合放置规格', '是否带遥控器': '遥控器配置', '充电功率': '充电容量', '使用方式': '操作方式'}\n",
      "2035 能告诉我a20air和g10spro的适合放置规格、[遥控器配置]以及g20标准版和p10spro的[充电容量]、[操作方式]吗？ {'建议摆放尺寸': '适合放置规格', '是否带遥控器': '遥控器配置', '充电功率': '充电容量', '使用方式': '操作方式'}\n",
      "2036 a20air和g10spro的理想放置尺寸、[配备遥控器否]和g20标准版和p10spro的[电源能力]、[操作模式]是什么？ {'建议摆放尺寸': '理想放置尺寸', '是否带遥控器': '配备遥控器否', '充电功率': '电源能力', '使用方式': '操作模式'}\n",
      "2037 a20air和g10spro的理想放置尺寸、[配备遥控器否]和g20标准版和p10spro的[电源能力]、[操作模式]是什么？ {'建议摆放尺寸': '理想放置尺寸', '是否带遥控器': '配备遥控器否', '充电功率': '电源能力', '使用方式': '操作模式'}\n",
      "2038 a20air和g10spro的理想放置尺寸、[配备遥控器否]和g20标准版和p10spro的[电源能力]、[操作模式]是什么？ {'建议摆放尺寸': '理想放置尺寸', '是否带遥控器': '配备遥控器否', '充电功率': '电源能力', '使用方式': '操作模式'}\n",
      "2039 请问a20air和g10spro的推荐设立大小、[是否有遥控器]与g20标准版和p10spro的[供电能力]、[如何使用]是多少？ {'建议摆放尺寸': '推荐设立大小', '是否带遥控器': '是否有遥控器', '充电功率': '供电能力', '使用方式': '如何使用'}\n",
      "2040 请问a20air和g10spro的推荐设立大小、[是否有遥控器]与g20标准版和p10spro的[供电能力]、[如何使用]是多少？ {'建议摆放尺寸': '推荐设立大小', '是否带遥控器': '是否有遥控器', '充电功率': '供电能力', '使用方式': '如何使用'}\n",
      "2041 请问a20air和g10spro的推荐设立大小、[是否有遥控器]与g20标准版和p10spro的[供电能力]、[如何使用]是多少？ {'建议摆放尺寸': '推荐设立大小', '是否带遥控器': '是否有遥控器', '充电功率': '供电能力', '使用方式': '如何使用'}\n"
     ]
    }
   ],
   "source": [
    "error_indices = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded.augment.iloc[i][\"replace\"]\n",
    "    question_raw =  df_exploded.augment.iloc[i][\"sentence\"]\n",
    "    for key in replace:\n",
    "        if \"[\"+replace[key]+\"]\" not in question_raw:\n",
    "            print(i, question_raw, replace)\n",
    "            error_indices.append(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "039757bd-0ee2-4f83-89f2-b2862f235495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.drop([df_exploded.index[i] for i in error_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "901e6b88-f3da-4a75-9209-d606eddad2a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "886 {'sentence': '请告知我[g20标准版]的[主刷转速]以及[p10s标准版]是否具备[虚拟墙设定]功能?', 'replace': {'g20标准版': 'g20标准版', '主刷转速': '主刷转速', 'p10s标准版': 'p10s标准版', '虚拟墙设定': '虚拟墙设定'}} {'sentence': '比较下，[g20标准版]的[主刷转速]是多少，以及[p10s标准版]有没有[虚拟墙设定]？', 'replace': {'主刷转速': '主刷转速', '有无虚拟墙': '虚拟墙设定'}}\n",
      "887 {'sentence': '我想了解一下，[g20标准版]的[主刷旋转速度]是多少，以及[p10s标准版]是否[支持虚拟墙功能]？', 'replace': {'g20标准版': 'g20标准版', '主刷旋转速度': '主刷旋转速度', 'p10s标准版': 'p10s标准版', '支不支持虚拟墙功能': '支持虚拟墙功能'}} {'sentence': '能告诉我[g20标准版]的[主刷旋转速度]以及[p10s标准版]它[支不支持虚拟墙功能]吗？', 'replace': {'主刷转速': '主刷旋转速度', '有无虚拟墙': '支不支持虚拟墙功能'}}\n",
      "888 {'sentence': '我想了解下[g20标准版]的[主刷旋转速率]以及[p10s标准版]的[虚拟墙功能是否开放]？', 'replace': {'g20标准版': 'g20标准版', '主刷旋转速率': '主刷旋转速率', 'p10s标准版': 'p10s标准版', '虚拟墙功能是否开放': '虚拟墙功能是否开放'}} {'sentence': '请问[g20标准版]的[主刷旋转速率]和[p10s标准版]的[虚拟墙功能是否开放]是什么样的？', 'replace': {'主刷转速': '主刷旋转速率', '有无虚拟墙': '虚拟墙功能是否开放'}}\n",
      "1241 {'sentence': '你能告诉我[电源线]的长度和[h1neo进水口]的长度吗，这两者都是h1的部分？', 'replace': {'电源线': '电源线', 'h1neo的进水口': 'h1neo进水口'}} {'sentence': '能告诉我h1的[电源线]有多长，以及h1neo的[进水口]有多长吗？', 'replace': {'电源线长度': '电源线', '进水管长度': '进水口'}}\n",
      "1769 {'sentence': '请问m1和h1neo[使用什么电机]，他们的[开关方式]是什么并且他们的[洗涣液的容量]是多少？同时，我想知道h1neo和h1在[脱水时的噪音]、[洗涤过程所需的时间]和[小件程序的时长]上的具体区别。', 'replace': {'使用什么电机': '使用什么电机', '开关方式': '开关的方式', '洗涣液的容量': '洗涣液的容量', '脱水时的噪音': '脱水时的噪音', '洗涤过程所需的时间': '洗涤过程所需的时间', '小件程序的时长': '小件程序的时长'}} {'sentence': 'm1和h1neo都[使用什么电机]、[开关的方式]和[洗涣液的容量]是多少？而h1neo和h1在[脱水时的噪音]、[洗涤过程所需的时间]和[小件程序的时长]上有何不同？', 'replace': {'电机类型': '使用什么电机', '开合方式': '开关的方式', '洗衣液容量': '洗涣液的容量', '脱水噪音': '脱水时的噪音', '洗涤程序时间': '洗涤过程所需的时间', '小件程序时长': '小件程序的时长'}}\n",
      "1770 {'sentence': '你能告诉我m1和h1neo具体是[使用什么电机]的，它们的[开关方式]是怎样的，并且他们的[洗涣液的容量]有多少吗？还有就是我想知道h1neo和h1在[脱水时的噪音]、[洗涤过程所需的时间]及[小件程序的时长]上各有哪些差异？', 'replace': {'使用什么电机': '使用什么电机', '开关方式': '开关的方式', '洗涣液的容量': '洗涣液的容量', '脱水时的噪音': '脱水时的噪音', '洗涤过程所需的时间': '洗涤过程所需的时间', '小件程序的时长': '小件程序的时长'}} {'sentence': 'm1和h1neo都[使用什么电机]、[开关的方式]和[洗涣液的容量]是多少？而h1neo和h1在[脱水时的噪音]、[洗涤过程所需的时间]和[小件程序的时长]上有何不同？', 'replace': {'电机类型': '使用什么电机', '开合方式': '开关的方式', '洗衣液容量': '洗涣液的容量', '脱水噪音': '脱水时的噪音', '洗涤程序时间': '洗涤过程所需的时间', '小件程序时长': '小件程序的时长'}}\n",
      "1775 {'sentence': '我可以获取关于m1和h1neo[电机种类]，[开关操作方法]和[能装多少洗涣液]的信息吗？并且，我也想了解h1neo和h1的[脱水时的噪音]，[洗涤过程大约需要多少时间]和[小件程序时长]。', 'replace': {'电机种类': '电机种类', '开关操作方法': '开关操作方法', '能装多少洗涣液': '能装多少洗涣液', '脱水时的噪音': '脱水时的噪音', '洗涤过程大约需要多少时间': '洗涤过程大约需要多少时间', '小件程序时长': '小件程序时长'}} {'sentence': '我想了解一下m1和h1neo的[电机种类]、[开关操作方法]以及[能装多少洗涣液]？同时，h1neo和h1的[在脱水时的噪音]、[洗涤过程大约需要多少时间]以及[小件程序时长]可以告诉我吗？', 'replace': {'电机类型': '电机种类', '开合方式': '开关操作方法', '洗衣液容量': '能装多少洗涣液', '脱水噪音': '在脱水时的噪音', '洗涤程序时间': '洗涤过程大约需要多少时间', '小件程序时长': '小件程序时长'}}\n",
      "1776 {'sentence': '能否提供一些信息，例如m1和h1neo的[电机种类]，[开关操作方法]和[能装多少洗涣液]？同时，我也对h1neo和h1的[脱水时的噪音]，[洗涤过程大约需要多少时间]以及[小件程序时长]感兴趣。', 'replace': {'电机种类': '电机种类', '开关操作方法': '开关操作方法', '能装多少洗涣液': '能装多少洗涣液', '脱水时的噪音': '脱水时的噪音', '洗涤过程大约需要多少时间': '洗涤过程大约需要多少时间', '小件程序时长': '小件程序时长'}} {'sentence': '我想了解一下m1和h1neo的[电机种类]、[开关操作方法]以及[能装多少洗涣液]？同时，h1neo和h1的[在脱水时的噪音]、[洗涤过程大约需要多少时间]以及[小件程序时长]可以告诉我吗？', 'replace': {'电机类型': '电机种类', '开合方式': '开关操作方法', '洗衣液容量': '能装多少洗涣液', '脱水噪音': '在脱水时的噪音', '洗涤程序时间': '洗涤过程大约需要多少时间', '小件程序时长': '小件程序时长'}}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "error_indices = []\n",
    "true_entity_list = []\n",
    "pred_entity_list = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    try:\n",
    "        for intermediate_true_entity in df_exploded[\"augment_sentence_only\"].iloc[i][\"replace\"]:\n",
    "            inv_dict = copy.deepcopy(df_exploded[\"augment\"].iloc[i][\"replace\"])\n",
    "            inv_dict = {inv_dict[key]: key for key in inv_dict}\n",
    "            true_entity_list.append(inv_dict[intermediate_true_entity])\n",
    "            pred_entity_list.append(df_exploded[\"augment_sentence_only\"].iloc[i][\"replace\"][intermediate_true_entity])\n",
    "    except:\n",
    "        error_indices.append(i)\n",
    "        print(i, df_exploded[\"augment_sentence_only\"].iloc[i], df_exploded[\"augment\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "180309bc-e636-4f04-9307-c4873a0800f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.drop([df_exploded.index[i] for i in error_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "6fdfbf48-2da2-423b-be9b-2cae2732e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "3ec56426-e2cd-42c7-aaa7-2e21859a8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"index_all\"] = range(df_exploded.shape[0])\n",
    "df_exploded[\"index_all\"] = df_exploded[\"index_all\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "39996b3f-ba79-4dda-9455-96e5c9897424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 这个是用来训练embedding召回模型的训练集\n",
    "# import copy\n",
    "# true_entity_list = []\n",
    "# pred_entity_list = []\n",
    "# for i in range(df_exploded.shape[0]):\n",
    "#     for intermediate_true_entity in df_exploded[\"augment_sentence_only\"].iloc[i][\"replace\"]:\n",
    "#         inv_dict = copy.deepcopy(df_exploded[\"augment\"].iloc[i][\"replace\"])\n",
    "#         inv_dict = {inv_dict[key]: key for key in inv_dict}\n",
    "#         true_entity_list.append(inv_dict[intermediate_true_entity])\n",
    "#         pred_entity_list.append(df_exploded[\"augment_sentence_only\"].iloc[i][\"replace\"][intermediate_true_entity])\n",
    "# df_entity = pd.DataFrame()\n",
    "# df_entity[\"true_entity\"] = true_entity_list\n",
    "# df_entity[\"pred_entity\"] = pred_entity_list\n",
    "# df_entity.to_csv(\"/data/dataset/kefu/entity_link.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "cee61988-2e61-4ede-a8f7-4cf7ed2db5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个是给业务人员打标用的训练集\n",
    "# df_exploded[\"crafted_question\"] = df_exploded[\"augment_sentence_only\"].apply(lambda x: x[\"sentence\"])\n",
    "# df_exploded[\"real_entities\"] = df_exploded[\"augment\"].apply(lambda x: x[\"replace\"])\n",
    "# df_exploded[\"set_name\"] = \"train\"\n",
    "# output_cols = [\"set_name\", \"index_all\", \"cat\", \"template\", \"crafted_question\", \"real_entities\"]\n",
    "# df_exploded[output_cols].to_excel(\"/data/dataset/kefu/for_label.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "864ad50a-c589-461a-8f22-466637065007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-name', 'I-name'], id=None), length=-1, id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'index_all': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = Features({'ner_tags': Sequence(ClassLabel(num_classes=3, names=['O', 'B-name', 'I-name'])),\n",
    "                     'tokens': Sequence(Value(dtype='string')), \n",
    "                     \"index_all\": Value(dtype='int32')})\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "78130d43-ab19-47a2-9dda-965653458ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = Dataset.from_pandas(df_exploded[[\"bio_words\", \"bio_tags_id\", \"index_all\"]].rename(columns={\"bio_words\": \"tokens\", \"bio_tags_id\": \"ner_tags\"}),\n",
    "                    features=features, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "212cba71-a141-4e77-8560-16776ee02731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8770d68a506646b0925d79a8e0507ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2027 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets.save_to_disk(\"/data/dataset/kefu/ner_from_template_augment_dataset_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "c189a9c3-0ac4-47ff-958e-3ae8dd3e4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做NER模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "e1826022-bbef-489a-9ccf-f055cb5f9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "7b67e3eb-cb5f-4629-aaef-e3fbc9e351e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = load_from_disk(\"/data/dataset/kefu/ner_from_template_augment_dataset_2\")\n",
    "test_datasets = load_from_disk(\"/data/dataset/kefu/ner_from_template_augment_test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "d7cd411f-49ee-4446-9b86-141501663b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets_split = test_datasets.train_test_split(test_size=0.2, seed=42, shuffle=True, stratify_by_column=\"cat_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "0dc8f26e-bdf2-4b04-9319-7e271df61571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个新的 DatasetDict\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': train_datasets,\n",
    "    'valid': test_datasets_split['test'],\n",
    "    'test': test_datasets_split['train'],\n",
    "    'all': test_datasets\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "c08a8012-ba6e-4a96-ac99-c677ec312f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-name', 'I-name']"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets['train'].features[\"ner_tags\"]\n",
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "040c0a2e-6b75-440f-a92f-493bf7713764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "能 否 给 我 一 个 g 2 0 标 准 版 的 商      品      访      问      链      接      ？ \n",
      "O O O O O O O O O O O O O B-name I-name I-name I-name I-name I-name O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets['train'][0][\"tokens\"]\n",
    "labels = raw_datasets['train'][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "dcd051e5-bfde-480d-887b-a64a67c86738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-bert-wwm')\n",
    "tokenizer = AutoTokenizer.from_pretrained('/data/dataset/huggingface/hub/bert-base-chinese')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('/data/dataset/huggingface/hub/bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "2df79f6a-1c41-46bd-beca-a615ea983b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "cd16ed44-4fa9-48c4-b142-79f3b31d84e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '能',\n",
       " '否',\n",
       " '给',\n",
       " '我',\n",
       " '一',\n",
       " '个',\n",
       " 'g',\n",
       " '2',\n",
       " '0',\n",
       " '标',\n",
       " '准',\n",
       " '版',\n",
       " '的',\n",
       " '商',\n",
       " '品',\n",
       " '访',\n",
       " '问',\n",
       " '链',\n",
       " '接',\n",
       " '？',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "5247d6e3-e678-4977-bf38-aea26384cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "b0225841-7dfc-44ea-9a19-63fb578f136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0]\n",
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "3bf75f43-0abd-48a8-897c-ab3c4d08c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "07a2941b-d125-4bd1-a824-11e56eaad864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1dee3db07441a2837daed3b72591d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "0781e07d-6726-4e9a-a193-8302c58db343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2027\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['cat_num', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 314\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['cat_num', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1253\n",
       "    })\n",
       "    all: Dataset({\n",
       "        features: ['cat_num', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1567\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "1bc04089-2b7d-4aab-a358-2c5011a45908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "054c807b-5934-4e07-be42-c422f2a7929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    1,    2,    2,    2,    2,    2,    0, -100],\n",
       "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            1,    2,    2,    2,    0,    0, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "4e9fec51-74f3-4ebe-9cf8-7c7538aad283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, -100]\n",
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "ec897e79-e002-4c42-ad1d-729b513856f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-name',\n",
       " 'I-name',\n",
       " 'I-name',\n",
       " 'I-name',\n",
       " 'I-name',\n",
       " 'I-name',\n",
       " 'O']"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "d78998bc-6d44-4711-a995-1674d5838e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "ca6dd20e-b61e-41d0-81bd-8e5b5b656280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /data/dataset/huggingface/hub/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    '/data/dataset/huggingface/hub/bert-base-chinese',\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "4060a1ec-d108-4a94-9b7a-2a610614e450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\n",
    "#     '/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/',\n",
    "#     id2label=id2label,\n",
    "#     label2id=label2id,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "b674de8f-6916-49da-ac70-b42617bd89c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "3bdd0c5d-6903-4ea0-b4a4-8694a2dbff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "id": "d4c0aff2-e115-455b-927e-fde7fc7708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "b3900b38-b624-4c6e-ba22-23aac20bd706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "args = TrainingArguments(\n",
    "    \"/workspace/data/private/zhuxiaohai/models/bert-finetuned-ner-augmented\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    per_device_train_batch_size=8,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "95e7fd7f-97c5-4521-a283-bb7f6edf9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "47005107-56f1-47b6-9b98-6c475713df14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2032' max='2032' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2032/2032 03:55, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.075186</td>\n",
       "      <td>0.819765</td>\n",
       "      <td>0.870550</td>\n",
       "      <td>0.844395</td>\n",
       "      <td>0.974440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.877405</td>\n",
       "      <td>0.906611</td>\n",
       "      <td>0.891769</td>\n",
       "      <td>0.980501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.058424</td>\n",
       "      <td>0.896163</td>\n",
       "      <td>0.917707</td>\n",
       "      <td>0.906807</td>\n",
       "      <td>0.983261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.056268</td>\n",
       "      <td>0.903576</td>\n",
       "      <td>0.922792</td>\n",
       "      <td>0.913083</td>\n",
       "      <td>0.985428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.062229</td>\n",
       "      <td>0.909747</td>\n",
       "      <td>0.932039</td>\n",
       "      <td>0.920758</td>\n",
       "      <td>0.986176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.057573</td>\n",
       "      <td>0.923007</td>\n",
       "      <td>0.936662</td>\n",
       "      <td>0.929784</td>\n",
       "      <td>0.988110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.059289</td>\n",
       "      <td>0.924374</td>\n",
       "      <td>0.938049</td>\n",
       "      <td>0.931161</td>\n",
       "      <td>0.988394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>0.926061</td>\n",
       "      <td>0.938049</td>\n",
       "      <td>0.932017</td>\n",
       "      <td>0.988394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2032, training_loss=0.03375346463092962, metrics={'train_runtime': 235.9954, 'train_samples_per_second': 68.713, 'train_steps_per_second': 8.61, 'total_flos': 601206914021418.0, 'train_loss': 0.03375346463092962, 'epoch': 8.0})"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "8d9e0c62-125d-4e33-addc-d39de866fc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0807223990559578,\n",
       " 'eval_precision': 0.9032258064516129,\n",
       " 'eval_recall': 0.9242718446601942,\n",
       " 'eval_f1': 0.9136276391554702,\n",
       " 'eval_accuracy': 0.9841337000211551,\n",
       " 'eval_runtime': 1.0595,\n",
       " 'eval_samples_per_second': 296.376,\n",
       " 'eval_steps_per_second': 37.755,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "2c06924f-92c7-4567-bc56-adc84bf0ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05905203893780708,\n",
       " 'eval_precision': 0.9260611592879964,\n",
       " 'eval_recall': 0.938049006010171,\n",
       " 'eval_f1': 0.9320165365181443,\n",
       " 'eval_accuracy': 0.9883936861652739,\n",
       " 'eval_runtime': 4.9372,\n",
       " 'eval_samples_per_second': 253.786,\n",
       " 'eval_steps_per_second': 31.799,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "id": "9893f6e5-33d7-450e-9992-5e2b5c91e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = pd.read_csv(\"/data/dataset/kefu/table_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "id": "68b7cf34-bbac-4afd-b61d-6c67c4470308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 16)"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "eeb3ecc8-5a9f-40df-956f-6d00e867433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['cat_num', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1567\n",
       "})"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "f4f693fd-4fd9-4ba9-a651-592eb4f0669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = trainer.predict(tokenized_datasets[\"all\"]).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "id": "e9dd4804-7c9f-4721-a6b9-2e544980d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"pred\"] = np.argmax(a, axis=-1).tolist()\n",
    "df_exploded[\"labels\"] = tokenized_datasets[\"all\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "id": "81951661-b9dc-4fa3-ba95-445b29415db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_groupby(df):\n",
    "    labels = df[\"labels\"].tolist()\n",
    "    predictions = df[\"pred\"].tolist()\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "    [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return pd.Series({\n",
    "        \"num\": df.shape[0],\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "8c9bb7d1-cfa6-4e95-b1d4-74ffe3daf3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1340229/569249638.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stat = df_exploded.groupby([\"type\", \"cat_num\"]).apply(lambda x: compute_groupby(x))\n"
     ]
    }
   ],
   "source": [
    "stat = df_exploded.groupby([\"type\", \"cat_num\"]).apply(lambda x: compute_groupby(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "93378b61-e817-4502-a1ca-d48cf8c4d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>primary_key_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gen_different_keywords_different_models</th>\n",
       "      <th>2</th>\n",
       "      <td>650.0</td>\n",
       "      <td>0.946483</td>\n",
       "      <td>0.953775</td>\n",
       "      <td>0.950115</td>\n",
       "      <td>0.990992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gen_different_keywords_different_models_v2</th>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.950893</td>\n",
       "      <td>0.942478</td>\n",
       "      <td>0.990590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.861925</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.871036</td>\n",
       "      <td>0.979114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_same_keywords_for_models</th>\n",
       "      <th>1</th>\n",
       "      <td>682.0</td>\n",
       "      <td>0.867898</td>\n",
       "      <td>0.894583</td>\n",
       "      <td>0.881038</td>\n",
       "      <td>0.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gen_same_keywords_for_models_v2</th>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.996833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              num  precision  \\\n",
       "type                                       primary_key_num                     \n",
       "gen_different_keywords_different_models    2                650.0   0.946483   \n",
       "gen_different_keywords_different_models_v2 4                 56.0   0.934211   \n",
       "                                           6                 59.0   0.861925   \n",
       "gen_same_keywords_for_models               1                682.0   0.867898   \n",
       "gen_same_keywords_for_models_v2            2                 60.0   1.000000   \n",
       "                                           3                 60.0   0.983333   \n",
       "\n",
       "                                                              recall  \\\n",
       "type                                       primary_key_num             \n",
       "gen_different_keywords_different_models    2                0.953775   \n",
       "gen_different_keywords_different_models_v2 4                0.950893   \n",
       "                                           6                0.880342   \n",
       "gen_same_keywords_for_models               1                0.894583   \n",
       "gen_same_keywords_for_models_v2            2                1.000000   \n",
       "                                           3                0.983333   \n",
       "\n",
       "                                                                  f1  accuracy  \n",
       "type                                       primary_key_num                      \n",
       "gen_different_keywords_different_models    2                0.950115  0.990992  \n",
       "gen_different_keywords_different_models_v2 4                0.942478  0.990590  \n",
       "                                           6                0.871036  0.979114  \n",
       "gen_same_keywords_for_models               1                0.881038  0.980300  \n",
       "gen_same_keywords_for_models_v2            2                1.000000  1.000000  \n",
       "                                           3                0.983333  0.996833  "
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "4509a497-ac20-4227-b822-5edbc378cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "1d32677e-c7e1-48bb-9d37-3b1bc499ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"ner\"] = df_exploded[\"question\"].apply(lambda x: token_classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "f392ca44-d9af-481d-93b0-85bb555bc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"ner_word\"] = df_exploded[\"ner\"].apply(lambda x: [i[\"word\"] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "0b295b9b-1de9-47fd-9c96-c54a4c4e0c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_raw</th>\n",
       "      <th>ner_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>请问m1和h1有多少[浸泡功能]，h1neo和h1的[控制方式]是什么？</td>\n",
       "      <td>[浸 泡 功 能, 控 制 方 式]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>能介绍一下m1和h1所含的[浸泡功能]，以及h1neo和h1的[控制方式]吗？</td>\n",
       "      <td>[浸 泡 功 能, 控 制 方 式]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>m1和h1的[浸泡功能]、h1neo和h1的[控制方式]是什么呢？</td>\n",
       "      <td>[浸 泡 功 能, 控 制 方 式]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>m1和h1的[浸泡功能]，以及h1neo和h1的[控制方式]能告诉我吗？</td>\n",
       "      <td>[浸 泡 功 能, 控 制 方 式]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>我想了解一下m1和h1的[浸泡功能]以及h1neo和h1的[控制方式]。</td>\n",
       "      <td>[浸 泡 功 能, 控 制 方 式]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>想这样了解下，m1、h1和h1neo他们的[颜色分类有几种]，[盒子的尺寸]，以及[机器的实...</td>\n",
       "      <td>[颜 色 分 类 有 几 种, 盒 子 的 尺 寸, 机 器 的 实 际 尺 寸, 断 电 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>想请教下，m1、h1和h1neo分别有哪些[颜色分类]，他们[包装的尺寸]和[机器本身的尺寸...</td>\n",
       "      <td>[哪 些, 颜 色 分 类, 包 装 的 尺 寸, 机 器 本 身 的 尺 寸, 有 断 电...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>请问下，m1、h1和h1neo的[颜色分类]，[包装占用的空间大小]，以及[机器实际的尺寸]...</td>\n",
       "      <td>[颜 色 分 类, 包 装 占 用 的 空 间 大 小, 机 器 实 际 的 尺 寸, 断 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>可以告诉我m1、h1和h1neo的[有什么颜色分类]，[包装尺寸有多大]，[机器的尺寸是多少...</td>\n",
       "      <td>[有 什 么 颜 色 分 类, 包 装 尺 寸 有 多 大, 机 器 的 尺 寸 是 多 少...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>我想询问m1、h1和h1neo的[颜色分类有些什么]，[它们的包装尺寸]，以及[机器尺寸是多...</td>\n",
       "      <td>[颜 色 分 类 有 些 什 么, 包 装 尺 寸, 机 器 尺 寸, 是 否 支 持 断 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question_raw  \\\n",
       "1452               请问m1和h1有多少[浸泡功能]，h1neo和h1的[控制方式]是什么？   \n",
       "1453            能介绍一下m1和h1所含的[浸泡功能]，以及h1neo和h1的[控制方式]吗？   \n",
       "1454                  m1和h1的[浸泡功能]、h1neo和h1的[控制方式]是什么呢？   \n",
       "1455               m1和h1的[浸泡功能]，以及h1neo和h1的[控制方式]能告诉我吗？   \n",
       "1456               我想了解一下m1和h1的[浸泡功能]以及h1neo和h1的[控制方式]。   \n",
       "...                                                 ...   \n",
       "1518  想这样了解下，m1、h1和h1neo他们的[颜色分类有几种]，[盒子的尺寸]，以及[机器的实...   \n",
       "1519  想请教下，m1、h1和h1neo分别有哪些[颜色分类]，他们[包装的尺寸]和[机器本身的尺寸...   \n",
       "1520  请问下，m1、h1和h1neo的[颜色分类]，[包装占用的空间大小]，以及[机器实际的尺寸]...   \n",
       "1521  可以告诉我m1、h1和h1neo的[有什么颜色分类]，[包装尺寸有多大]，[机器的尺寸是多少...   \n",
       "1522  我想询问m1、h1和h1neo的[颜色分类有些什么]，[它们的包装尺寸]，以及[机器尺寸是多...   \n",
       "\n",
       "                                               ner_word  \n",
       "1452                                 [浸 泡 功 能, 控 制 方 式]  \n",
       "1453                                 [浸 泡 功 能, 控 制 方 式]  \n",
       "1454                                 [浸 泡 功 能, 控 制 方 式]  \n",
       "1455                                 [浸 泡 功 能, 控 制 方 式]  \n",
       "1456                                 [浸 泡 功 能, 控 制 方 式]  \n",
       "...                                                 ...  \n",
       "1518  [颜 色 分 类 有 几 种, 盒 子 的 尺 寸, 机 器 的 实 际 尺 寸, 断 电 ...  \n",
       "1519  [哪 些, 颜 色 分 类, 包 装 的 尺 寸, 机 器 本 身 的 尺 寸, 有 断 电...  \n",
       "1520  [颜 色 分 类, 包 装 占 用 的 空 间 大 小, 机 器 实 际 的 尺 寸, 断 ...  \n",
       "1521  [有 什 么 颜 色 分 类, 包 装 尺 寸 有 多 大, 机 器 的 尺 寸 是 多 少...  \n",
       "1522  [颜 色 分 类 有 些 什 么, 包 装 尺 寸, 机 器 尺 寸, 是 否 支 持 断 ...  \n",
       "\n",
       "[71 rows x 2 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[(df_exploded[\"type\"]==\"gen_different_keywords_different_models_v2\"\n",
    "            )&(df_exploded[\"cat_num\"]==1)][[\"question_raw\", \"ner_word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "9e600ff5-f8fc-4642-a5b3-1bd4543bc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER模型的召回效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d9c6bb2-21c5-4d18-9c71-87dd9e48f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77917700-184c-4c6f-9c37-8035ecabe178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "dim_df.model = dim_df.model.apply(lambda x: x.replace(\"版本\", \"\").replace(\"版\", \"\"))\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()\n",
    "all_model_list = [i.replace(\"版本\", \"\").replace(\"版\", \"\") for i in all_model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9781fe54-c6a6-4053-9830-8fbf3bf1fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = pd.read_csv(\"/data/dataset/kefu/table_qa.csv\")\n",
    "df_exploded[\"augment\"] = df_exploded[\"augment\"].apply(lambda x: json.loads(x))\n",
    "df_exploded[\"gen\"] = df_exploded[\"gen\"].apply(lambda x: json.loads(x))\n",
    "df_exploded[\"final_prompt\"] = df_exploded[\"final_prompt\"].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ea05e04-cdd0-4211-9c82-53cff023b92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"augment\"].apply(lambda x: len(x[\"replace\"])==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc1741eb-a80e-47f3-947c-7f3627c01c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"augment\"].apply(lambda x: x[\"sentence\"].find(\"[\")<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "42e18ec0-5f69-40b0-88b6-5381533ce0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS, Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d58296b-df45-4e5b-9a90-43c67757f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"model_list\"] = df_exploded['gen'].apply(lambda x: [item[\"primary_value\"] for item in x[\"prompt\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd453cd2-fc9f-4f62-9622-0059f19895be",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_set = list(df_all.columns)\n",
    "exclude_cols = [\"平台ID\", \"商品id\", \"商品编码\", \"商品分类\", \"商品名字\", \"版本\", \"商品型号\", \"primary_key\"]\n",
    "schema_set = [col for col in schema_set if col not in exclude_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2073a54-76c6-474b-90bc-de1188e71cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for index, line in enumerate(schema_set):\n",
    "    data = {\"entity_name\": line, \n",
    "            \"washing\": \"washing\" in filter[line],\n",
    "            \"mopping\": \"mopping\" in filter[line],\n",
    "            \"sweeping\": \"sweeping\" in filter[line],\n",
    "            \"content\": line.lower(),\n",
    "            \"ids\": index,\n",
    "           }\n",
    "    docs.append(data)\n",
    "docs = pd.DataFrame(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6eb8e8a5-7a07-4296-86c5-d89e660d9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_csv(\"data/table_entity.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20e75321-38a6-4682-9fee-8346531ec975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = HuggingFaceEmbeddings(model_name=\"/data/dataset/huggingface/hub/bge-large-zh-v1.5\", \n",
    "#                                    encode_kwargs = {'normalize_embeddings': True},\n",
    "#                                    model_kwargs={'device': 'cuda:0'})\n",
    "# encoder = HuggingFaceEmbeddings(model_name=\"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\", \n",
    "#                                    encode_kwargs = {'normalize_embeddings': True},\n",
    "#                                    model_kwargs={'device': 'cuda:0'})\n",
    "encoder = HuggingFaceEmbeddings(model_name=\"/workspace/data/private/zhuxiaohai/models/bge_finetuned_emb_ner_link\", \n",
    "                                   encode_kwargs = {'normalize_embeddings': True},\n",
    "                                   model_kwargs={'device': 'cuda:0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a9d0e84-78f1-4b1d-9a6c-22a77c826387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize the Chroma client\n",
    "chroma_client = Chroma()\n",
    "\n",
    "# List all collections\n",
    "collections = chroma_client._client.list_collections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aedd8863-59f0-498e-9202-583a9f2ae389",
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection in collections:\n",
    "    chroma_client._client.delete_collection(collection.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7cc6b131-e141-4579-86d2-9581890b769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = HuggingFaceBgeEmbeddings(model_name=\"/data/dataset/huggingface/hub/bge-large-zh-v1.5\", \n",
    "#                                    encode_kwargs = {'normalize_embeddings': True},\n",
    "#                                    model_kwargs={'device': 'cuda:0'})\n",
    "\n",
    "store = Chroma.from_documents([Document(page_content=line, metadata={\"id\": id,\n",
    "                                                                    \"washing\": \"washing\" in filter[line],\n",
    "                                                                    \"mopping\": \"mopping\" in filter[line],\n",
    "                                                                    \"sweeping\": \"sweeping\" in filter[line],\n",
    "                                                                     \"content\": line.lower(),\n",
    "                                                                   })\n",
    " for id, line in enumerate(schema_set)], embedding=encoder, collection_name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11084554-5fd9-4dba-b394-abeba5a1684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastbm25 import fastbm25\n",
    "# from utils import WordCut\n",
    "# wc = WordCut()\n",
    "\n",
    "# bm25 = fastbm25([wc.cut(doc) for doc in schema_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c5d1f6a1-c506-480b-90f4-750fe2a11064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_blocks(models, keywords):\n",
    "    models_name_list = [model[0] for model in models] \n",
    "    keywords_name_list = [keyword[0] for keyword in keywords]\n",
    "    positions = sorted(models + keywords, key=lambda x: x[1])\n",
    "    model_blocks = []\n",
    "    keyword_blocks = []\n",
    "\n",
    "    current_model_block = []\n",
    "    current_keyword_block = []\n",
    "\n",
    "    for i, (word, start, end) in enumerate(positions):\n",
    "        if word in models_name_list:\n",
    "            if (i == 0 or positions[i-1][0] in keywords_name_list):\n",
    "                if current_model_block:\n",
    "                    model_blocks.append(current_model_block)\n",
    "                current_model_block = [(word, start, end)]\n",
    "            else:\n",
    "                current_model_block.append((word, start, end))\n",
    "\n",
    "            if (i == len(positions) - 1 or positions[i+1][0] in keywords_name_list):\n",
    "                model_blocks.append(current_model_block)\n",
    "                current_model_block = []\n",
    "        elif word in keywords_name_list:\n",
    "            if (i == 0 or positions[i-1][0] in models_name_list):\n",
    "                if current_keyword_block:\n",
    "                    keyword_blocks.append(current_keyword_block)\n",
    "                current_keyword_block = [(word, start, end)]\n",
    "            else:\n",
    "                current_keyword_block.append((word, start, end))\n",
    "\n",
    "            if (i == len(positions) - 1 or positions[i+1][0] in models_name_list):\n",
    "                keyword_blocks.append(current_keyword_block)\n",
    "                current_keyword_block = []\n",
    "\n",
    "    return model_blocks, keyword_blocks\n",
    "\n",
    "def find_nearest_model_block(keyword, model_blocks):\n",
    "    keyword_start = keyword[1]\n",
    "    left_model_block = None\n",
    "    right_model_block = None\n",
    "\n",
    "    for block in model_blocks:\n",
    "        block_end = block[-1][2]\n",
    "        block_start = block[0][1]\n",
    "\n",
    "        if block_end <= keyword_start:\n",
    "            left_model_block = block\n",
    "        elif block_start >= keyword_start and right_model_block is None:\n",
    "            right_model_block = block\n",
    "\n",
    "    if left_model_block:\n",
    "        return left_model_block\n",
    "    else:\n",
    "        return right_model_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29661c14-6b46-4702-8393-ace25a1ebb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]\n",
    "\n",
    "def recall_from_edit_distance(word, store, schema_set, recall_n=1, cat=None):\n",
    "    if cat is None:\n",
    "        filter = None\n",
    "    else:\n",
    "        cat = list(set(cat))\n",
    "        if len(cat) == 1:\n",
    "            filter = {cat[0]: True}\n",
    "        else:\n",
    "            cat_list = [ {\n",
    "                        i: True\n",
    "                    } for i in list(set(cat))]\n",
    "            filter = {\n",
    "                \"$or\": cat_list\n",
    "            }\n",
    "    filter_content = {\"$and\": [{\"content\": word.lower()}, filter]}\\\n",
    "            if filter else {\"content\": word.lower()}\n",
    "    searched = store.similarity_search_with_score(word, k=recall_n, filter=filter_content)\n",
    "    searched += store.similarity_search_with_score(word, k=recall_n, filter=filter)\n",
    "    recalls = [(schema_set[i[0].metadata[\"id\"]], i[1]) for i in searched]\n",
    "    # candidates = [i[0]find_model for i in recalls]\n",
    "    # edit_lens = [edit_distance(i, word) for i in candidates]\n",
    "    # return [cand for i, cand in enumerate(candidates) if edit_lens[i] != max(len(candidates[i]), len(word)) and edit_lens[i] <= 4]\n",
    "    results = [i[0] for i in recalls]\n",
    "    return results \n",
    "\n",
    "def recall_from_edit_distance2(word, store, schema_set, recall_n=3):\n",
    "    searched = store.top_k_sentence(wc.cut(word.lower()), k=recall_n)\n",
    "    results = [schema_set[i[1]] for i in searched]\n",
    "    return results \n",
    "\n",
    "def find_min_positive_index(b):\n",
    "    # 筛选出所有大于0的元素及其索引\n",
    "    positive_elements = [(index, value) for index, value in enumerate(b) if value > 0]\n",
    "    \n",
    "    # 如果没有大于0的元素，返回None\n",
    "    if not positive_elements:\n",
    "        return None\n",
    "    \n",
    "    # 找到最小的正值及其索引\n",
    "    min_index, min_value = min(positive_elements, key=lambda x: x[1])\n",
    "    \n",
    "    return min_index\n",
    "\n",
    "\n",
    "def prepare_columns_for_sql_v2(query_body, store, schema_set, all_model_dict, cat_list=None):\n",
    "    query = query_body[\"query\"]\n",
    "    model_list = find_model_v2(query, all_model_dict)\n",
    "    keywords = [(query[entity[\"start\"]:entity[\"end\"]], entity[\"start\"], entity[\"end\"]) for entity in query_body.get(\"entities\", [])]\n",
    "    # if cat_list is None:\n",
    "    #     model_blocks, keyword_blocks = find_blocks(model_list, keywords)\n",
    "    #     meta_keywords = []\n",
    "    #     name_map = {\"洗地机\": \"mopping\", \"洗衣机\": \"washing\", \"扫地机\": \"sweeping\"}\n",
    "    #     for keyword in keywords:\n",
    "    #         nearest_model_block = find_nearest_model_block(keyword, model_blocks)\n",
    "    #         if nearest_model_block:\n",
    "    #             words = [word for word, _, _ in nearest_model_block]\n",
    "    #             cat_list = [all_model_dict[word] for word in words]\n",
    "    #             cat_list = [name_map[i] for i in cat_list]\n",
    "    #         else:\n",
    "    #             cat_list = None\n",
    "    #         meta_keywords.append(cat_list)\n",
    "    if cat_list is None:\n",
    "        name_map = {\"洗地机\": \"mopping\", \"洗衣机\": \"washing\", \"扫地机\": \"sweeping\"}\n",
    "        cat_list = [all_model_dict[model[0]] for model in model_list]\n",
    "        cat_list = [name_map[i] for i in cat_list]\n",
    "        meta_keywords = []\n",
    "        for keyword in keywords:\n",
    "            meta_keywords.append(cat_list)\n",
    "    else:\n",
    "        meta_keywords = []\n",
    "        for keyword in keywords:\n",
    "            meta_keywords.append(cat_list)\n",
    "        \n",
    "    all_cols = []\n",
    "    \n",
    "    # for keyword in keywords:\n",
    "    #     if keyword[0] in schema_set:\n",
    "    #         all_cols.append(keyword[0])\n",
    "            \n",
    "    for keyword, cat in zip(keywords, meta_keywords):\n",
    "        all_cols += recall_from_edit_distance(keyword[0], store, schema_set, cat=cat)\n",
    "\n",
    "    all_cols_set = []\n",
    "    for col in all_cols:\n",
    "        if col not in all_cols_set:\n",
    "            all_cols_set.append(col)\n",
    "\n",
    "    return all_cols_set\n",
    "\n",
    "def get_keywords(model, query):\n",
    "    entities = model(query)\n",
    "    return {\"query\": query, \"entities\": entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b557480-c096-41f3-bc41-7b63f372665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"/workspace/data/private/zhuxiaohai/models/bert_finetuned_ner_augmented/\"\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee1fc407-2ca3-4e87-8246-697c35d3c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下这一段代码是用来造训练embedding召回模型的训练集最终版本的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "93b8a879-3157-4efc-a058-f04bcb3452fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_entity = pd.read_csv(\"/data/dataset/kefu/entity_link.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2b3082b0-c39b-4daa-80f1-6201cd11a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg = []\n",
    "# for i in range(df_entity.shape[0]):\n",
    "#     pred_entity = df_entity.iloc[i][\"pred_entity\"]\n",
    "#     true_entity = df_entity.iloc[i][\"true_entity\"]\n",
    "#     cat = list(filter[true_entity])\n",
    "#     # cat = None\n",
    "#     all_cols = recall_from_edit_distance(pred_entity, store, schema_set, recall_n=10, cat=cat)[2:5]\n",
    "#     neg.append(all_cols)\n",
    "# df_entity[\"neg\"] = neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5689df94-d6f7-48a1-94d6-a67d381fc0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_entity[\"true_entity\"] = df_entity[\"true_entity\"].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "187fe38a-735e-41b0-aac6-cea5704cc375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['商品链接',\n",
       " '采购地',\n",
       " '店铺名称',\n",
       " '支持APP',\n",
       " '平台',\n",
       " '产品信息',\n",
       " '导航类型',\n",
       " '标配清单',\n",
       " 'Wi-Fi连接',\n",
       " '电源线']"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall_from_edit_distance(\"商品访问链接\", store, schema_set, recall_n=10, cat=list({'mopping', 'sweeping', 'washing'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "db76b384-4d3c-41bd-9c0a-9237ce7726cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_jsonl(df, filename, query=\"question_cleaned\", pos_col=\"question_positive\", neg_col=\"question_bge_hard\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            # Constructing the dictionary for each row\n",
    "            data = {\n",
    "                \"query\": row[query],\n",
    "                \"pos\": row[pos_col],\n",
    "                \"neg\": row[neg_col]\n",
    "            }\n",
    "            # Writing the JSON string followed by a newline character to make it JSONL\n",
    "            file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "42e3b587-b916-45eb-a0a7-df2fd357df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_df_to_jsonl(df_entity, '/data/dataset/kefu/bge_finetune_emb_finetuned_ner_link_with_filter.jsonl', \n",
    "#                     query=\"pred_entity\", pos_col=\"true_entity\", neg_col=\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "e33b461d-afce-4ba9-b314-c53455c1eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_entity[\"neg\"].apply(lambda x: len(x)!= len(set(x))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "3a512f95-521f-490e-9902-57c3dde16e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_entity</th>\n",
       "      <th>pred_entity</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[商品链接]</td>\n",
       "      <td>商品访问链接</td>\n",
       "      <td>[店铺名称, 支持APP, 平台]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[商品链接]</td>\n",
       "      <td>购买链接</td>\n",
       "      <td>[标配清单, 店铺名称, 产品信息]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[商品链接]</td>\n",
       "      <td>在线购买页面链接</td>\n",
       "      <td>[平台, 支持APP, 店铺名称]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[平台]</td>\n",
       "      <td>平台</td>\n",
       "      <td>[商品链接, APP程序, 设备共享]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[平台]</td>\n",
       "      <td>系统平台</td>\n",
       "      <td>[控制面板程序, 设备共享, 标配]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  true_entity pred_entity                  neg\n",
       "0      [商品链接]      商品访问链接    [店铺名称, 支持APP, 平台]\n",
       "1      [商品链接]        购买链接   [标配清单, 店铺名称, 产品信息]\n",
       "2      [商品链接]    在线购买页面链接    [平台, 支持APP, 店铺名称]\n",
       "3        [平台]          平台  [商品链接, APP程序, 设备共享]\n",
       "4        [平台]        系统平台   [控制面板程序, 设备共享, 标配]"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_entity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912509f3-42d3-473c-99ee-ea0fdd2f5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上这一段代码是用来造训练embedding召回模型的训练集最终版本的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc8913cd-7df8-4f7c-bebb-ccf1b481a022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "gen_same_keywords_for_models                  682\n",
       "gen_different_keywords_different_models       650\n",
       "gen_same_keywords_for_models_v2               120\n",
       "gen_different_keywords_different_models_v2    115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b08c3470-6375-4274-927d-a8d9cb33769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"ner\"] = df_exploded[\"question\"].apply(lambda x: get_keywords(token_classifier, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83f0d622-9d79-4674-9bcf-5319ff3e4c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_model = store\n",
    "df_exploded[\"pred\"] = df_exploded[[\"ner\", \"cat\"]].apply(\n",
    "    lambda x: prepare_columns_for_sql_v2(x[\"ner\"], recall_model, schema_set, all_model_dict, x[\"cat\"].split(\",\")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "331e8431-14c7-43ab-9d70-1f1c5bbfc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred, gt):\n",
    "    gt_key = []\n",
    "    for item in gt:\n",
    "        for key in item[\"key\"].split(\"|\"):\n",
    "            gt_key.append(key)\n",
    "    gt_key = set(gt_key)\n",
    "    pred = set(pred)\n",
    "    match = gt_key & pred\n",
    "    if len(pred) > 0:\n",
    "        precision = len(match)/ len(pred)\n",
    "    else:\n",
    "        if len(gt_key) == 0:\n",
    "            precision = 1\n",
    "        else:\n",
    "            precision = 0\n",
    "    if len(gt_key) > 0:\n",
    "        recall = len(match) / len(gt_key)\n",
    "    else:\n",
    "        recall = 1\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "59634fda-37b5-4c7b-8888-2dad186dbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"metric\"] = df_exploded[[\"pred\", \"gen\"]].apply(lambda x: metric(x[\"pred\"], x[\"gen\"][\"prompt\"]), axis=1)\n",
    "df_exploded[\"precision\"] = df_exploded[\"metric\"].apply(lambda x: x[0])\n",
    "df_exploded[\"recall\"] = df_exploded[\"metric\"].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b435fbe-c7af-4a50-acbc-a74fae5eba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {\"洗地机\": \"mopping\", \"洗衣机\": \"washing\", \"扫地机\": \"sweeping\"}\n",
    "test_indices = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    primary = [j[\"primary_value\"] for j in df_exploded.gen[i][\"prompt\"]]\n",
    "    primary = list(set([model.replace(\"标准版\", \"\").replace(\"上下水版\", \"\").replace(\"上下水\", \"\") for model in primary]))\n",
    "    primary = sorted(primary)\n",
    "    query = df_exploded.ner.iloc[i][\"query\"]\n",
    "    model_list = find_model_v2(query, all_model_dict)\n",
    "    model_list = [model[0] for model in model_list]\n",
    "    model_list = list(set([model.replace(\"标准版\", \"\").replace(\"上下水版\", \"\").replace(\"上下水\", \"\") for model in model_list]))\n",
    "    model_list = sorted(model_list)\n",
    "    cat_list = list(set([all_model_dict[model] for model in model_list]))\n",
    "    cat_list = [name_map[cat] for cat in cat_list]\n",
    "    cat_list = sorted(cat_list)\n",
    "    raw_cat_list = df_exploded.cat.iloc[i].split(\",\")\n",
    "    raw_cat_list = sorted(raw_cat_list)\n",
    "    raw_key = list(set([j[\"key\"] for j in df_exploded.gen.iloc[i][\"prompt\"]]))\n",
    "    new_raw_key = []\n",
    "    for j in raw_key:\n",
    "        new_raw_key += j.split(\"|\")\n",
    "    new_raw_key = list(set(new_raw_key))\n",
    "    raw_key_cat = [filter[key] for key in new_raw_key]\n",
    "    set_cat = raw_key_cat[0]\n",
    "    for j in raw_key_cat[1:]:\n",
    "        set_cat |= j\n",
    "    set_cat = sorted(list(set_cat))\n",
    "    if cat_list != raw_cat_list:\n",
    "        if len(cat_list) > len(raw_cat_list):\n",
    "            print(i, query)\n",
    "            print(\"model\", cat_list)\n",
    "            print(\"raw\", raw_cat_list)\n",
    "            print(\"keycat\", set_cat)\n",
    "            break\n",
    "    else:\n",
    "        test_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3238b462-2670-47df-9f48-6925ee91e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt(gt):\n",
    "    gt_key = []\n",
    "    for item in gt:\n",
    "        for key in item[\"key\"].split(\"|\"):\n",
    "            gt_key.append(key)\n",
    "    gt_key = set(gt_key)\n",
    "    return list(gt_key)\n",
    "\n",
    "def get_pred(pred):\n",
    "    return list(set(pred))\n",
    "\n",
    "test = df_exploded.iloc[test_indices].copy()\n",
    "test[\"model_list\"] = test[\"ner\"].apply(lambda x: find_model_v2(x[\"query\"], all_model_dict))\n",
    "test[\"keywords\"] = test[\"ner\"].apply(lambda x: [\n",
    "    (x[\"query\"][entity[\"start\"]:entity[\"end\"]], entity[\"start\"], entity[\"end\"]) \n",
    "    for entity in x.get(\"entities\", [])])\n",
    "test[\"true_entity\"] = test[\"gen\"].apply(lambda x: get_gt(x[\"prompt\"]))\n",
    "test[\"pred_entity\"] = test[\"pred\"].apply(lambda x: get_pred(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1b246ca3-2ff3-48b7-b2ef-6fe274b40091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"keywords\", \"model_list\", \"true_entity\", \"pred_entity\"]:\n",
    "    test[col] = test[col].apply(lambda x: json.dumps(x, ensure_ascii=False))\n",
    "test[[\"question\", \"keywords\", \"model_list\", \"true_entity\", \"pred_entity\"]].to_csv(\"tests/data/data_table_qa.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3fe1c057-8202-41d4-abfd-90c519e0e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_map = {'洗地机': 'mopping', '洗衣机': 'washing', '扫地机': 'sweeping', \"吸尘器\": \"vacuum\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f43fdf74-8d80-4ab8-b676-85eaf9bf8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = []\n",
    "for col in all_model_dict:\n",
    "    data = {\"model\": col, \"cat\": name_map[all_model_dict[col]], \"cat_cn\": all_model_dict[col]}\n",
    "    dim_df.append(data)\n",
    "dim_df = pd.DataFrame(dim_df)\n",
    "dim_df.to_csv(\"data/dim_df20240619.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "925c57fb-2428-4907-9e50-e8636536f1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>primary_key_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gen_different_keywords_different_models</th>\n",
       "      <th>2</th>\n",
       "      <td>650</td>\n",
       "      <td>0.940513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gen_different_keywords_different_models_v2</th>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0.982993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>0.929742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_same_keywords_for_models</th>\n",
       "      <th>1</th>\n",
       "      <td>682</td>\n",
       "      <td>0.910802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gen_same_keywords_for_models_v2</th>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           precision          \n",
       "                                                                 len      mean\n",
       "type                                       primary_key_num                    \n",
       "gen_different_keywords_different_models    2                     650  0.940513\n",
       "gen_different_keywords_different_models_v2 4                      56  0.982993\n",
       "                                           6                      59  0.929742\n",
       "gen_same_keywords_for_models               1                     682  0.910802\n",
       "gen_same_keywords_for_models_v2            2                      60  0.941667\n",
       "                                           3                      60  0.994444"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.groupby([\"type\", \"primary_key_num\"]).agg({\"precision\": [len, \"mean\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "250873a3-b76c-4ba9-862d-3e02ca8c4f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>primary_key_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gen_different_keywords_different_models</th>\n",
       "      <th>2</th>\n",
       "      <td>650</td>\n",
       "      <td>0.949231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gen_different_keywords_different_models_v2</th>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0.994048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>0.995763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_same_keywords_for_models</th>\n",
       "      <th>1</th>\n",
       "      <td>682</td>\n",
       "      <td>0.931085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">gen_same_keywords_for_models_v2</th>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           recall          \n",
       "                                                              len      mean\n",
       "type                                       primary_key_num                 \n",
       "gen_different_keywords_different_models    2                  650  0.949231\n",
       "gen_different_keywords_different_models_v2 4                   56  0.994048\n",
       "                                           6                   59  0.995763\n",
       "gen_same_keywords_for_models               1                  682  0.931085\n",
       "gen_same_keywords_for_models_v2            2                   60  0.944444\n",
       "                                           3                   60  0.994444"
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.groupby([\"type\", \"primary_key_num\"]).agg({\"recall\": [len, \"mean\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "id": "cbd3435c-5784-4a18-8591-0c96df980ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                                        primary_key_num  recall  \n",
       "gen_different_keywords_different_models     2                1.000000    0.906154\n",
       "                                                             0.500000    0.086154\n",
       "                                                             0.000000    0.007692\n",
       "gen_different_keywords_different_models_v2  4                1.000000    0.964286\n",
       "                                                             0.833333    0.035714\n",
       "                                            6                1.000000    0.983051\n",
       "                                                             0.750000    0.016949\n",
       "gen_same_keywords_for_models                1                1.000000    0.931085\n",
       "                                                             0.000000    0.068915\n",
       "gen_same_keywords_for_models_v2             2                1.000000    0.933333\n",
       "                                                             0.000000    0.050000\n",
       "                                                             0.666667    0.016667\n",
       "                                            3                1.000000    0.983333\n",
       "                                                             0.666667    0.016667\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded.groupby([\"type\", \"primary_key_num\"])[\"recall\"].value_counts(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a2503c5-112e-414d-bbee-105c75a5e046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308034764639742"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"precision\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3ba768b-1cd4-4ad9-b3d8-214247b24271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462348436502872"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[\"recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac0b86b-0641-4b26-a089-9d53d9213678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NL2SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c4ed6192-6a5a-4ec8-af96-941709999bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "请你给我写一个sql从数据库查询型号参数，必须在查询结果中包括所有涉及的型号， 但是你需要根据我的问题从涉及的字段中准确选择而不是简单使用全部字段或者捏造字段。直接给出sql除此之外不要返回任何东西。\n",
    "1. 表名：df\n",
    "2. 涉及的型号：{}\n",
    "3. 涉及的字段：{}\n",
    "\n",
    "我的问题是：\n",
    "{}\n",
    "sql:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0954be36-694a-41d7-9177-606f7844d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer3(prompt, model_list, col_list, question, model=\"gpt-4-8k\"): # model = \"deployment_name\"\n",
    "    response = client.chat.completions.create(\n",
    "    model=model, # model = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt.format(\",\".join(model_list), \",\".join(col_list), question)},\n",
    "    ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dab96bd4-eb69-45ba-8606-b488262e0b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.00191497802734375\n",
      "10\n",
      "16.90106463432312\n",
      "20\n",
      "11.905110120773315\n",
      "30\n",
      "19.474507808685303\n",
      "40\n",
      "19.630595684051514\n",
      "50\n",
      "16.00170922279358\n",
      "60\n",
      "13.391375541687012\n",
      "70\n",
      "22.235890865325928\n",
      "80\n",
      "16.160751581192017\n",
      "90\n",
      "20.687827587127686\n",
      "100\n",
      "13.638507604598999\n",
      "110\n",
      "15.120668888092041\n",
      "120\n",
      "18.546640872955322\n",
      "130\n",
      "20.348158836364746\n",
      "140\n",
      "17.136104822158813\n",
      "150\n",
      "20.882124662399292\n",
      "160\n",
      "18.00317144393921\n",
      "170\n",
      "18.182682752609253\n",
      "180\n",
      "18.085890769958496\n",
      "190\n",
      "21.10001254081726\n",
      "200\n",
      "16.112658739089966\n",
      "210\n",
      "16.337135553359985\n",
      "220\n",
      "13.653748035430908\n",
      "230\n",
      "15.926572799682617\n",
      "240\n",
      "20.126106023788452\n",
      "250\n",
      "19.249960899353027\n",
      "260\n",
      "12.346578121185303\n",
      "270\n",
      "13.472089052200317\n",
      "280\n",
      "17.217100620269775\n",
      "290\n",
      "14.071109771728516\n",
      "300\n",
      "20.342352151870728\n",
      "310\n",
      "15.294995307922363\n",
      "320\n",
      "17.525383472442627\n",
      "330\n",
      "16.690564393997192\n",
      "340\n",
      "18.626447439193726\n",
      "350\n",
      "14.869285821914673\n",
      "360\n",
      "17.506174087524414\n",
      "370\n",
      "14.495913028717041\n",
      "380\n",
      "17.11882781982422\n",
      "390\n",
      "17.15841245651245\n",
      "400\n",
      "16.023648977279663\n",
      "410\n",
      "20.38727903366089\n",
      "420\n",
      "14.304219007492065\n",
      "430\n",
      "13.831573486328125\n",
      "440\n",
      "15.957952976226807\n",
      "450\n",
      "15.606539487838745\n",
      "460\n",
      "13.315152406692505\n",
      "470\n",
      "20.470433712005615\n",
      "480\n",
      "20.050451040267944\n",
      "490\n",
      "19.108659982681274\n",
      "500\n",
      "12.198169708251953\n",
      "510\n",
      "12.548205137252808\n",
      "520\n",
      "15.542815923690796\n",
      "530\n",
      "12.004806756973267\n",
      "540\n",
      "12.833245515823364\n",
      "550\n",
      "13.654059648513794\n",
      "560\n",
      "14.273037672042847\n",
      "570\n",
      "13.977152585983276\n",
      "580\n",
      "14.722201824188232\n",
      "590\n",
      "15.46530818939209\n",
      "600\n",
      "14.452305555343628\n",
      "610\n",
      "11.347846984863281\n",
      "620\n",
      "14.42941665649414\n",
      "630\n",
      "11.195287704467773\n",
      "640\n",
      "15.643964290618896\n",
      "650\n",
      "18.266090631484985\n",
      "660\n",
      "20.327900648117065\n",
      "670\n",
      "15.724217891693115\n",
      "680\n",
      "14.977348566055298\n",
      "690\n",
      "16.080604791641235\n",
      "700\n",
      "20.34078860282898\n",
      "710\n",
      "35.41726279258728\n",
      "720\n",
      "26.727609872817993\n",
      "730\n",
      "19.608150005340576\n",
      "740\n",
      "31.513176918029785\n",
      "750\n",
      "46.32020044326782\n",
      "760\n",
      "40.88411498069763\n",
      "770\n",
      "33.72273135185242\n",
      "780\n",
      "26.724329233169556\n",
      "790\n",
      "33.77045226097107\n",
      "800\n",
      "29.895952463150024\n",
      "810\n",
      "42.198328733444214\n",
      "820\n",
      "35.88564968109131\n",
      "830\n",
      "29.380178689956665\n",
      "840\n",
      "32.534950971603394\n",
      "850\n",
      "38.26226568222046\n",
      "860\n",
      "27.311542510986328\n",
      "870\n",
      "30.340099334716797\n",
      "880\n",
      "36.05140471458435\n",
      "890\n",
      "38.88874316215515\n",
      "900\n",
      "28.424417734146118\n",
      "910\n",
      "26.478292226791382\n",
      "920\n",
      "25.150634288787842\n",
      "930\n",
      "25.78243398666382\n",
      "940\n",
      "30.720595598220825\n",
      "950\n",
      "28.7259361743927\n",
      "960\n",
      "29.68704843521118\n",
      "970\n",
      "20.79627823829651\n",
      "980\n",
      "30.851613998413086\n",
      "990\n",
      "35.88100528717041\n",
      "1000\n",
      "28.93167209625244\n",
      "1010\n",
      "25.69800114631653\n",
      "1020\n",
      "32.08495545387268\n",
      "1030\n",
      "29.737512588500977\n",
      "1040\n",
      "31.777249097824097\n",
      "1050\n",
      "35.70735692977905\n",
      "1060\n",
      "27.348703145980835\n",
      "1070\n",
      "26.500134706497192\n",
      "1080\n",
      "23.574620962142944\n",
      "1090\n",
      "36.460811138153076\n",
      "1100\n",
      "27.230780601501465\n",
      "1110\n",
      "39.326045513153076\n",
      "1120\n",
      "36.31777381896973\n",
      "1130\n",
      "35.66435170173645\n",
      "1140\n",
      "39.37253165245056\n",
      "1150\n",
      "34.43237614631653\n",
      "1160\n",
      "37.92762279510498\n",
      "1170\n",
      "34.00446629524231\n",
      "1180\n",
      "35.83063364028931\n",
      "1190\n",
      "55.096763610839844\n",
      "1200\n",
      "30.14405632019043\n",
      "1210\n",
      "30.26137924194336\n",
      "1220\n",
      "20.789907455444336\n",
      "1230\n",
      "19.86720085144043\n",
      "1240\n",
      "26.666303157806396\n",
      "1250\n",
      "23.79206871986389\n",
      "1260\n",
      "23.30519127845764\n",
      "1270\n",
      "27.628130435943604\n",
      "1280\n",
      "18.64722752571106\n",
      "1290\n",
      "25.839927434921265\n",
      "1300\n",
      "25.94924259185791\n",
      "1310\n",
      "27.2344810962677\n",
      "1320\n",
      "23.014298677444458\n",
      "1330\n",
      "26.251957416534424\n",
      "1340\n",
      "27.78957772254944\n",
      "1350\n",
      "29.579397678375244\n",
      "1360\n",
      "40.506054639816284\n",
      "1370\n",
      "35.278250217437744\n",
      "1380\n",
      "32.790377140045166\n",
      "1390\n",
      "32.071789503097534\n",
      "1400\n",
      "55.55176901817322\n",
      "1410\n",
      "75.62622046470642\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "prev_time = time.time()\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        cur_time = time.time()\n",
    "        print(cur_time-prev_time)\n",
    "        prev_time = cur_time\n",
    "    item = generate_answer3(prompt, df_exploded.iloc[i].model_list, df_exploded.iloc[i].pred, df_exploded.iloc[i].question)\n",
    "    result.append(item)\n",
    "    joblib.dump(item, \"/data/dataset/kefu/gpt4_template_sql/{}.jsonl\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3644c859-eb87-45cf-9cb3-151d52ec403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    item = joblib.load(\"/data/dataset/kefu/gpt4_template_sql/{}.jsonl\".format(i))\n",
    "    result.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f172f0c6-0e0d-4dba-8363-b37d791e4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"sql\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "738560b4-3a69-48fd-b270-23c629539876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_field(field):\n",
    "    return field.strip().strip('`').strip('\"').strip(\"'\")\n",
    "\n",
    "def extract_fields_and_models(sql_query):\n",
    "    # 提取所有 SELECT 和 FROM 之间的部分\n",
    "    select_from_pattern = r\"SELECT\\s+(.*?)\\s+FROM\"\n",
    "    select_from_matches = re.findall(select_from_pattern, sql_query, re.DOTALL)\n",
    "    select_from_fields = [clean_field(field) for match in select_from_matches for field in match.split(',')]\n",
    "\n",
    "    # 提取所有 WHERE 型号 IN 或 WHERE 型号 = 后面的部分\n",
    "    where_in_or_equal_pattern = r\"WHERE\\s+`?型号`?\\s*=\\s*['\\\"]([^'\\\"]*)['\\\"]|WHERE\\s+`?型号`?\\s*IN\\s*\\(([^)]*)\\)\"\n",
    "    where_in_or_equal_matches = re.findall(where_in_or_equal_pattern, sql_query, re.DOTALL)\n",
    "    \n",
    "    where_fields = []\n",
    "    for match in where_in_or_equal_matches:\n",
    "        if match[0]:\n",
    "            where_fields.append(clean_field(match[0]))\n",
    "        elif match[1]:\n",
    "            where_fields.extend([clean_field(model) for model in match[1].split(',')])\n",
    "\n",
    "    return select_from_fields, where_fields\n",
    "\n",
    "def process_union_queries(sql_query):\n",
    "    # 分割 UNION ALL 语句\n",
    "    union_queries = sql_query.split('UNION ALL')\n",
    "    \n",
    "    all_fields = []\n",
    "    all_models = []\n",
    "    \n",
    "    for query in union_queries:\n",
    "        fields, models = extract_fields_and_models(query)\n",
    "        all_fields.extend(fields)\n",
    "        all_models.extend(models)\n",
    "    \n",
    "    return all_fields, all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c82de390-c9e7-44e8-ba42-b57567e25eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded[\"sql_extracted\"] = df_exploded[\"sql\"].apply(lambda x: process_union_queries(x)[0])\n",
    "df_exploded[\"sql_metric\"] = df_exploded[[\"sql_extracted\", \"gen\"]].apply(\n",
    "    lambda x: metric(x[\"sql_extracted\"], x[\"gen\"][\"prompt\"]), axis=1)\n",
    "df_exploded[\"sql_precision\"] = df_exploded[\"sql_metric\"].apply(lambda x: x[0])\n",
    "df_exploded[\"sql_recall\"] = df_exploded[\"sql_metric\"].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "31148605-4578-4bef-8c70-2434a25caac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207221350078493"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[df_exploded[\"recall\"]==1][\"sql_recall\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a821f62b-c7c5-4a90-ae3a-81004f76357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql_recall\n",
       "1.000000    0.879906\n",
       "0.500000    0.077708\n",
       "0.000000    0.040031\n",
       "0.833333    0.002355\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[df_exploded[\"recall\"]==1][\"sql_recall\"].value_counts(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0355bd71-5baa-4418-a98c-3b166fcfad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql_precision\n",
       "1.000000    0.807851\n",
       "0.666667    0.067149\n",
       "0.500000    0.059917\n",
       "0.333333    0.054752\n",
       "0.400000    0.006198\n",
       "0.750000    0.002066\n",
       "0.285714    0.001033\n",
       "0.857143    0.001033\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[(df_exploded[\"recall\"]==1)&(df_exploded[\"sql_recall\"]==1)][\"sql_precision\"].value_counts(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "159a143f-6874-4db9-99e6-a9a17823604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'g20标准版的集尘频率是什么？',\n",
       " 'prompt': [{'primary_value': 'g20标准版', 'key': '集尘频率', '集尘频率': nan}],\n",
       " 'replace': {'[问询词0]': 'g20标准版', '[关键词0]': '集尘频率'}}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[(df_exploded[\"recall\"]==1)&(df_exploded[\"sql_recall\"]==1)&(df_exploded[\"sql_precision\"]==0.5)].iloc[10].gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e0a2e103-aa72-40dd-96da-2ae5b7b576d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '针对G20标准版来说，你了解其多频集尘功能吗？',\n",
       " 'entities': [{'entity_group': 'name',\n",
       "   'score': 0.9779524,\n",
       "   'word': '多 频 集 尘 功 能',\n",
       "   'start': 15,\n",
       "   'end': 21}]}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[(df_exploded[\"recall\"]==1)&(df_exploded[\"sql_recall\"]==1)&(df_exploded[\"sql_precision\"]==0.5)].iloc[10].ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c2950b41-29ee-4e6e-90c7-470b39a88e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['集尘频率', '集尘模式']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[(df_exploded[\"recall\"]==1)&(df_exploded[\"sql_recall\"]==1)&(df_exploded[\"sql_precision\"]==0.5)].iloc[10].sql_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "121b086f-2b51-4ec9-b2ea-b4189b7c86c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['集尘频率', '集尘模式', '是否支持自动集尘']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exploded[(df_exploded[\"recall\"]==1)&(df_exploded[\"sql_recall\"]==1)&(df_exploded[\"sql_precision\"]==0.5)].iloc[10].pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0db2111b-4062-42da-8ea4-8717bd5ab52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义反查字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "9e8a7b1c6ff118d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:04.307794425Z",
     "start_time": "2024-04-30T06:57:04.285086613Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954\n"
     ]
    }
   ],
   "source": [
    "all_dict = {}\n",
    "for i in range(df_exploded.shape[0]):\n",
    "    replace = df_exploded['augment'].iloc[i][\"replace\"]\n",
    "    primaries = [j['primary_value'] for j in df_exploded['gen'].iloc[i]['prompt']]\n",
    "    for key in replace:\n",
    "        if replace[key] in primaries:\n",
    "            print(i)\n",
    "            continue\n",
    "        if key in all_dict:\n",
    "            all_dict[key].add(replace[key])\n",
    "        else:\n",
    "            all_dict[key] = set([replace[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "28411e60a0d55779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:22.736396566Z",
     "start_time": "2024-04-30T06:57:22.682318705Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for key in all_dict:\n",
    "    all_dict[key] = list(all_dict[key])\n",
    "    if key not in all_dict[key]:\n",
    "        all_dict[key] = all_dict[key] + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "621dca5bf5452d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:23.519490303Z",
     "start_time": "2024-04-30T06:57:23.504082230Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cherry_pick(key, value):\n",
    "    if key not in all_dict:\n",
    "        print(key, 'oops')\n",
    "        return\n",
    "    u_list = all_dict[key]\n",
    "    for i in range(len(u_list)-1, -1, -1):\n",
    "        if u_list[i] == value:\n",
    "            u_list.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "a366952fa0f2c98e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:24.017445678Z",
     "start_time": "2024-04-30T06:57:23.999021453Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cherry_pick_list = []\n",
    "alias_inv_dict = {}\n",
    "for k, v in all_dict.items():\n",
    "    for u in v:\n",
    "        if u in alias_inv_dict:\n",
    "            cherry_pick_list.append((k, u, alias_inv_dict[u]))\n",
    "        alias_inv_dict[u] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "e4abe555ceb3b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:24.480460517Z",
     "start_time": "2024-04-30T06:57:24.459495761Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(cherry_pick_list)):\n",
    "    cherry_pick(cherry_pick_list[i][0], cherry_pick_list[i][1])\n",
    "    cherry_pick(cherry_pick_list[i][2], cherry_pick_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "450fe4b9f905d245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:25.452094423Z",
     "start_time": "2024-04-30T06:57:25.437066302Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cherry_pick_list = []\n",
    "alias_inv_dict = {}\n",
    "for k, v in all_dict.items():\n",
    "    for u in v:\n",
    "        if u in alias_inv_dict:\n",
    "            cherry_pick_list.append((k, u, alias_inv_dict[u]))\n",
    "        alias_inv_dict[u] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "ec934367d8067bbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:25.895086217Z",
     "start_time": "2024-04-30T06:57:25.887697641Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cherry_pick_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "7ac24039d66a14ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:57:26.882459394Z",
     "start_time": "2024-04-30T06:57:26.845959699Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alias_inv_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
