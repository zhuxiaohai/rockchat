{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:42.548847243Z",
     "start_time": "2024-03-25T06:02:38.184841377Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pandasql import sqldf\n",
    "import re\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import joblib\n",
    "import json \n",
    "import jieba \n",
    "import copy\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import matplotlib.pyplot as plt \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import FlagReranker\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3c94a74b02eeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:46.162727178Z",
     "start_time": "2024-03-25T06:02:46.099330239Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# pandasql查询函数需要的环境\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a367387e-f525-4599-912c-c68be7331cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:46.614837917Z",
     "start_time": "2024-03-25T06:02:46.594416571Z"
    }
   },
   "outputs": [],
   "source": [
    "# 原始数据处理\n",
    "def format_model(x):\n",
    "    model_list = x.split(',')\n",
    "    model_list = [i.strip().lower() for i in model_list]\n",
    "    new_list = [model_list[0]]\n",
    "    i = 1\n",
    "    while i < len(model_list):\n",
    "        if (i != len(model_list) - 1) and (model_list[i-1] == model_list[i]):\n",
    "            new_list.append(model_list[i]+model_list[i+1])\n",
    "            if i < len(model_list) - 1:\n",
    "                i += 2\n",
    "            else:\n",
    "                break\n",
    "        elif (i != len(model_list) - 1) and (model_list[i-1] != model_list[i]):\n",
    "            new_list.append(model_list[i])\n",
    "            i += 1\n",
    "        elif (model_list[i] == \"上下水\") or (model_list[i] == \"air\"):\n",
    "            for j in range(len(new_list)):\n",
    "                if model_list[i-1] == new_list[j]:\n",
    "                    new_list.pop(j)\n",
    "                    break\n",
    "            new_list.append(model_list[i-1]+model_list[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            new_list.append(model_list[i])\n",
    "            break\n",
    "    return new_list\n",
    "\n",
    "def format_all_models(x, dim_df):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"全型号\") >= 0:\n",
    "            end_idx = i.find(\"全型号\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[dim_df['cat_name'] == name].model.tolist() if j not in x]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "def format_series(x, dim_df):\n",
    "    def contains_chinese(s):\n",
    "        return re.search('[\\u4e00-\\u9fff]', s) is not None\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"系列\") >= 0:\n",
    "            end_idx = i.find(\"系列\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[(dim_df.model.str.find(name)>=0) & (\n",
    "                dim_df.model.apply(lambda x: not contains_chinese(x)))].model.tolist() if j not in x]\n",
    "            new_list += [i]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ec7f8a-e9c3-48b5-9dbf-b26fb5045320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:47.275074278Z",
     "start_time": "2024-03-25T06:02:47.228000273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 拼接openai embedding\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16717201-59cd-412f-9e3d-f2b2a5592356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:47.759486977Z",
     "start_time": "2024-03-25T06:02:47.702318041Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集处理及计算与正确qa的相似度\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def search_docs(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = generate_embeddings(\n",
    "        user_query,\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_002.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[[\"qa_id\", \"question\", \"answer\", \"similarities\"]]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def concat(x):\n",
    "    return \",\".join(x.astype(str).tolist())\n",
    "\n",
    "def format_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return x\n",
    "    else:\n",
    "        return \",\".join(x.split(\"\\n\"))\n",
    "\n",
    "def count_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x.split(\",\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cce4679-0c44-45a8-89dd-808f7a33977d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:48.269259251Z",
     "start_time": "2024-03-25T06:02:48.231943506Z"
    }
   },
   "outputs": [],
   "source": [
    "# 向量召回\n",
    "def search_docs_bge(df, user_query, top_n=4, to_print=True, add_instruction=False, content_col=\"question\"):\n",
    "    df = df.copy()\n",
    "    if add_instruction:\n",
    "        instruction = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "        user_query = instruction+user_query\n",
    "    embedding = model.encode(user_query, normalize_embeddings=True).tolist()\n",
    "    df = df.drop_duplicates([content_col])\n",
    "    df[\"similarities\"] = df.bge_large.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def find_non_chinese_substrings(s):\n",
    "    # 正则表达式解释：\n",
    "    # [^\\u4e00-\\u9fff\\W]+ 匹配非中文字符和非ASCII标点的连续字符\n",
    "    # 但这样会排除空格，所以我们需要允许空格存在\n",
    "    # 我们使用(?:[^\\u4e00-\\u9fff\\W]| )+ 来实现这一点，(?:) 是非捕获组，用于匹配模式但不作为捕获结果返回\n",
    "    # [^\\u4e00-\\u9fff\\W] 匹配非中文且非标点的字符，| 表示或，空格 ' ' 被显式允许\n",
    "    pattern = r'(?:[^\\u4e00-\\u9fff\\W]| )+'\n",
    "    \n",
    "    # 使用findall方法查找所有匹配项\n",
    "    matches = re.findall(pattern, s)\n",
    "    \n",
    "    # 过滤掉只包含空格的字符串\n",
    "    matches = [match for match in matches if not match.isspace()]\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.replace(\" \", \"\").lower()\n",
    "    return s\n",
    "\n",
    "def find_model(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    x = find_non_chinese_substrings(x)\n",
    "    result = [clean_string(s) for s in x]\n",
    "    return [model for model in all_model_list if model in result]\n",
    "\n",
    "def find_cat(x, all_cat_list):\n",
    "    return [name for name in all_cat_list if name in x]   \n",
    "\n",
    "def filter_model(x, model_list):\n",
    "    x = x.split(\",\")\n",
    "    for model in model_list:\n",
    "        if model in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_error_with_reason(a):\n",
    "    # 第一次匹配“错误xxx”\n",
    "    pattern1 = r\"错误\\s*\\d+\"\n",
    "    matches1 = re.findall(pattern1, a)\n",
    "    \n",
    "    # 第二次匹配“错误原因xxx”\n",
    "    pattern2 = r\"错误原因\\s*\\d+\"\n",
    "    matches2 = re.findall(pattern2, a)\n",
    "\n",
    "    # 合并两次匹配的结果\n",
    "    matches = matches1 + matches2\n",
    "    \n",
    "    return [name.replace(\" \", \"\").replace(\"原因\", \"\") for name in matches]\n",
    "\n",
    "def filter_reason(x, query_reason_list):\n",
    "    reason_list = find_error_with_reason(x)\n",
    "    for name in query_reason_list:\n",
    "        if name in reason_list:\n",
    "            return True \n",
    "    return False\n",
    "\n",
    "def transform_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        cleaned_name = clean_string(name)\n",
    "        for model in all_model_list:\n",
    "            if cleaned_name == model:\n",
    "                x = x.replace(name, model)\n",
    "                break\n",
    "    return x \n",
    "\n",
    "def remove_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        if clean_string(name) in all_model_list:\n",
    "            x = x.replace(name, \"\")\n",
    "    return x \n",
    "\n",
    "class BM25_Model(object):\n",
    "    def __init__(self, documents_list, k1=2, k2=1, b=0.5):\n",
    "        self.documents_list = documents_list\n",
    "        self.documents_number = len(documents_list)\n",
    "        self.avg_documents_len = sum([len(document) for document in documents_list]) / self.documents_number\n",
    "        self.f = []\n",
    "        self.idf = {}\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.b = b\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        df = {}\n",
    "        for document in self.documents_list:\n",
    "            temp = {}\n",
    "            for word in document:\n",
    "                temp[word] = temp.get(word, 0) + 1\n",
    "            self.f.append(temp)\n",
    "            for key in temp.keys():\n",
    "                df[key] = df.get(key, 0) + 1\n",
    "        for key, value in df.items():\n",
    "            self.idf[key] = np.log((self.documents_number - value + 0.5) / (value + 0.5))\n",
    "\n",
    "    def get_score(self, index, query):\n",
    "        score = 0.0\n",
    "        document_len = len(self.f[index])\n",
    "        qf = Counter(query)\n",
    "        for q in query:\n",
    "            if q not in self.f[index]:\n",
    "                continue\n",
    "            score += self.idf[q] * (self.f[index][q] * (self.k1 + 1) / (\n",
    "                        self.f[index][q] + self.k1 * (1 - self.b + self.b * document_len / self.avg_documents_len))) * (\n",
    "                                 qf[q] * (self.k2 + 1) / (qf[q] + self.k2))\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_documents_score(self, query, indices):\n",
    "        score_list = []\n",
    "        for i in indices:\n",
    "            score_list.append(self.get_score(i, query))\n",
    "        return score_list\n",
    "\n",
    "\n",
    "class WordCut:\n",
    "    def __init__(self, all_model_list=None):\n",
    "        with open('/data/dataset/kefu/hit_stopwords.txt', encoding='utf-8') as f: # 可根据需要打开停用词库，然后加上不想显示的词语\n",
    "            con = f.readlines()\n",
    "            stop_words = set()\n",
    "            for i in con:\n",
    "                i = i.replace(\"\\n\", \"\")   # 去掉读取每一行数据的\\n\n",
    "                stop_words.add(i)\n",
    "        self.stop_words = stop_words\n",
    "        self.all_model_list = all_model_list\n",
    "        \n",
    "    def cut(self, mytext):\n",
    "        # jieba.load_userdict('自定义词典.txt')  # 这里你可以添加jieba库识别不了的网络新词，避免将一些新词拆开\n",
    "        # jieba.initialize()  # 初始化jieba\n",
    "        # 文本预处理 ：去除一些无用的字符只提取出中文出来\n",
    "        # new_data = re.findall('[\\u4e00-\\u9fa5]+', mytext, re.S)\n",
    "        # new_data = \" \".join(new_data)\n",
    "        # 匹配中英文标点符号，以及全角和半角符号\n",
    "        pattern = r'[\\u3000-\\u303f\\uff01-\\uff0f\\uff1a-\\uff20\\uff3b-\\uff40\\uff5b-\\uff65\\u2018\\u2019\\u201c\\u201d\\u2026\\u00a0\\u2022\\u2013\\u2014\\u2010\\u2027\\uFE10-\\uFE1F\\u3001-\\u301E]|[\\.,!¡?¿\\-—_(){}[\\]\\'\\\";:/]'\n",
    "        # 使用 re.sub 替换掉符合模式的字符为空字符\n",
    "        new_data = re.sub(pattern, '', mytext)\n",
    "        new_data = transform_model_name(new_data, self.all_model_list)\n",
    "        # 文本分词\n",
    "        seg_list_exact = jieba.lcut(new_data)\n",
    "        result_list = []\n",
    "        # 去除停用词并且去除单字\n",
    "        for word in seg_list_exact:\n",
    "            if word not in self.stop_words and len(word) > 1:\n",
    "                result_list.append(word) \n",
    "        return result_list\n",
    "\n",
    "def search_docs_bm25(df, indices, user_query, top_n=4):\n",
    "    # document_list = [wc.cut(doc) for doc in df.question]\n",
    "    # bm25_model = BM25_Model(document_list)\n",
    "    embedding = wc.cut(user_query)\n",
    "    df[\"similarities\"] = bm25_model.get_documents_score(embedding, indices)\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82256265-3637-4f14-8fad-ff436810319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 综合分析\n",
    "def ranking_metric(x):\n",
    "    if (x.find(\"error\")>=0) and (x.find(\"model\")>=0):\n",
    "        return 1 \n",
    "    elif (x.find(\"error\")>=0) and (x.find(\"cat\")>=0):\n",
    "        return 2 \n",
    "    elif (x.find(\"error\")>=0):\n",
    "        return 3 \n",
    "    elif (x.find(\"model\")>=0):\n",
    "        return 4\n",
    "    elif (x.find(\"cat\")>=0):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def mine_hard_negative(x, similarities, reason, result, positive):\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = pd.DataFrame(x[[similarities, reason, result]].to_dict())\n",
    "    df = df[~df[result].isin(positives)]\n",
    "    df[\"ranking\"] = df[reason].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", similarities], ascending=[True, False])\n",
    "    df = df.drop_duplicates(result)\n",
    "    df = df.iloc[:10]\n",
    "    return pd.Series({col+\"_hard\": df[col].values.tolist() for col in [similarities, reason, result]})\n",
    "\n",
    "def format_result(x, similarities, reason, result, contents):\n",
    "    assert len(x[contents]) == len(x[result])\n",
    "    num_result = len(x[result])\n",
    "    new_set = dict()\n",
    "    for j in range(num_result):\n",
    "        content = x[contents][j]\n",
    "        result_name = x[result][j]\n",
    "        sim = x[similarities][j]\n",
    "        reason_code = x[reason][j]\n",
    "        if content in new_set:\n",
    "            if (ranking_metric(reason_code) <= ranking_metric(new_set[content][\"reason\"])\n",
    "               ) & (sim > new_set[content][\"similarities\"]):\n",
    "                new_set.update({content: {\"similarities\": sim, \"reason\": reason_code, \"result\": result_name}})\n",
    "        else:\n",
    "            new_set.update({content: {\"similarities\": sim, \"reason\": reason_code, \"result\": result_name}})\n",
    "    df = pd.DataFrame(new_set).T.reset_index().rename(columns={\"index\": \"content\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'similarities', 'content']].to_dict(orient='records')\n",
    "\n",
    "def merge_recall(x, recall_list, weights):\n",
    "    pool = {}\n",
    "    for i in range(len(weights)):\n",
    "        weight = weights[i] \n",
    "        recall_name = recall_list[i]\n",
    "        num_results = len(x[recall_name])\n",
    "        for j in range(num_results):\n",
    "            result_item = x[recall_name][j]\n",
    "            result = result_item[\"result\"]\n",
    "            if result in pool:\n",
    "                if ranking_metric(result_item['reason']) < ranking_metric(pool[result]['reason']):\n",
    "                    reason = result_item['reason']\n",
    "                    pool[result]['reason'] = reason\n",
    "                pool[result]['similarities'] += weight * result_item['similarities'] / sum(weights)\n",
    "                pool[result]['full_reason'] = pool[result]['full_reason']+\",\"+result_item['reason']+\"_\"+recall_name\n",
    "            else:\n",
    "                pool[result]= {\n",
    "                    \"reason\": result_item['reason'],\n",
    "                    \"similarities\": weight * result_item['similarities'] / sum(weights),\n",
    "                    \"full_reason\": result_item['reason']+\"_\"+recall_name\n",
    "                              }\n",
    "    df = pd.DataFrame(pool).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'full_reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def mine_hard_negative2(x, recall, top_n, positive, output_cols):\n",
    "    df = pd.DataFrame(x[recall])\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = df[~df[\"result\"].isin(positives)]\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    df = df.iloc[:top_n]\n",
    "    return df[output_cols].to_dict(orient='records')  \n",
    "\n",
    "def split_recall(x, output_cols, new_cols):\n",
    "    df = pd.DataFrame(x)\n",
    "    return pd.Series({new_col: df[col].values.tolist() \n",
    "                      for col, new_col in zip(output_cols, new_cols)})\n",
    "\n",
    "def find_score_limit(x):\n",
    "    min_all = float(\"inf\")\n",
    "    max_all = float(\"-inf\")\n",
    "    for i in range(len(x)):\n",
    "        min_i = min(x[i])\n",
    "        max_i = max(x[i])\n",
    "        min_all = min(min_all, min_i)\n",
    "        max_all = max(max_all, max_i)\n",
    "    return min_all, max_all\n",
    "\n",
    "def convert_limit(x, min_all, max_all):\n",
    "    return [(i-min_all)/(max_all-min_all) for i in x]\n",
    "\n",
    "def convert_df_to_jsonl(df, filename, query=\"question_cleaned\", pos_col=\"question_positive\", neg_col=\"question_bge_hard\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            # Constructing the dictionary for each row\n",
    "            data = {\n",
    "                \"query\": row[query],\n",
    "                \"pos\": row[pos_col],\n",
    "                \"neg\": row[neg_col]\n",
    "            }\n",
    "            # Writing the JSON string followed by a newline character to make it JSONL\n",
    "            file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1a11e3-d608-41ef-a2ea-d33f675bc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序\n",
    "def mrr_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    mrr_score = 0\n",
    "    for rank, index in enumerate(pred_ranking[:k]):\n",
    "        if is_relevant[index]:\n",
    "            mrr_score = 1 / (rank + 1)\n",
    "            break\n",
    "\n",
    "    return mrr_score\n",
    "\n",
    "def recall_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    recall_score = 0\n",
    "    for index in pred_ranking[:k]:\n",
    "        if is_relevant[index]:\n",
    "            recall_score = 1\n",
    "            break\n",
    "\n",
    "    return recall_score\n",
    "\n",
    "def ap_score(is_relevant, pred_scores):\n",
    "    \"\"\"\n",
    "    Computes AP score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_scores (`List[float]` of length `num_pos+num_neg`): Predicted similarity scores\n",
    "\n",
    "    Returns:\n",
    "        ap_score (`float`): AP score\n",
    "    \"\"\"\n",
    "    # preds = np.array(is_relevant)[pred_scores_argsort]\n",
    "    # precision_at_k = np.mean(preds[:k])\n",
    "    # ap = np.mean([np.mean(preds[: k + 1]) for k in range(len(preds)) if preds[k]])\n",
    "    ap = average_precision_score(is_relevant, pred_scores)\n",
    "    return ap\n",
    "\n",
    "def compute_recall_score(df, model, query, recall):\n",
    "    pairs = []\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        for p in sample[recall]:\n",
    "            pairs.append([sample[query], p])\n",
    "    all_scores = model.compute_score(pairs)\n",
    "    result = []\n",
    "    start_inx = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        pred_scores = all_scores[start_inx:start_inx + len(sample[recall])]\n",
    "        result.append(pred_scores)\n",
    "        start_inx += len(sample[recall])\n",
    "    return result\n",
    "\n",
    "def compute_metrics_batched_from_crossencoder(df, score, relevant, \n",
    "                                              mrr_at_k=10, recall_at_list=[1,2], metrics=[\"map\", \"mrr\", \"recall\"]):\n",
    "    all_mrr_scores = []\n",
    "    all_ap_scores = []\n",
    "    all_recall_scores = [[] for _ in range(len(recall_at_list))]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        is_relevant = sample[relevant]\n",
    "        pred_scores = np.array(sample[score])\n",
    "\n",
    "        pred_scores_argsort = np.argsort(-pred_scores)  # Sort in decreasing order\n",
    "        if \"mrr\" in metrics:\n",
    "            mrr = mrr_at_k_score(is_relevant, pred_scores_argsort, mrr_at_k)\n",
    "            all_mrr_scores.append(mrr)\n",
    "        if \"map\" in metrics:\n",
    "            ap = ap_score(is_relevant, pred_scores)\n",
    "            all_ap_scores.append(ap)\n",
    "        if \"recall\" in metrics:\n",
    "            for recall_index, recall_at in enumerate(recall_at_list):\n",
    "                recall_score = recall_at_k_score(is_relevant, pred_scores_argsort, recall_at)\n",
    "                all_recall_scores[recall_index].append(recall_score)\n",
    "\n",
    "    result = {}\n",
    "    if \"map\" in metrics:\n",
    "        mean_ap = np.mean(all_ap_scores)\n",
    "        result[\"map\"] = mean_ap\n",
    "    if \"mrr\" in metrics:\n",
    "        mean_mrr = np.mean(all_mrr_scores)\n",
    "        result[f\"mrr@{mrr_at_k}\"] = mean_mrr\n",
    "    if \"recall\" in metrics:\n",
    "        for recall_index, recall_at in enumerate(recall_at_list):\n",
    "            result[f\"recall@{recall_at}\"] = np.mean(all_recall_scores[recall_index])\n",
    "    return result\n",
    "\n",
    "def find_T_loc(x, relevant, score):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    for rank, index in enumerate(pred_scores_argsort):\n",
    "        if is_relevant[index]:\n",
    "            return rank\n",
    "    return np.nan\n",
    "\n",
    "def get_reranking(x, relevant, score, recall):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    recall_list = copy.deepcopy(x[recall])\n",
    "    reranking = []\n",
    "    for i in pred_scores_argsort:\n",
    "        temp = recall_list[i]\n",
    "        temp.update({\"ranking_score\": pred_scores[i]})\n",
    "        reranking.append(temp)\n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d514496-9b26-4fa1-bba4-35bb6ff63345",
   "metadata": {},
   "source": [
    "# 向量召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7780da1-7e32-4aca-ae67-364177cd94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "664df7cf0601055b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:38.687361618Z",
     "start_time": "2024-03-21T11:33:38.519915254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "oot = pd.read_csv(\"/data/dataset/kefu/oot20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7641a473-b5b1-4837-b39f-bed036db6b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:40.730909535Z",
     "start_time": "2024-03-21T11:33:39.108590586Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/data/dataset/kefu/test20240315.csv\")\n",
    "# df1 = pd.read_csv(\"/data/dataset/kefu/database_before_online_with_emb.csv\")\n",
    "# df2 = pd.read_csv(\"/data/dataset/kefu/database_with_emb20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3d39a5-a608-4590-ba33-f3ad9df6f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/data/dataset/kefu/database_before_online.csv\")\n",
    "df2 = pd.read_csv(\"/data/dataset/kefu/database20240506.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66f4874-b4e8-4ecd-8f88-a328f422ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_vedio = df1[df1.answer.apply(lambda x: True if x.lower().strip()[:10].find(\"http\")>=0 else False)]\n",
    "df1_fig = df1[df1.question.apply(lambda x: True if x.lower().strip().find(\"开箱图\")>=0 else False)]\n",
    "df2_vedio = df2[df2.answer.apply(lambda x: True if x.lower().strip()[:10].find(\"http\")>=0 else False)]\n",
    "df2_fig = df2[df2.question.apply(lambda x: True if x.lower().strip().find(\"开箱图\")>=0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55539138-98f9-4856-801b-1d8d585f7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.answer.apply(lambda x: True if x.lower().strip()[:10].find(\"http\")<0 else False)]\n",
    "df1 = df1[df1.question.apply(lambda x: True if x.lower().strip().find(\"开箱图\")<0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec11b98-9d98-4a2d-b496-49c290567d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2.answer.apply(lambda x: True if x.lower().strip()[:10].find(\"http\")<0 else False)]\n",
    "df2 = df2[df2.question.apply(lambda x: True if x.lower().strip().find(\"开箱图\")<0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc694ef6-a007-4cd7-8cca-a593a408b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"error_list\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "423592a5-6b15-4067-be0a-d02e411a870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1448, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "774c8ae0-30ec-49a5-8865-2fdadf005dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2883, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7410d7f3-463b-49e4-96ef-ede656e656d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881f88af-d7b8-4c48-91c3-1a8e682bfc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"question\", \"model\", \"update_time\"],\n",
    "                       ).drop_duplicates(subset=[\"question\", \"model\"], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b042ceb1-2593-4b62-bade-6b5f11cfa40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3276, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec85ec5-d2fd-4b5d-a728-f7c39ca7821b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:52:22.903675555Z",
     "start_time": "2024-03-22T01:52:15.663951567Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('/data/dataset/huggingface/hub/bge-large-zh-v1.5')\n",
    "# model = SentenceTransformer('/workspace/data/private/zhuxiaohai/models/bge_finetune_emb')\n",
    "# q_embeddings = model.encode(df1.question.tolist(), normalize_embeddings=True, batch_size=32)\n",
    "# df1['bge_large'] = q_embeddings.tolist()\n",
    "# q_embeddings = model.encode(df2.question.tolist(), normalize_embeddings=True, batch_size=32)\n",
    "# df2['bge_large'] = q_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b109ba5-c061-4615-a5b1-738d8e856844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签+向量3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c606973e-485d-4534-92dd-fdc8c3065e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embeddings = model.encode(df.answer.tolist(), normalize_embeddings=True, batch_size=32)\n",
    "df['bge_large'] = q_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b25f2649-ffd0-4ab5-ac72-0c49ae5b84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.copy()\n",
    "df1 = df.copy()\n",
    "test[\"gt_qa_id\"] = test['qa_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "363eb8b3-d728-4885-ae73-2b9be17be7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:34:40.239087863Z",
     "start_time": "2024-03-21T11:33:58.341292040Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n"
     ]
    }
   ],
   "source": [
    "def sub_worker(result, score, reason, content, top_n, content_col):\n",
    "    if (filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)).sum() > 0:\n",
    "        aug_mask = filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        content += [j[content_col] for j in res]\n",
    "        \n",
    "        if len(set(content)) < top_n:\n",
    "            aug_mask = filter_mask & (~(reason_indicator.str.find(\"errorcode\")>=0))\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            content += [j[content_col] for j in res]\n",
    "    else:\n",
    "        aug_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            content += [j[content_col] for j in res]\n",
    "\n",
    "        if len(set(content)) < top_n:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            content += [j[content_col] for j in res]\n",
    "\n",
    "    if len(set(content)) < top_n:\n",
    "        aug_mask = (~filter_mask) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            content += [j[content_col] for j in res]\n",
    "    return result, score, reason, content\n",
    "    \n",
    "label = []\n",
    "result_list = []\n",
    "top_n = 20\n",
    "for i in range(test.shape[0]):\n",
    "    if i % 10 ==0:\n",
    "        print(i)\n",
    "    gt = test['gt_qa_id'].iloc[i].split(\",\")\n",
    "    question = test['question'].iloc[i]\n",
    "    model_list = find_model(question, all_model_list)\n",
    "    cat_list = find_cat(question, all_cat_list)   \n",
    "    cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "    reason_list = find_error_with_reason(question)\n",
    "    model_mask = (df1.model_list.apply(lambda x: filter_model(x, model_list)))\n",
    "    cat_mask = (df1.cat_name.apply(lambda x: filter_model(x, cat_list)))\n",
    "    reason_mask = (df1.question.apply(lambda x: filter_reason(x, reason_list)))\n",
    "    reason_indicator = pd.Series([\"none\"]*df1.shape[0], index=df1.index)\n",
    "    reason_indicator[model_mask] = reason_indicator[model_mask].apply(lambda x: x + \"|model\" if x != \"none\" else \"model\")\n",
    "    reason_indicator[cat_mask] = reason_indicator[cat_mask].apply(lambda x: x + \"|cat\" if x != \"none\" else \"cat\")\n",
    "    reason_indicator[reason_mask] = reason_indicator[reason_mask].apply(lambda x: x + \"|errorcode\" if x != \"none\" else \"errorcode\")\n",
    "    result = []\n",
    "    score = []\n",
    "    reason = []\n",
    "    content = []\n",
    "    content_col = \"answer\"\n",
    "    # question = remove_model_name(question, all_model_list)\n",
    "    filter_mask = (reason_indicator.str.find(\"model\")>=0)\n",
    "    if filter_mask.sum() > 0:\n",
    "        result, score, reason, content = sub_worker(result, score, reason, content, top_n, \"answer\")\n",
    "    else:\n",
    "        filter_mask = (reason_indicator.str.find(\"cat\")>=0)   \n",
    "        if filter_mask.sum() > 0:\n",
    "            result, score, reason, content = sub_worker(result, score, reason, content, top_n, \"answer\")\n",
    "    if len(result) == 0:\n",
    "        filter_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if filter_mask.sum() > 0:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "            content += [j[content_col] for j in res]\n",
    "            if len(set(content)) < top_n:\n",
    "                aug_mask = (~filter_mask)\n",
    "                filtered_df = df1[aug_mask].copy()\n",
    "                filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "                res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "                result += [j[\"qa_id\"] for j in res]\n",
    "                score += [round(j[\"similarities\"], 2) for j in res]\n",
    "                reason += [j[\"hit_reason\"] for j in res]  \n",
    "                content += [j[content_col] for j in res]\n",
    "        else:\n",
    "            filtered_df = df1.copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator.copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True, content_col=content_col)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            content += [j[content_col] for j in res]\n",
    "    \n",
    "    found = False\n",
    "    for j in result:\n",
    "        if j in gt:\n",
    "            found = True\n",
    "            break \n",
    "    if found:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    result_list.append({\"qa_id\": test['qa_id'].iloc[i], \n",
    "                        \"result\": result, \n",
    "                        \"similarities\": score, \n",
    "                        \"hit_reason\": reason, \n",
    "                        \"content\": content,\n",
    "                        \"label\": int(found)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "028a5086-4652-4cc2-8534-027713f2e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(result_list, \"/data/dataset/kefu/query_answer_sim.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a625440-165f-4661-aec3-16a0aaccce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = joblib.load(\"/data/dataset/kefu/query_answer_sim.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70db0ce0-3d55-483a-8f71-b6fa1c7acadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:34:40.282373600Z",
     "start_time": "2024-03-21T11:34:40.244442816Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_list)\n",
    "test_result = test.merge(result_df, how='left', left_on='qa_id', right_on='qa_id')\n",
    "test_result[\"sim_max\"] = test_result[\"similarities\"].apply(lambda x: max(x))\n",
    "test_result[\"sim_min\"] = test_result[\"similarities\"].apply(lambda x: min(x))\n",
    "test_result[\"result_num\"] = test_result.result.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65275a1f-1949-493d-8d78-eb46ee50024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_result = test_result.sort_values([\"question\", \"model\", \"update_time\"],\n",
    "#                        ).drop_duplicates(subset=[\"question\", \"model\"], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0df47911-96af-47dc-aa74-a17484a2afa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6242368742368742"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887fdb96-f168-4d45-929f-995c1de0fd15",
   "metadata": {},
   "source": [
    "# 综合分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99d0ed00-0f71-4a6d-bc04-21256179da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = test_result.rename(columns={col: col+\"_bge\" for col in [\n",
    "                                               \"result\",\n",
    "                                               \"similarities\",\n",
    "                                               \"hit_reason\",\n",
    "                                               \"content\",\n",
    "                                               \"label\",\n",
    "                                               \"sim_max\",\n",
    "                                               \"sim_min\",\n",
    "                                               \"result_num\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f15c518-a06b-4744-9b00-cc5dbe439a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:05:55.259172090Z",
     "start_time": "2024-03-21T11:05:55.156211614Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_result = pd.merge(left=test_result, right=test_result2[[\"qa_id\",\n",
    "#                                                \"result\",\n",
    "#                                                \"similarities\",\n",
    "#                                                \"hit_reason\",\n",
    "#                                                \"label\",\n",
    "#                                                \"sim_max\",\n",
    "#                                                \"sim_min\",\n",
    "#                                                \"result_num\"]], \n",
    "#                  left_on=\"qa_id\", right_on=\"qa_id\", how=\"left\",\n",
    "#                  suffixes=[\"_bge\", \"_bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d68e41f-7974-49a8-be41-bdae403b3333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:05:57.080761738Z",
     "start_time": "2024-03-21T11:05:57.024953056Z"
    }
   },
   "outputs": [],
   "source": [
    "# final_result['label_all'] = final_result[[\"label_bge\", \"label_bm25\"]].apply(lambda x: max(x[\"label_bge\"], x[\"label_bm25\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962062d7-2d4f-4c43-a51a-f2f86ab8a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_all, max_all = find_score_limit(final_result[\"similarities_bm25\"].tolist())\n",
    "# final_result[\"similarities_rescaled_bm25\"] = final_result[\"similarities_bm25\"].apply(\n",
    "#     lambda x: convert_limit(x, min_all, max_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a275df4b-b658-4807-858c-212188ccc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\"]\n",
    "# final_result[\"recall_bge\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "# cols = [\"similarities_rescaled_bm25\", \"hit_reason_bm25\", \"result_bm25\"]\n",
    "# final_result[\"recall_bm25\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "# final_result[\"recall_all\"] = final_result[[\"recall_bge\", \"recall_bm25\"]].apply(\n",
    "#     lambda x: merge_recall(x, \n",
    "#                            recall_list=[\"recall_bge\", \"recall_bm25\"], \n",
    "#                            weights=[0.9, 0.84]\n",
    "#                           ), \n",
    "#     axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26595b92-49a1-40a3-bb7f-ca178749d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\", \"content_bge\"]\n",
    "final_result[\"recall_bge\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e72caaa0-1050-4caf-8793-f385efcd0257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_result[\"recall_bge\"].apply(\n",
    "    lambda x: len([i[\"content\"] for i in x])) != final_result[\"recall_bge\"].apply(\n",
    "    lambda x: len(set([i[\"content\"] for i in x])))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fd8fd93-aa84-4356-8639-2fc17109e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_model_reason(x):\n",
    "    count = 0\n",
    "    for item in x:\n",
    "        i = item[\"reason\"]\n",
    "        if (i.find(\"model\") >= 0) & (i.find(\"error\") < 0):\n",
    "            count += 1\n",
    "    return count \n",
    "\n",
    "def count_error_reason(x):\n",
    "    count = 0\n",
    "    for item in x:\n",
    "        i = item[\"reason\"]\n",
    "        if (i.find(\"model\") < 0) & (i.find(\"cat\") < 0) & (i.find(\"error\") >= 0):\n",
    "            count += 1\n",
    "    return count \n",
    "\n",
    "def count_cat_reason(x):\n",
    "    count = 0\n",
    "    for item in x:\n",
    "        i = item[\"reason\"]\n",
    "        if (i.find(\"cat\") >= 0) & (i.find(\"model\") < 0) & (i.find(\"error\") < 0):\n",
    "            count += 1\n",
    "    return count \n",
    "\n",
    "def count_none_reason(x):\n",
    "    count = 0\n",
    "    for item in x:\n",
    "        i = item[\"reason\"]\n",
    "        if (i.find(\"cat\") < 0) & (i.find(\"model\") < 0) & (i.find(\"error\") < 0):\n",
    "            count += 1\n",
    "    return count \n",
    "\n",
    "def get_gt_pos(x, gt_col, recall_col):\n",
    "    positives = x[gt_col].split(\",\")\n",
    "    for index, item in enumerate(x[recall_col]):\n",
    "        i = item[\"result\"]\n",
    "        if i in positives:\n",
    "            return index\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b833c83c-4a0f-48f0-822e-feed55a5d44c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_result[\"reason_model_num\"] = final_result[\"recall_bge\"].apply(lambda x: count_model_reason(x))\n",
    "final_result[\"reason_error_num\"] = final_result[\"recall_bge\"].apply(lambda x: count_error_reason(x))\n",
    "final_result[\"reason_cat_num\"] = final_result[\"recall_bge\"].apply(lambda x: count_cat_reason(x))\n",
    "final_result[\"reason_none_num\"] = final_result[\"recall_bge\"].apply(lambda x: count_none_reason(x))\n",
    "final_result[\"result_unique_num\"] = final_result[\"recall_bge\"].apply(lambda x: len(x))\n",
    "final_result[\"gt_pos\"] = final_result[[\"recall_bge\", \"gt_qa_id\"]].apply(lambda x: get_gt_pos(x, \"gt_qa_id\", \"recall_bge\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e7832016-a4f8-4af9-808a-e9704f4c2c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason_model_num</th>\n",
       "      <th>reason_error_num</th>\n",
       "      <th>reason_cat_num</th>\n",
       "      <th>reason_none_num</th>\n",
       "      <th>result_unique_num</th>\n",
       "      <th>gt_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>3276.000000</td>\n",
       "      <td>3276.000000</td>\n",
       "      <td>3276.000000</td>\n",
       "      <td>3276.000000</td>\n",
       "      <td>3276.000000</td>\n",
       "      <td>3276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.593407</td>\n",
       "      <td>0.058303</td>\n",
       "      <td>2.466422</td>\n",
       "      <td>15.939866</td>\n",
       "      <td>20.065934</td>\n",
       "      <td>2.935452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reason_model_num  reason_error_num  reason_cat_num  reason_none_num  \\\n",
       "len          3276.000000       3276.000000     3276.000000      3276.000000   \n",
       "min             0.000000          0.000000        0.000000         0.000000   \n",
       "max            20.000000          7.000000       20.000000        20.000000   \n",
       "mean            1.593407          0.058303        2.466422        15.939866   \n",
       "median          0.000000          0.000000        0.000000        20.000000   \n",
       "\n",
       "        result_unique_num       gt_pos  \n",
       "len           3276.000000  3276.000000  \n",
       "min             20.000000     0.000000  \n",
       "max             27.000000    19.000000  \n",
       "mean            20.065934     2.935452  \n",
       "median          20.000000     1.000000  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.agg({\"reason_model_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                  \"reason_error_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                  \"reason_cat_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                  \"reason_none_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                  \"result_unique_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                  \"gt_pos\": [len, \"min\", \"max\", \"mean\", \"median\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8b4d48f1-e00a-4f40-bf67-5e83b92528be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason_none_num</th>\n",
       "      <th>result_unique_num</th>\n",
       "      <th>gt_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "      <td>2611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.999617</td>\n",
       "      <td>20.072769</td>\n",
       "      <td>3.073983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reason_none_num  result_unique_num       gt_pos\n",
       "len         2611.000000        2611.000000  2611.000000\n",
       "min           19.000000          20.000000     0.000000\n",
       "max           20.000000          27.000000    19.000000\n",
       "mean          19.999617          20.072769     3.073983\n",
       "median        20.000000          20.000000     1.000000"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"reason_none_num\"]>0].agg({\"reason_none_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"result_unique_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"gt_pos\": [len, \"min\", \"max\", \"mean\", \"median\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7b73c86e-a25b-4e57-baeb-45011d42c05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason_model_num</th>\n",
       "      <th>result_unique_num</th>\n",
       "      <th>gt_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>261.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.009756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reason_model_num  result_unique_num      gt_pos\n",
       "len                261.0              261.0  261.000000\n",
       "min                 20.0               20.0    0.000000\n",
       "max                 20.0               20.0   19.000000\n",
       "mean                20.0               20.0    2.009756\n",
       "median              20.0               20.0    0.000000"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"reason_model_num\"]>0].agg({\"reason_model_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"result_unique_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"gt_pos\": [len, \"min\", \"max\", \"mean\", \"median\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ee9b3249-449e-45dc-b844-0bfdaddc6d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason_error_num</th>\n",
       "      <th>result_unique_num</th>\n",
       "      <th>gt_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.417722</td>\n",
       "      <td>22.405063</td>\n",
       "      <td>0.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reason_error_num  result_unique_num     gt_pos\n",
       "len            79.000000          79.000000  79.000000\n",
       "min             1.000000          21.000000   0.000000\n",
       "max             7.000000          27.000000   4.000000\n",
       "mean            2.417722          22.405063   0.655172\n",
       "median          2.000000          22.000000   0.000000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"reason_error_num\"]>0].agg({\"reason_error_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"result_unique_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"gt_pos\": [len, \"min\", \"max\", \"mean\", \"median\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "12954f52-d6fd-4828-9835-5c9f0718dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reason_cat_num</th>\n",
       "      <th>result_unique_num</th>\n",
       "      <th>gt_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>404.0</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.064356</td>\n",
       "      <td>2.775229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reason_cat_num  result_unique_num      gt_pos\n",
       "len              404.0         404.000000  404.000000\n",
       "min               20.0          20.000000    0.000000\n",
       "max               20.0          23.000000   19.000000\n",
       "mean              20.0          20.064356    2.775229\n",
       "median            20.0          20.000000    1.000000"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"reason_cat_num\"]>0].agg({\"reason_cat_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"result_unique_num\": [len, \"min\", \"max\", \"mean\", \"median\"],\n",
    "                                                      \"gt_pos\": [len, \"min\", \"max\", \"mean\", \"median\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4fae46fd-c13b-47a4-bf9d-3ea2e1c0533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_target = \"recall_bge\"\n",
    "# output_cols = [\"result\", \"reason\", \"similarities\"]\n",
    "# final_result[\"recall_hard\"] = final_result[[merge_target, \"gt_qa_id\"]].apply(\n",
    "#     lambda x: mine_hard_negative2(x, \n",
    "#                                   merge_target, \n",
    "#                                   positive='gt_qa_id', \n",
    "#                                   top_n=20,\n",
    "#                                   output_cols=output_cols\n",
    "#                                  ), \n",
    "#     axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcd1f025-5a96-4a26-8686-dc4b7323d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"similarities\", \"reason\", \"result\"]\n",
    "new_cols = [\"similarities_merge_hard\", \"reason_merge_hard\", \"result_merge_hard\"]\n",
    "# cols = [\"similarities\", \"reason\", \"result\"]\n",
    "# new_cols = [\"similarities_merge_hard\", \"reason_merge_hard\", \"result_merge_hard\"]\n",
    "final_result[new_cols] = final_result[\"recall_bge\"].apply(lambda x: split_recall(x, cols, new_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "989767e7-86f3-4d6b-8f0d-cedfb2536275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result['result_num_bge_set'] = final_result.recall_bge.apply(lambda x: len(x))\n",
    "# final_result['result_num_bm25_set'] = final_result.recall_bm25.apply(lambda x: len(x))\n",
    "# final_result['result_num_all_set'] = final_result.recall_all.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1896706d-3647-423d-b299-c59d02c60d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3ecd78d-7613-40a1-94eb-a49139f7b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_result.copy()\n",
    "temp_exploded = temp.explode(\"result_merge_hard\")[['qa_id', 'result_merge_hard']]\n",
    "temp_right = df1[['qa_id', \n",
    "               'question', \n",
    "               'answer']].copy()\n",
    "temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                         left_on='result_merge_hard', right_on='qa_id', \n",
    "                         how='left', suffixes=[\"\", \"_merge_hard\"])[[\"qa_id\", \"result_merge_hard\", \"question\", \"answer\"]]\n",
    "temp_exploded = temp_exploded.rename(columns={\"question\": \"question_merge_hard\", \"answer\": \"answer_merge_hard\"})\n",
    "temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question_merge_hard\", \"answer_merge_hard\"]].apply(\n",
    "    lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9414dd0-56f2-479c-8e87-3fba11da0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.merge(left=final_result, right=temp_exploded,\n",
    "                        left_on='qa_id', right_on='qa_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb7e559b-a77d-48aa-b69a-4069f0c8b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = final_result.copy()\n",
    "# temp_exploded = temp.explode(\"result_bge_hard\")[['qa_id', 'result_bge_hard']]\n",
    "# temp_right = df1[['qa_id', \n",
    "#                'question', \n",
    "#                'answer']].copy()\n",
    "# temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "#                          left_on='result_bge_hard', right_on='qa_id', \n",
    "#                          how='left', suffixes=[\"\", \"_bge_hard\"])[[\"qa_id\", \"result_bge_hard\", \"question\", \"answer\"]]\n",
    "# temp_exploded = temp_exploded.rename(columns={\"question\": \"question_bge_hard\", \"answer\": \"answer_bge_hard\"})\n",
    "# temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question_bge_hard\", \"answer_bge_hard\"]].apply(\n",
    "#     lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f1949e8-24f3-46cd-8bb8-6d534b10ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_result = pd.merge(left=final_result, right=temp_exploded,\n",
    "#                         left_on='qa_id', right_on='qa_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a6fbc7f-19b4-4c2f-b4af-1772dbc5e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_result.copy()\n",
    "temp['gt_qa_id'] = temp['gt_qa_id'].apply(lambda x: x.split(\",\"))\n",
    "temp_exploded = temp.explode(\"gt_qa_id\")[['qa_id', 'gt_qa_id']]\n",
    "temp_right = df1[['qa_id', \n",
    "               'question', \n",
    "               'answer']].copy()\n",
    "temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                         left_on='gt_qa_id', right_on='qa_id', \n",
    "                         how='left', suffixes=[\"\", \"_kg\"])[[\"qa_id\", \"gt_qa_id\", \"question\", \"answer\"]]\n",
    "temp_exploded = temp_exploded.rename(columns={\"question\": \"question_positive\", \"answer\": \"answer_positive\"})\n",
    "temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question_positive\", \"answer_positive\"]].apply(\n",
    "    lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "final_result = pd.merge(left=final_result, right=temp_exploded,\n",
    "                        left_on='qa_id', right_on='qa_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f06abf18-9a8a-4d57-9415-d1b08880004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import faiss\n",
    "import tqdm\n",
    "def create_index(embeddings, use_gpu):\n",
    "    index = faiss.IndexFlatIP(len(embeddings[0]))\n",
    "    embeddings = np.asarray(embeddings, dtype=np.float32)\n",
    "    if use_gpu:\n",
    "        co = faiss.GpuMultipleClonerOptions()\n",
    "        co.shard = True\n",
    "        co.useFloat16 = True\n",
    "        index = faiss.index_cpu_to_all_gpus(index, co=co)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def batch_search(index,\n",
    "                 query,\n",
    "                 topk: int = 200,\n",
    "                 batch_size: int = 64):\n",
    "    all_scores, all_inxs = [], []\n",
    "    for start_index in range(0, len(query), batch_size):\n",
    "        batch_query = query[start_index:start_index + batch_size]\n",
    "        batch_scores, batch_inxs = index.search(np.asarray(batch_query, dtype=np.float32), k=topk)\n",
    "        all_scores.extend(batch_scores.tolist())\n",
    "        all_inxs.extend(batch_inxs.tolist())\n",
    "    return all_scores, all_inxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "992d8f31-e9f6-4470-892b-ed80a0287971",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(set(df.answer.tolist()))\n",
    "p_vecs = model.encode(corpus, normalize_embeddings=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1657c30-166b-4419-8865-032abfa3459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create index and search------------------\n"
     ]
    }
   ],
   "source": [
    "print('create index and search------------------')\n",
    "index = create_index(p_vecs, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ac83945-b537-4ecc-b905-d579f294af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"为这个句子生成表示以用于检索相关文章：\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56f34ba9-6cfc-44ac-b686-11fa1190884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vecs =  model.encode([instruction+i for i in final_result[\"question\"].tolist()], normalize_embeddings=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10e7f0d0-b562-4b5b-b170-b4d694dd750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"query_vec\"] = q_vecs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5064764f-2d9d-42e4-b93c-44185c171c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_hard_negative3(x, query, recall, positive, embedding, top_range, negative_number):\n",
    "    question = x[query]\n",
    "    positive_list = x[positive]\n",
    "    start, end = top_range\n",
    "    negative_list = []\n",
    "    recall_list = []\n",
    "    for item in x[recall]:\n",
    "        if item not in recall_list:\n",
    "            recall_list.append(item)\n",
    "    for item in recall_list[start:end]:\n",
    "        if (item not in positive_list) and (item != question):\n",
    "            negative_list.append(item)\n",
    "    recall_list = [item for item in recall_list if (item not in negative_list) & (item != question)]\n",
    "    if len(negative_list) > negative_number:\n",
    "        negative_list = random.sample(negative_list, negative_number)\n",
    "    elif (len(negative_list) < negative_number) & (len(recall_list) >= (negative_number - len(negative_list) + len(positive_list))):\n",
    "        samples = random.sample(recall_list, negative_number - len(negative_list) + len(positive_list))\n",
    "        samples = [sent for sent in samples if sent not in positive_list]\n",
    "        negative_list.extend(samples[:negative_number - len(negative_list)])\n",
    "    else:\n",
    "        _, a = batch_search(index, [x[embedding]], topk=negative_number + len(positive_list)+1)\n",
    "        samples = [corpus[i] for i in a[0]]\n",
    "        samples = [sent for sent in samples if (sent not in positive_list) & (sent not in negative_list) & (sent != query)]\n",
    "        negative_list.extend(samples[:negative_number - len(negative_list)])\n",
    "    return negative_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19023aef-07da-49b9-8c1e-8b81b8cbf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1024)\n",
    "final_result[\"answer_negative\"] = final_result.apply(lambda x: mine_hard_negative3(\n",
    "    x, \"question\", \"answer_merge_hard\", \"answer_positive\", \"query_vec\", [10,20], 5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20f9a97f-4fc9-446b-8d7e-60ed5290b96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(final_result[\"answer_negative\"].apply(\n",
    "    lambda x: len(x)) != final_result[\"answer_negative\"].apply(lambda x: len(set(x)))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee6eb46e-8349-4632-accb-66a1be971efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来训练bge ranker模型的数据集（采用finetuned embedding模型召回后，每路召回取前10个，融合取前20个）\n",
    "# Replace 'your_dataframe.jsonl' with your desired output filename\n",
    "convert_df_to_jsonl(final_result, '/data/dataset/kefu/bge_finetune_emb_from_db2.jsonl', \n",
    "                    query=\"question\", pos_col=\"answer_positive\", neg_col=\"answer_negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "63aa6b7e-4aa3-4baa-8b0a-57f2169842d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/workspace/data/private/zhuxiaohai/models/bge_emb_finetune_from_db\",\n",
    "    use_fast=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9e081c97-9e9f-4f73-9d44-c977c7a6a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenizer(final_result.answer.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f194246b-18a0-47e6-ab8e-a8380ac8310a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = []\n",
    "for i in a[\"input_ids\"]:\n",
    "    len_list.append(len(i))\n",
    "max(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "47bd5848-e3ee-4aad-b2c1-4761041ba859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.28571428571429"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len_list)/len(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0c766d95-f09b-4d96-9ad2-ad308a525a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n"
     ]
    }
   ],
   "source": [
    "for index, i in enumerate(len_list):\n",
    "    if i > 900:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9cc78e3d-3357-4673-a0e4-f6c8ec938b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我们在持续优化烘干效果，请您连接手机APP，升级到最新版本后再体验\\n- 小件与大件（如床单与上衣），很多衣物混合在一起洗，导致的烘不干\\n- 您好，很抱歉给您带来不便，小件衣物与床单等大件衣物一起洗烘，大件衣物会把小件衣物包裹住，使洗衣机烘干时的抖散动作无法展开，从而导致小件衣物无法烘干，建议您分类洗烘，使用【家纺】+【洗烘】程序，单独洗烘四件套或窗帘等大件织物。\\n- 用户所处的环境在沿海潮湿的地带或梅雨季节，烘干后的衣物放置在洗衣机内长时间未取出，导致的潮湿\\n- 您好，很抱歉给您带来不便，如您所处的环境在沿海潮湿的地带或梅雨季节，烘干后未能及时取出，可能会出现微微潮湿，建议您再使用【快速】+【烘干】程序继续烘一下且及时拿出即可。\\n- 用户放入的衣物过多，挤满内筒，导致的烘不干\\n- 您好，很抱歉给您带来不便，如果您在滚筒内放入了过多衣物，充满了整个滚筒。使洗衣机烘干时的抖散动作无法展开，部分衣物因筒内空间不足而导致烘干效果不佳，建议您洗烘时减少衣物投放量，选择【快速】+【烘干】模式继续烘一会儿。\\n- 正常使用，但有衣物的边角没能烘干\\n- 您好，很抱歉给您带来不便，石头分子筛洗烘一体机H1的洗烘或烘干程序，会根据您选择的洗护程序与和RR智能算法专门调试的，软件算法自动判干，衣干即停。不同材质及重量的衣物含水率不同，混合洗烘时可能会出现烘干不匀的情况，您可以选择【快速】+【烘干】继续烘干即可，建议您下次分类洗涤或减少衣物量。\\n- 放入洗衣袋内的衣物，没能烘干\\n- 您好，很抱歉给您带来不便，衣物放入洗衣袋内，会影响衣物舒展而导致烘干效果不佳，使用烘干功能时，可以将衣物取出烘干。建议您将单件衣物放入单个洗衣袋内使用，避免多件衣物放入同一个袋内而影响烘干效果。\\n- 【干衣度】上选择了【微干】而衣物有潮湿感\\n- 您好，很抱歉给您带来不便，您在使用烘干程序的时候，干衣度选择了【微干】烘干后的衣物是略带水分，【微干】的潮湿效果适合熨烫定型使用。建议您下次将【干衣度】调节成【普通】或者【超干】\\n- 手洗的衣物，如没有彻底拧干而选择了【烘干】模式，导致烘不干\\n- 您好，很抱歉给您带来不便，您手洗的衣物，如没有彻底拧干而选择了【烘干】模式，可能会导致烘干效果不佳，建议使用【洗烘】+【单脱水】，甩干后再进行烘干。'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.answer.tolist()[2294]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
