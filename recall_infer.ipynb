{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:11:06.959071886Z",
     "start_time": "2024-03-28T14:11:00.676852853Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import joblib\n",
    "import json \n",
    "import jieba \n",
    "import copy\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import matplotlib.pyplot as plt \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import FlagReranker\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a367387e-f525-4599-912c-c68be7331cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:46.614837917Z",
     "start_time": "2024-03-25T06:02:46.594416571Z"
    }
   },
   "outputs": [],
   "source": [
    "# 原始数据处理\n",
    "def format_model(x):\n",
    "    model_list = x.split(',')\n",
    "    model_list = [i.strip().lower() for i in model_list]\n",
    "    new_list = [model_list[0]]\n",
    "    i = 1\n",
    "    while i < len(model_list):\n",
    "        if (i != len(model_list) - 1) and (model_list[i-1] == model_list[i]):\n",
    "            new_list.append(model_list[i]+model_list[i+1])\n",
    "            if i < len(model_list) - 1:\n",
    "                i += 2\n",
    "            else:\n",
    "                break\n",
    "        elif (i != len(model_list) - 1) and (model_list[i-1] != model_list[i]):\n",
    "            new_list.append(model_list[i])\n",
    "            i += 1\n",
    "        elif (model_list[i] == \"上下水\") or (model_list[i] == \"air\"):\n",
    "            for j in range(len(new_list)):\n",
    "                if model_list[i-1] == new_list[j]:\n",
    "                    new_list.pop(j)\n",
    "                    break\n",
    "            new_list.append(model_list[i-1]+model_list[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            new_list.append(model_list[i])\n",
    "            break\n",
    "    return new_list\n",
    "\n",
    "def format_all_models(x, dim_df):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"全型号\") >= 0:\n",
    "            end_idx = i.find(\"全型号\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[dim_df['cat_name'] == name].model.tolist() if j not in x]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "def format_series(x, dim_df):\n",
    "    def contains_chinese(s):\n",
    "        return re.search('[\\u4e00-\\u9fff]', s) is not None\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"系列\") >= 0:\n",
    "            end_idx = i.find(\"系列\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[(dim_df.model.str.find(name)>=0) & (\n",
    "                dim_df.model.apply(lambda x: not contains_chinese(x)))].model.tolist() if j not in x]\n",
    "            new_list += [i]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ec7f8a-e9c3-48b5-9dbf-b26fb5045320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:47.275074278Z",
     "start_time": "2024-03-25T06:02:47.228000273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 拼接openai embedding\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16717201-59cd-412f-9e3d-f2b2a5592356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:47.759486977Z",
     "start_time": "2024-03-25T06:02:47.702318041Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集处理及计算与正确qa的相似度\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def search_docs(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = generate_embeddings(\n",
    "        user_query,\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_002.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[[\"qa_id\", \"question\", \"answer\", \"similarities\"]]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def concat(x):\n",
    "    return \",\".join(x.astype(str).tolist())\n",
    "\n",
    "def format_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return x\n",
    "    else:\n",
    "        return \",\".join(x.split(\"\\n\"))\n",
    "\n",
    "def count_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x.split(\",\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cce4679-0c44-45a8-89dd-808f7a33977d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:48.269259251Z",
     "start_time": "2024-03-25T06:02:48.231943506Z"
    }
   },
   "outputs": [],
   "source": [
    "# 向量召回\n",
    "def search_docs_bge(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = model.encode(user_query, normalize_embeddings=True).tolist()\n",
    "    df[\"similarities\"] = df.bge_large.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def find_non_chinese_substrings(s):\n",
    "    # 正则表达式解释：\n",
    "    # [^\\u4e00-\\u9fff\\W]+ 匹配非中文字符和非ASCII标点的连续字符\n",
    "    # 但这样会排除空格，所以我们需要允许空格存在\n",
    "    # 我们使用(?:[^\\u4e00-\\u9fff\\W]| )+ 来实现这一点，(?:) 是非捕获组，用于匹配模式但不作为捕获结果返回\n",
    "    # [^\\u4e00-\\u9fff\\W] 匹配非中文且非标点的字符，| 表示或，空格 ' ' 被显式允许\n",
    "    pattern = r'(?:[^\\u4e00-\\u9fff\\W]| )+'\n",
    "    \n",
    "    # 使用findall方法查找所有匹配项\n",
    "    matches = re.findall(pattern, s)\n",
    "    \n",
    "    # 过滤掉只包含空格的字符串\n",
    "    matches = [match for match in matches if not match.isspace()]\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.replace(\" \", \"\").lower()\n",
    "    return s\n",
    "\n",
    "def find_model(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    x = find_non_chinese_substrings(x)\n",
    "    result = [clean_string(s) for s in x]\n",
    "    return [model for model in all_model_list if model in result]\n",
    "\n",
    "def find_cat(x, all_cat_list):\n",
    "    return [name for name in all_cat_list if name in x]   \n",
    "\n",
    "def filter_model(x, model_list):\n",
    "    x = x.split(\",\")\n",
    "    for model in model_list:\n",
    "        if model in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_error_with_reason(a):\n",
    "    # 第一次匹配“错误xxx”\n",
    "    pattern1 = r\"错误\\s*\\d+\"\n",
    "    matches1 = re.findall(pattern1, a)\n",
    "    \n",
    "    # 第二次匹配“错误原因xxx”\n",
    "    pattern2 = r\"错误原因\\s*\\d+\"\n",
    "    matches2 = re.findall(pattern2, a)\n",
    "\n",
    "    # 合并两次匹配的结果\n",
    "    matches = matches1 + matches2\n",
    "    \n",
    "    return [name.replace(\" \", \"\").replace(\"原因\", \"\") for name in matches]\n",
    "\n",
    "def filter_reason(x, query_reason_list):\n",
    "    reason_list = find_error_with_reason(x)\n",
    "    for name in query_reason_list:\n",
    "        if name in reason_list:\n",
    "            return True \n",
    "    return False\n",
    "\n",
    "def transform_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        cleaned_name = clean_string(name)\n",
    "        for model in all_model_list:\n",
    "            if cleaned_name == model:\n",
    "                x = x.replace(name, model)\n",
    "                break\n",
    "    return x \n",
    "\n",
    "def remove_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        if clean_string(name) in all_model_list:\n",
    "            x = x.replace(name, \"\")\n",
    "    return x \n",
    "\n",
    "class BM25_Model(object):\n",
    "    def __init__(self, documents_list, k1=2, k2=1, b=0.5):\n",
    "        self.documents_list = documents_list\n",
    "        self.documents_number = len(documents_list)\n",
    "        self.avg_documents_len = sum([len(document) for document in documents_list]) / self.documents_number\n",
    "        self.f = []\n",
    "        self.idf = {}\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.b = b\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        df = {}\n",
    "        for document in self.documents_list:\n",
    "            temp = {}\n",
    "            for word in document:\n",
    "                temp[word] = temp.get(word, 0) + 1\n",
    "            self.f.append(temp)\n",
    "            for key in temp.keys():\n",
    "                df[key] = df.get(key, 0) + 1\n",
    "        for key, value in df.items():\n",
    "            self.idf[key] = np.log((self.documents_number - value + 0.5) / (value + 0.5))\n",
    "\n",
    "    def get_score(self, index, query):\n",
    "        score = 0.0\n",
    "        document_len = len(self.f[index])\n",
    "        qf = Counter(query)\n",
    "        for q in query:\n",
    "            if q not in self.f[index]:\n",
    "                continue\n",
    "            score += self.idf[q] * (self.f[index][q] * (self.k1 + 1) / (\n",
    "                        self.f[index][q] + self.k1 * (1 - self.b + self.b * document_len / self.avg_documents_len))) * (\n",
    "                                 qf[q] * (self.k2 + 1) / (qf[q] + self.k2))\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_documents_score(self, query, indices):\n",
    "        score_list = []\n",
    "        for i in indices:\n",
    "            score_list.append(self.get_score(i, query))\n",
    "        return score_list\n",
    "\n",
    "\n",
    "class WordCut:\n",
    "    def __init__(self, all_model_list=None):\n",
    "        with open('/data/dataset/kefu/hit_stopwords.txt', encoding='utf-8') as f: # 可根据需要打开停用词库，然后加上不想显示的词语\n",
    "            con = f.readlines()\n",
    "            stop_words = set()\n",
    "            for i in con:\n",
    "                i = i.replace(\"\\n\", \"\")   # 去掉读取每一行数据的\\n\n",
    "                stop_words.add(i)\n",
    "        self.stop_words = stop_words\n",
    "        self.all_model_list = all_model_list\n",
    "        \n",
    "    def cut(self, mytext):\n",
    "        # jieba.load_userdict('自定义词典.txt')  # 这里你可以添加jieba库识别不了的网络新词，避免将一些新词拆开\n",
    "        # jieba.initialize()  # 初始化jieba\n",
    "        # 文本预处理 ：去除一些无用的字符只提取出中文出来\n",
    "        # new_data = re.findall('[\\u4e00-\\u9fa5]+', mytext, re.S)\n",
    "        # new_data = \" \".join(new_data)\n",
    "        # 匹配中英文标点符号，以及全角和半角符号\n",
    "        pattern = r'[\\u3000-\\u303f\\uff01-\\uff0f\\uff1a-\\uff20\\uff3b-\\uff40\\uff5b-\\uff65\\u2018\\u2019\\u201c\\u201d\\u2026\\u00a0\\u2022\\u2013\\u2014\\u2010\\u2027\\uFE10-\\uFE1F\\u3001-\\u301E]|[\\.,!¡?¿\\-—_(){}[\\]\\'\\\";:/]'\n",
    "        # 使用 re.sub 替换掉符合模式的字符为空字符\n",
    "        new_data = re.sub(pattern, '', mytext)\n",
    "        new_data = transform_model_name(new_data, self.all_model_list)\n",
    "        # 文本分词\n",
    "        seg_list_exact = jieba.lcut(new_data)\n",
    "        result_list = []\n",
    "        # 去除停用词并且去除单字\n",
    "        for word in seg_list_exact:\n",
    "            if word not in self.stop_words and len(word) > 1:\n",
    "                result_list.append(word) \n",
    "        return result_list\n",
    "\n",
    "def search_docs_bm25(df, indices, user_query, top_n=4):\n",
    "    # document_list = [wc.cut(doc) for doc in df.question]\n",
    "    # bm25_model = BM25_Model(document_list)\n",
    "    embedding = wc.cut(user_query)\n",
    "    df[\"similarities\"] = bm25_model.get_documents_score(embedding, indices)\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82256265-3637-4f14-8fad-ff436810319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 综合分析\n",
    "def ranking_metric(x):\n",
    "    if (x.find(\"error\")>=0) and (x.find(\"model\")>=0):\n",
    "        return 1 \n",
    "    elif (x.find(\"error\")>=0) and (x.find(\"cat\")>=0):\n",
    "        return 2 \n",
    "    elif (x.find(\"error\")>=0):\n",
    "        return 3 \n",
    "    elif (x.find(\"model\")>=0):\n",
    "        return 4\n",
    "    elif (x.find(\"cat\")>=0):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def mine_hard_negative(x, similarities, reason, result, positive):\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = pd.DataFrame(x[[similarities, reason, result]].to_dict())\n",
    "    df = df[~df[result].isin(positives)]\n",
    "    df[\"ranking\"] = df[reason].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", similarities], ascending=[True, False])\n",
    "    df = df.drop_duplicates(result)\n",
    "    df = df.iloc[:10]\n",
    "    return pd.Series({col+\"_hard\": df[col].values.tolist() for col in [similarities, reason, result]})\n",
    "\n",
    "def format_result(x, similarities, reason, result):\n",
    "    num_result = len(x[result])\n",
    "    new_set = dict()\n",
    "    for j in range(num_result):\n",
    "        result_name = x[result][j]\n",
    "        sim = x[similarities][j]\n",
    "        reason_code = x[reason][j]\n",
    "        if result_name in new_set:\n",
    "            if (ranking_metric(reason_code) <= ranking_metric(new_set[result_name][\"reason\"])\n",
    "               ) & (sim > new_set[result_name][\"similarities\"]):\n",
    "                new_set.update({result_name: {\"similarities\": sim, \"reason\": reason_code}})\n",
    "        else:\n",
    "            new_set.update({result_name: {\"similarities\": sim, \"reason\": reason_code}})\n",
    "    df = pd.DataFrame(new_set).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def merge_recall(x, recall_list, weights):\n",
    "    pool = {}\n",
    "    for i in range(len(weights)):\n",
    "        weight = weights[i] \n",
    "        recall_name = recall_list[i]\n",
    "        num_results = len(x[recall_name])\n",
    "        for j in range(num_results):\n",
    "            result_item = x[recall_name][j]\n",
    "            result = result_item[\"result\"]\n",
    "            if result in pool:\n",
    "                if ranking_metric(result_item['reason']) < ranking_metric(pool[result]['reason']):\n",
    "                    reason = result_item['reason']\n",
    "                    pool[result]['reason'] = reason\n",
    "                pool[result]['similarities'] += weight * result_item['similarities'] / sum(weights)\n",
    "                pool[result]['full_reason'] = pool[result]['full_reason']+\",\"+result_item['reason']+\"_\"+recall_name\n",
    "            else:\n",
    "                pool[result]= {\n",
    "                    \"reason\": result_item['reason'],\n",
    "                    \"similarities\": weight * result_item['similarities'] / sum(weights),\n",
    "                    \"full_reason\": result_item['reason']+\"_\"+recall_name\n",
    "                              }\n",
    "    df = pd.DataFrame(pool).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'full_reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def mine_hard_negative2(x, recall, top_n, positive, output_cols):\n",
    "    df = pd.DataFrame(x[recall])\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = df[~df[\"result\"].isin(positives)]\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    df = df.iloc[:top_n]\n",
    "    return df[output_cols].to_dict(orient='records')  \n",
    "\n",
    "def split_recall(x, output_cols, new_cols):\n",
    "    df = pd.DataFrame(x)\n",
    "    return pd.Series({new_col: df[col].values.tolist() \n",
    "                      for col, new_col in zip(output_cols, new_cols)})\n",
    "\n",
    "def find_score_limit(x):\n",
    "    min_all = float(\"inf\")\n",
    "    max_all = float(\"-inf\")\n",
    "    for i in range(len(x)):\n",
    "        min_i = min(x[i])\n",
    "        max_i = max(x[i])\n",
    "        min_all = min(min_all, min_i)\n",
    "        max_all = max(max_all, max_i)\n",
    "    return min_all, max_all\n",
    "\n",
    "def convert_limit(x, min_all, max_all):\n",
    "    return [(i-min_all)/(max_all-min_all) for i in x]\n",
    "\n",
    "def convert_df_to_jsonl(df, filename, query=\"question_cleaned\", pos_col=\"question_positive\", neg_col=\"question_bge_hard\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            # Constructing the dictionary for each row\n",
    "            data = {\n",
    "                \"query\": row[query],\n",
    "                \"pos\": row[pos_col],\n",
    "                \"neg\": row[neg_col]\n",
    "            }\n",
    "            # Writing the JSON string followed by a newline character to make it JSONL\n",
    "            file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1a11e3-d608-41ef-a2ea-d33f675bc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序\n",
    "def mrr_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    mrr_score = 0\n",
    "    for rank, index in enumerate(pred_ranking[:k]):\n",
    "        if is_relevant[index]:\n",
    "            mrr_score = 1 / (rank + 1)\n",
    "            break\n",
    "\n",
    "    return mrr_score\n",
    "\n",
    "def recall_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    recall_score = 0\n",
    "    for index in pred_ranking[:k]:\n",
    "        if is_relevant[index]:\n",
    "            recall_score = 1\n",
    "            break\n",
    "\n",
    "    return recall_score\n",
    "\n",
    "def ap_score(is_relevant, pred_scores):\n",
    "    \"\"\"\n",
    "    Computes AP score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_scores (`List[float]` of length `num_pos+num_neg`): Predicted similarity scores\n",
    "\n",
    "    Returns:\n",
    "        ap_score (`float`): AP score\n",
    "    \"\"\"\n",
    "    # preds = np.array(is_relevant)[pred_scores_argsort]\n",
    "    # precision_at_k = np.mean(preds[:k])\n",
    "    # ap = np.mean([np.mean(preds[: k + 1]) for k in range(len(preds)) if preds[k]])\n",
    "    ap = average_precision_score(is_relevant, pred_scores)\n",
    "    return ap\n",
    "\n",
    "def compute_recall_score(df, model, query, recall):\n",
    "    pairs = []\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        for p in sample[recall]:\n",
    "            pairs.append([sample[query], p])\n",
    "    all_scores = model.compute_score(pairs)\n",
    "    result = []\n",
    "    start_inx = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        pred_scores = all_scores[start_inx:start_inx + len(sample[recall])]\n",
    "        result.append(pred_scores)\n",
    "        start_inx += len(sample[recall])\n",
    "    return result\n",
    "\n",
    "def compute_metrics_batched_from_crossencoder(df, score, relevant, \n",
    "                                              mrr_at_k=10, recall_at_list=[1,2], metrics=[\"map\", \"mrr\", \"recall\"]):\n",
    "    all_mrr_scores = []\n",
    "    all_ap_scores = []\n",
    "    all_recall_scores = [[] for _ in range(len(recall_at_list))]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        is_relevant = sample[relevant]\n",
    "        pred_scores = np.array(sample[score])\n",
    "\n",
    "        pred_scores_argsort = np.argsort(-pred_scores)  # Sort in decreasing order\n",
    "        if \"mrr\" in metrics:\n",
    "            mrr = mrr_at_k_score(is_relevant, pred_scores_argsort, mrr_at_k)\n",
    "            all_mrr_scores.append(mrr)\n",
    "        if \"map\" in metrics:\n",
    "            ap = ap_score(is_relevant, pred_scores)\n",
    "            all_ap_scores.append(ap)\n",
    "        if \"recall\" in metrics:\n",
    "            for recall_index, recall_at in enumerate(recall_at_list):\n",
    "                recall_score = recall_at_k_score(is_relevant, pred_scores_argsort, recall_at)\n",
    "                all_recall_scores[recall_index].append(recall_score)\n",
    "\n",
    "    result = {}\n",
    "    if \"map\" in metrics:\n",
    "        mean_ap = np.mean(all_ap_scores)\n",
    "        result[\"map\"] = mean_ap\n",
    "    if \"mrr\" in metrics:\n",
    "        mean_mrr = np.mean(all_mrr_scores)\n",
    "        result[f\"mrr@{mrr_at_k}\"] = mean_mrr\n",
    "    if \"recall\" in metrics:\n",
    "        for recall_index, recall_at in enumerate(recall_at_list):\n",
    "            result[f\"recall@{recall_at}\"] = np.mean(all_recall_scores[recall_index])\n",
    "    return result\n",
    "\n",
    "def find_T_loc(x, relevant, score):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    for rank, index in enumerate(pred_scores_argsort):\n",
    "        if is_relevant[index]:\n",
    "            return rank\n",
    "    return np.nan\n",
    "\n",
    "def get_reranking(x, relevant, score, recall, reason, postranking=False):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    recall_list = copy.deepcopy(x[recall])\n",
    "    for index, i in enumerate(recall_list):\n",
    "        i.update({\"relevant\": is_relevant[index], \"recall_order\": index})\n",
    "    reranking = []\n",
    "    for index, i in enumerate(pred_scores_argsort):\n",
    "        temp = recall_list[i]\n",
    "        temp.update({\"ranking_score\": pred_scores[i], \"ranking_order\": index})\n",
    "        reranking.append(temp)\n",
    "    if postranking:\n",
    "        reranking = pd.DataFrame(reranking)\n",
    "        reranking[\"if_special\"] = reranking[reason].apply(\n",
    "            lambda x: (x.find(\"model\") >= 0)|(x.find(\"error\") >= 0)|(len(x.split(\",\"))>1)).astype(int)\n",
    "        reranking.loc[(reranking[\"if_special\"]==1)&(reranking[\"similarities\"]<=0.75), \"if_special\"] = 0\n",
    "        reranking[\"ranking\"] = reranking[reason].apply(lambda x: ranking_metric(x))\n",
    "        top_list = reranking[reranking[\"if_special\"]==1].sort_values(\n",
    "            [\"if_special\", \"ranking\", \"similarities\"], ascending=[False, True, False])[\"result\"].iloc[:2].tolist()\n",
    "        reranking[\"if_top\"] = reranking[\"result\"].isin(top_list)\n",
    "        reranking = pd.concat([reranking[reranking[\"if_top\"]==True], reranking[reranking[\"if_top\"]==False]], axis=0).reset_index(drop=True)\n",
    "        reranking[\"reranking_score\"] = list(range(reranking.shape[0]))[::-1]\n",
    "        reranking[\"reranking_order\"] = list(range(reranking.shape[0]))\n",
    "        reranking = reranking.drop(\"ranking\", axis=1)\n",
    "        reranking = reranking.to_dict(orient=\"records\")\n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d514496-9b26-4fa1-bba4-35bb6ff63345",
   "metadata": {},
   "source": [
    "# 向量召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664df7cf0601055b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:38.687361618Z",
     "start_time": "2024-03-21T11:33:38.519915254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "oot = pd.read_csv(\"/data/dataset/kefu/oot20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7641a473-b5b1-4837-b39f-bed036db6b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:40.730909535Z",
     "start_time": "2024-03-21T11:33:39.108590586Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/data/dataset/kefu/database20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec85ec5-d2fd-4b5d-a728-f7c39ca7821b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:52:22.903675555Z",
     "start_time": "2024-03-22T01:52:15.663951567Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('/workspace/data/private/zhuxiaohai/models/bge_finetune_emb')\n",
    "q_embeddings = model.encode(df2.question.tolist(), normalize_embeddings=True, batch_size=32)\n",
    "df2['bge_large'] = q_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8137af06-7808-42e6-9f65-38e5492aae29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:49.128203734Z",
     "start_time": "2024-03-21T11:33:49.055985301Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2679e67b-764b-4b97-bf55-25f71ddfceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = oot\n",
    "df1 = df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b109ba5-c061-4615-a5b1-738d8e856844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签+向量3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "363eb8b3-d728-4885-ae73-2b9be17be7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:34:40.239087863Z",
     "start_time": "2024-03-21T11:33:58.341292040Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_worker(result, score, reason, top_n):\n",
    "    if (filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)).sum() > 0:\n",
    "        aug_mask = filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = filter_mask & (~(reason_indicator.str.find(\"errorcode\")>=0))\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "    else:\n",
    "        aug_mask = filter_mask\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "\n",
    "    aug_mask = (~filter_mask) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "    if aug_mask.sum() > 0:\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "    return result, score, reason\n",
    "    \n",
    "label = []\n",
    "result_list = []\n",
    "top_n = 10\n",
    "for i in range(test.shape[0]):\n",
    "    gt = test['gt_qa_id'].iloc[i].split(\",\")\n",
    "    question = test['question'].iloc[i]\n",
    "    model_list = find_model(question, all_model_list)\n",
    "    cat_list = find_cat(question, all_cat_list)   \n",
    "    cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "    reason_list = find_error_with_reason(question)\n",
    "    model_mask = (df1.model_list.apply(lambda x: filter_model(x, model_list)))\n",
    "    cat_mask = (df1.cat_name.apply(lambda x: filter_model(x, cat_list)))\n",
    "    reason_mask = (df1.question.apply(lambda x: filter_reason(x, reason_list)))\n",
    "    reason_indicator = pd.Series([\"none\"]*df1.shape[0], index=df1.index)\n",
    "    reason_indicator[model_mask] = reason_indicator[model_mask].apply(lambda x: x + \"|model\" if x != \"none\" else \"model\")\n",
    "    reason_indicator[cat_mask] = reason_indicator[cat_mask].apply(lambda x: x + \"|cat\" if x != \"none\" else \"cat\")\n",
    "    reason_indicator[reason_mask] = reason_indicator[reason_mask].apply(lambda x: x + \"|errorcode\" if x != \"none\" else \"errorcode\")\n",
    "    result = []\n",
    "    score = []\n",
    "    reason = []\n",
    "    question = remove_model_name(question, all_model_list)\n",
    "    filter_mask = (reason_indicator.str.find(\"model\")>=0)\n",
    "    if filter_mask.sum() > 0:\n",
    "        result, score, reason = sub_worker(result, score, reason, top_n)\n",
    "    else:\n",
    "        filter_mask = (reason_indicator.str.find(\"cat\")>=0)   \n",
    "        if filter_mask.sum() > 0:\n",
    "            result, score, reason = sub_worker(result, score, reason, top_n)\n",
    "    if len(result) == 0:\n",
    "        filter_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if filter_mask.sum() > 0:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "            aug_mask = (~filter_mask)\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "        else:\n",
    "            filtered_df = df1.copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator.copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "    \n",
    "    found = False\n",
    "    for j in result:\n",
    "        if j in gt:\n",
    "            found = True\n",
    "            break \n",
    "    if found:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    result_list.append({\"qa_id\": test['qa_id'].iloc[i], \n",
    "                        \"result\": result, \n",
    "                        \"similarities\": score, \n",
    "                        \"hit_reason\": reason, \n",
    "                        \"label\": int(found)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70db0ce0-3d55-483a-8f71-b6fa1c7acadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:34:40.282373600Z",
     "start_time": "2024-03-21T11:34:40.244442816Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_list)\n",
    "test_result = test.merge(result_df, how='left', left_on='qa_id', right_on='qa_id')\n",
    "test_result[\"sim_max\"] = test_result[\"similarities\"].apply(lambda x: max(x))\n",
    "test_result[\"sim_min\"] = test_result[\"similarities\"].apply(lambda x: min(x))\n",
    "test_result[\"result_num\"] = test_result.result.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0df47911-96af-47dc-aa74-a17484a2afa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8296ce3-c998-4894-8e27-648b08573b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签+bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6851af43-1b93-4085-b1cb-069eaef5473b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:41:32.647165586Z",
     "start_time": "2024-03-21T11:41:32.553294811Z"
    }
   },
   "outputs": [],
   "source": [
    "wc = WordCut(all_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53de1cab-97dd-4c74-a88e-300311ab4259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.867 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "document_list = [wc.cut(doc) for doc in df1.question]\n",
    "bm25_model = BM25_Model(document_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "461d90e1-2740-40e9-817e-4ef988b99c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:05:48.384702446Z",
     "start_time": "2024-03-21T11:05:35.467706537Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_worker_bm25(result, score, reason, top_n):\n",
    "    if (filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)).sum() > 0:\n",
    "        aug_mask = filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = filter_mask & (~(reason_indicator.str.find(\"errorcode\")>=0))\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "    else:\n",
    "        aug_mask = filter_mask\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "\n",
    "    aug_mask = (~filter_mask) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "    # aug_mask = (~filter_mask) & (~(reason_indicator.str.find(\"errorcode\")>=0)) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "    if aug_mask.sum() > 0:\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "\n",
    "    return result, score, reason\n",
    "\n",
    "label = []\n",
    "result_list = []\n",
    "top_n = 10\n",
    "for i in range(test.shape[0]):\n",
    "    gt = test['gt_qa_id'].iloc[i].split(\",\")\n",
    "    question = test['question'].iloc[i]\n",
    "    model_list = find_model(question, all_model_list)\n",
    "    cat_list = find_cat(question, all_cat_list)   \n",
    "    cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "    reason_list = find_error_with_reason(question)\n",
    "    model_mask = (df1.model_list.apply(lambda x: filter_model(x, model_list)))\n",
    "    cat_mask = (df1.cat_name.apply(lambda x: filter_model(x, cat_list)))\n",
    "    reason_mask = (df1.question.apply(lambda x: filter_reason(x, reason_list)))\n",
    "    reason_indicator = pd.Series([\"none\"]*df1.shape[0], index=df1.index)\n",
    "    reason_indicator[model_mask] = reason_indicator[model_mask].apply(lambda x: x + \"|model\" if x != \"none\" else \"model\")\n",
    "    reason_indicator[cat_mask] = reason_indicator[cat_mask].apply(lambda x: x + \"|cat\" if x != \"none\" else \"cat\")\n",
    "    reason_indicator[reason_mask] = reason_indicator[reason_mask].apply(lambda x: x + \"|errorcode\" if x != \"none\" else \"errorcode\")\n",
    "    result = []\n",
    "    score = []\n",
    "    reason = []\n",
    "    question = remove_model_name(question, all_model_list)\n",
    "    filter_mask = (reason_indicator.str.find(\"model\")>=0)\n",
    "    if filter_mask.sum() > 0:\n",
    "        result, score, reason = sub_worker_bm25(result, score, reason, top_n)\n",
    "    else:\n",
    "        filter_mask = (reason_indicator.str.find(\"cat\")>=0)   \n",
    "        if filter_mask.sum() > 0:\n",
    "            result, score, reason = sub_worker_bm25(result, score, reason, top_n)\n",
    "    if len(result) == 0:\n",
    "        filter_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if filter_mask.sum() > 0:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "            aug_mask = (~filter_mask)\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "        else:\n",
    "            filtered_df = df1.copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator.copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=top_n)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "    # result_list.append({\"qa_id\": test['qa_id'].iloc[i], \"result\": result, \"similarities\": score, \"hit_reason\": reason})\n",
    "    found = False\n",
    "    for j in result:\n",
    "        if j in gt:\n",
    "            found = True\n",
    "            break \n",
    "    if found:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    result_list.append({\"qa_id\": test['qa_id'].iloc[i], \"result\": result, \"similarities\": score, \"hit_reason\": reason, \"label\": int(found)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e35ec455-5506-4413-9ae7-a8d9975407a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:05:48.419866682Z",
     "start_time": "2024-03-21T11:05:48.392615033Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_list)\n",
    "test_result2 = test.merge(result_df, how='left', left_on='qa_id', right_on='qa_id')\n",
    "test_result2[\"sim_max\"] = test_result2[\"similarities\"].apply(lambda x: max(x) if len(x)>0 else np.nan)\n",
    "test_result2[\"sim_min\"] = test_result2[\"similarities\"].apply(lambda x: min(x) if len(x)>0 else np.nan)\n",
    "test_result2[\"result_num\"] = test_result2.result.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c483a6-1896-4588-b80f-4932d52c951d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205128205128205"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result2.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887fdb96-f168-4d45-929f-995c1de0fd15",
   "metadata": {},
   "source": [
    "# 综合分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f15c518-a06b-4744-9b00-cc5dbe439a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:05:55.259172090Z",
     "start_time": "2024-03-21T11:05:55.156211614Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result = pd.merge(left=test_result, right=test_result2[[\"qa_id\",\n",
    "                                               \"result\",\n",
    "                                               \"similarities\",\n",
    "                                               \"hit_reason\",\n",
    "                                               \"label\",\n",
    "                                               \"sim_max\",\n",
    "                                               \"sim_min\",\n",
    "                                               \"result_num\"]], \n",
    "                 left_on=\"qa_id\", right_on=\"qa_id\", how=\"left\",\n",
    "                 suffixes=[\"_bge\", \"_bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d68e41f-7974-49a8-be41-bdae403b3333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:05:57.080761738Z",
     "start_time": "2024-03-21T11:05:57.024953056Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result['label_all'] = final_result[[\"label_bge\", \"label_bm25\"]].apply(lambda x: max(x[\"label_bge\"], x[\"label_bm25\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e551574a-ca18-48ec-84fc-7ac7753949e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.label_all.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "962062d7-2d4f-4c43-a51a-f2f86ab8a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_all, max_all = find_score_limit(final_result[\"similarities_bm25\"].tolist())\n",
    "final_result[\"similarities_rescaled_bm25\"] = final_result[\"similarities_bm25\"].apply(\n",
    "    lambda x: convert_limit(x, min_all, max_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a275df4b-b658-4807-858c-212188ccc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\"]\n",
    "final_result[\"recall_bge\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "cols = [\"similarities_rescaled_bm25\", \"hit_reason_bm25\", \"result_bm25\"]\n",
    "final_result[\"recall_bm25\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "final_result[\"recall_all\"] = final_result[[\"recall_bge\", \"recall_bm25\"]].apply(\n",
    "    lambda x: merge_recall(x, \n",
    "                           recall_list=[\"recall_bge\", \"recall_bm25\"], \n",
    "                           weights=[0.9, 0.84]\n",
    "                          ), \n",
    "    axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fae46fd-c13b-47a4-bf9d-3ea2e1c0533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"recall_hard\"] = final_result[[\"recall_all\", \"gt_qa_id\"]].apply(\n",
    "    lambda x: mine_hard_negative2(x, \n",
    "                                  \"recall_all\", \n",
    "                                  positive='gt_qa_id', \n",
    "                                  top_n=20,\n",
    "                                  output_cols=[\"result\", \"reason\", \"full_reason\", \"similarities\"]\n",
    "                                 ), \n",
    "    axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd1f025-5a96-4a26-8686-dc4b7323d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"similarities\", \"reason\", \"full_reason\", \"result\"]\n",
    "new_cols = [\"similarities_merge_hard\", \"reason_merge_hard\", \"full_reason_merge_hard\", \"result_merge_hard\"]\n",
    "final_result[new_cols] = final_result[\"recall_hard\"].apply(lambda x: split_recall(x, cols, new_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "989767e7-86f3-4d6b-8f0d-cedfb2536275",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result['result_num_bge_set'] = final_result.recall_bge.apply(lambda x: len(x))\n",
    "final_result['result_num_bm25_set'] = final_result.recall_bm25.apply(lambda x: len(x))\n",
    "final_result['result_num_all_set'] = final_result.recall_all.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52307929-a273-4d15-838d-4438e72271c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只做向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aea8d3c4-2222-44e0-ba46-816fc7c5c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\", \"gt_qa_id\"]\n",
    "new_cols = [col+\"_hard\" for col in cols if col != \"gt_qa_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efb06a55-8d4d-4b7b-b658-a5f2c9fe6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[new_cols] = final_result[cols].apply(lambda x: mine_hard_negative(x, *cols), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1896706d-3647-423d-b299-c59d02c60d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3ecd78d-7613-40a1-94eb-a49139f7b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_result.copy()\n",
    "temp_exploded = temp.explode(\"result_merge_hard\")[['qa_id', 'result_merge_hard']]\n",
    "temp_right = df1[['qa_id', \n",
    "               'question', \n",
    "               'answer']].copy()\n",
    "temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                         left_on='result_merge_hard', right_on='qa_id', \n",
    "                         how='left', suffixes=[\"\", \"_merge_hard\"])[[\"qa_id\", \"result_merge_hard\", \"question\", \"answer\"]]\n",
    "temp_exploded = temp_exploded.rename(columns={\"question\": \"question_merge_hard\", \"answer\": \"answer_merge_hard\"})\n",
    "temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question_merge_hard\", \"answer_merge_hard\"]].apply(\n",
    "    lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c29c1cb-d8ef-463b-b1af-0586a6cdcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.merge(left=final_result, right=temp_exploded,\n",
    "                        left_on='qa_id', right_on='qa_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb7e559b-a77d-48aa-b69a-4069f0c8b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_result.copy()\n",
    "temp_exploded = temp.explode(\"result_bge_hard\")[['qa_id', 'result_bge_hard']]\n",
    "temp_right = df1[['qa_id', \n",
    "               'question', \n",
    "               'answer']].copy()\n",
    "temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                         left_on='result_bge_hard', right_on='qa_id', \n",
    "                         how='left', suffixes=[\"\", \"_bge_hard\"])[[\"qa_id\", \"result_bge_hard\", \"question\", \"answer\"]]\n",
    "temp_exploded = temp_exploded.rename(columns={\"question\": \"question_bge_hard\", \"answer\": \"answer_bge_hard\"})\n",
    "temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question_bge_hard\", \"answer_bge_hard\"]].apply(\n",
    "    lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f1949e8-24f3-46cd-8bb8-6d534b10ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.merge(left=final_result, right=temp_exploded,\n",
    "                        left_on='qa_id', right_on='qa_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a6fbc7f-19b4-4c2f-b4af-1772dbc5e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_result.copy()\n",
    "temp['gt_qa_id'] = temp['gt_qa_id'].apply(lambda x: x.split(\",\"))\n",
    "temp_exploded = temp.explode(\"gt_qa_id\")[['qa_id', 'gt_qa_id']]\n",
    "temp_right = df1[['qa_id', \n",
    "               'question', \n",
    "               'answer']].copy()\n",
    "temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                         left_on='gt_qa_id', right_on='qa_id', \n",
    "                         how='left', suffixes=[\"\", \"_kg\"])[[\"qa_id\", \"gt_qa_id\", \"question\", \"answer\"]]\n",
    "temp_exploded = temp_exploded.rename(columns={\"question\": \"question_positive\", \"answer\": \"answer_positive\"})\n",
    "temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question_positive\", \"answer_positive\"]].apply(\n",
    "    lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "final_result = pd.merge(left=final_result, right=temp_exploded,\n",
    "                        left_on='qa_id', right_on='qa_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "070adc5e-3e12-4269-add9-466a84f8d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"question_cleaned\"] = final_result[\"question\"].apply(lambda x: remove_model_name(x, all_model_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbdd4d-db0b-4173-9625-61d2fa752fca",
   "metadata": {},
   "source": [
    "# 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4606ffe7-0695-48c9-a7af-4358b59f0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reranker = FlagReranker(\"/workspace/data/private/zhuxiaohai/models/bge_finetune_reranker_question_top20\", use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62a08d02-c40f-4344-b905-a852eab6f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute Scores: 100%|█████████████████████████████| 2/2 [00:00<00:00,  7.21it/s]\n",
      "Compute Scores: 100%|█████████████████████████████| 2/2 [00:00<00:00,  9.06it/s]\n",
      "Compute Scores: 100%|█████████████████████████████| 2/2 [00:00<00:00,  8.31it/s]\n",
      "Compute Scores: 100%|█████████████████████████████| 2/2 [00:00<00:00,  8.44it/s]\n",
      "Compute Scores: 100%|█████████████████████████████| 3/3 [00:00<00:00,  7.32it/s]\n",
      "Compute Scores: 100%|█████████████████████████████| 3/3 [00:00<00:00,  7.61it/s]\n"
     ]
    }
   ],
   "source": [
    "recall_list = [\"recall_bge\", \"recall_bm25\", \"recall_all\"]\n",
    "top_n = [1, 2]\n",
    "use_sim_score = False\n",
    "result_all = {}\n",
    "result_T_loc = {}\n",
    "result_reranking = {}\n",
    "preranking = None\n",
    "target = \"question\"\n",
    "postranking = True\n",
    "for recall in recall_list:\n",
    "    # 召回特性\n",
    "    temp = final_result.copy()\n",
    "    if preranking is not None:\n",
    "        temp[recall] = temp[recall].apply(lambda x: x[:preranking])\n",
    "    temp[f\"{recall}_all\"] = temp[recall].apply(lambda x: [i[\"result\"] for i in x])\n",
    "    temp[\"relevant\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(\n",
    "        lambda x: [True if i in x[\"gt_qa_id\"].split(\",\") else False for i in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp_exploded = temp.explode(f\"{recall}_all\")[['qa_id', f\"{recall}_all\"]]\n",
    "    temp_right = df1[['qa_id', 'question', 'answer']].copy()\n",
    "    temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                             left_on=f\"{recall}_all\", right_on='qa_id', \n",
    "                             how='left', suffixes=[\"\", \"_right\"])[[\"qa_id\", f\"{recall}_all\", \"question\", \"answer\"]]\n",
    "    temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question\", \"answer\"]].apply(\n",
    "        lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "    temp = pd.merge(left=temp[[\"qa_id\", \"question_cleaned\", f\"{recall}_all\", \"relevant\", recall]], right=temp_exploded,\n",
    "                    left_on='qa_id', right_on='qa_id', how='left')\n",
    "    if use_sim_score:\n",
    "        temp[\"score\"] = temp[f\"{recall}_all\"].apply(lambda x: list(range(len(x)))[::-1])\n",
    "    else:\n",
    "        temp[\"score\"] = compute_recall_score(temp, model_reranker, \"question_cleaned\", target)\n",
    "    # T_loc = temp[[\"relevant\", \"score\"]].apply(lambda x: find_T_loc(x, \"relevant\", \"score\"), axis=1)\n",
    "    if recall.find(\"_all\") >= 0:\n",
    "        reason = \"full_reason\"\n",
    "    else:\n",
    "        reason = \"reason\"\n",
    "    result_reranking[recall] = temp[[\"relevant\", \"score\", recall]].apply(\n",
    "        lambda x: get_reranking(x, \"relevant\", \"score\", recall, reason, postranking), axis=1)\n",
    "    # result_T_loc[recall] = T_loc\n",
    "    if postranking:\n",
    "        temp[\"score\"] = [[j[\"reranking_score\"] for j in i] for i in result_reranking[recall]] \n",
    "        temp[\"relevant\"] = [[j[\"relevant\"] for j in i] for i in result_reranking[recall]]\n",
    "    T_loc = temp[[\"relevant\", \"score\"]].apply(lambda x: find_T_loc(x, \"relevant\", \"score\"), axis=1)\n",
    "    result_T_loc[recall] = T_loc\n",
    "    result_all[recall] = compute_metrics_batched_from_crossencoder(temp, \"score\", \"relevant\", metrics=[\"recall\"], recall_at_list=top_n)\n",
    "\n",
    "    # 排序特性\n",
    "    temp = final_result.copy()\n",
    "    if preranking is not None:\n",
    "        temp[recall] = temp[recall].apply(lambda x: x[:preranking])\n",
    "    temp[f\"{recall}_all\"] = temp[recall].apply(lambda x: [i[\"result\"] for i in x])\n",
    "    temp[f\"{recall}_all\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(lambda x: x[f\"{recall}_all\"] + [\n",
    "        i for i in x[\"gt_qa_id\"].split(\",\") if i not in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp[\"relevant\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(\n",
    "        lambda x: [True if i in x[\"gt_qa_id\"].split(\",\") else False for i in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp_exploded = temp.explode(f\"{recall}_all\")[['qa_id', f\"{recall}_all\"]]\n",
    "    temp_right = df1[['qa_id', 'question', 'answer']].copy()\n",
    "    temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                             left_on=f\"{recall}_all\", right_on='qa_id', \n",
    "                             how='left', suffixes=[\"\", \"_right\"])[[\"qa_id\", f\"{recall}_all\", \"question\", \"answer\"]]\n",
    "    temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question\", \"answer\"]].apply(\n",
    "        lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "    temp = pd.merge(left=temp[[\"qa_id\", \"question_cleaned\", f\"{recall}_all\", \"relevant\"]], right=temp_exploded,\n",
    "                    left_on='qa_id', right_on='qa_id', how='left')\n",
    "    if use_sim_score:\n",
    "        temp[\"score\"] = temp[f\"{recall}_all\"].apply(lambda x: list(range(len(x)))[::-1])\n",
    "    else:\n",
    "        temp[\"score\"] = compute_recall_score(temp, model_reranker, \"question_cleaned\", target)\n",
    "    result_all[recall].update(compute_metrics_batched_from_crossencoder(temp, \"score\", \"relevant\", metrics=[\"map\", \"mrr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2ac08de0-bd94-4318-92ac-67933fb668e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>proportion_x</th>\n",
       "      <th>recall_bm25</th>\n",
       "      <th>proportion_y</th>\n",
       "      <th>recall_all</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recall_bge  proportion_x  recall_bm25  proportion_y  recall_all  proportion\n",
       "0         0.0      0.820513          0.0      0.769231         0.0    0.743590\n",
       "1         1.0      0.025641          NaN           NaN         1.0    0.051282\n",
       "2         2.0      0.025641          2.0      0.025641         2.0    0.025641\n",
       "3         NaN           NaN          NaN           NaN         3.0    0.076923\n",
       "4         4.0      0.025641          NaN           NaN         NaN         NaN\n",
       "5         6.0      0.051282          NaN           NaN         6.0    0.051282\n",
       "6       100.0      0.051282        100.0      0.179487       100.0    0.051282\n",
       "7         NaN           NaN          3.0      0.025641         NaN         NaN"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bge ranker finetune过后\n",
    "a = pd.DataFrame(result_T_loc)\n",
    "cols = a.columns.tolist()\n",
    "len_cols = [a[col].unique().shape[0] for col in cols]\n",
    "anchor = cols[np.argmax(len_cols)]\n",
    "stat = a[anchor].fillna(100).value_counts(\"mean\").sort_index().reset_index()\n",
    "for col in [col for col in cols if col != anchor]:\n",
    "    temp = a[col].fillna(100).value_counts(\"mean\").sort_index().reset_index()\n",
    "    stat = pd.merge(left=stat, right=temp, left_on=anchor, right_on=col, how=\"outer\")\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "341c8d4a-32c8-4d26-9614-b41cd71439f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>recall_bm25</th>\n",
       "      <th>recall_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall@1</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@2</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map</th>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.810939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr@10</th>\n",
       "      <td>0.835775</td>\n",
       "      <td>0.880189</td>\n",
       "      <td>0.827839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          recall_bge  recall_bm25  recall_all\n",
       "recall@1    0.820513     0.769231    0.743590\n",
       "recall@2    0.846154     0.769231    0.794872\n",
       "map         0.818681     0.863095    0.810939\n",
       "mrr@10      0.835775     0.880189    0.827839"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bge ranker finetune过后\n",
    "pd.DataFrame(result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "480070fb-a4ca-4f7b-a2cd-2b3fccaec089",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"reranking_bge\"] = pd.DataFrame(result_reranking)[\"recall_bge\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d363ba31-7770-4858-b19a-0a9012df19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"GT_rank_bge\"] = pd.DataFrame(result_T_loc)[\"recall_bge\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b1754d9-718d-4ddc-80ed-1a9cb9009d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GT_rank_bge\n",
       "0.0    32\n",
       "6.0     2\n",
       "1.0     1\n",
       "2.0     1\n",
       "4.0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[\"GT_rank_bge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "434a61d2-451c-40a9-80d7-48323ada9c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_positive</th>\n",
       "      <th>answer_positive</th>\n",
       "      <th>GT_rank_bge</th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>reranking_bge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7S PLUS 错误一</td>\n",
       "      <td>[扫地机器人机器人报错误1激光头遮挡]</td>\n",
       "      <td>[1,引导客户提供报错时照片或视频，进一步确认；\\n*有贴膜，优先引导客户取下贴膜后再关机重...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243886', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202402061673', 'reason': 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>G10S不集尘</td>\n",
       "      <td>[为什么扫地机清扫结束没有自动集尘？]</td>\n",
       "      <td>[您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>G20不集尘</td>\n",
       "      <td>[为什么扫地机清扫结束没有自动集尘？]</td>\n",
       "      <td>[您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>G10无法清洗拖布，请清理基座附近障碍物</td>\n",
       "      <td>[无法清洗拖布/回充失败/无法回充/不回基站]</td>\n",
       "      <td>[您好，基座未通电会出现上述情况，确认基座指示灯是否亮起；\\n（1）如不亮，参考话术：\\n关...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243284', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202307243284', 'reason': 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question        question_positive  \\\n",
       "6           T7S PLUS 错误一      [扫地机器人机器人报错误1激光头遮挡]   \n",
       "18               G10S不集尘      [为什么扫地机清扫结束没有自动集尘？]   \n",
       "32                G20不集尘      [为什么扫地机清扫结束没有自动集尘？]   \n",
       "34  G10无法清洗拖布，请清理基座附近障碍物  [无法清洗拖布/回充失败/无法回充/不回基站]   \n",
       "\n",
       "                                      answer_positive  GT_rank_bge  \\\n",
       "6   [1,引导客户提供报错时照片或视频，进一步确认；\\n*有贴膜，优先引导客户取下贴膜后再关机重...          3.0   \n",
       "18  [您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...          6.0   \n",
       "32  [您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...          6.0   \n",
       "34  [您好，基座未通电会出现上述情况，确认基座指示灯是否亮起；\\n（1）如不亮，参考话术：\\n关...          3.0   \n",
       "\n",
       "                                           recall_bge  \\\n",
       "6   [{'result': 'ICWIKI202307243886', 'reason': 'm...   \n",
       "18  [{'result': 'ICWIKI202307243982', 'reason': 'm...   \n",
       "32  [{'result': 'ICWIKI202307243982', 'reason': 'm...   \n",
       "34  [{'result': 'ICWIKI202307243284', 'reason': 'm...   \n",
       "\n",
       "                                        reranking_bge  \n",
       "6   [{'result': 'ICWIKI202402061673', 'reason': 'c...  \n",
       "18  [{'result': 'ICWIKI202307243982', 'reason': 'm...  \n",
       "32  [{'result': 'ICWIKI202307243982', 'reason': 'm...  \n",
       "34  [{'result': 'ICWIKI202307243284', 'reason': 'm...  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"GT_rank_bge\"]>=3][[\"question\", \n",
    "                                              \"question_positive\", \n",
    "                                              \"answer_positive\", \n",
    "                                              \"GT_rank_bge\", \n",
    "                                              \"recall_bge\",\n",
    "                                              \"reranking_bge\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "030aa51a-bd29-4f1a-a1a0-e65c8d55402e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ICWIKI202307243886'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"GT_rank_bge\"]>=3].iloc[0].gt_qa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b4acc753-b1f6-4862-9aa5-971e2c409d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'result': 'ICWIKI202402061673',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.78,\n",
       "  'relevant': False,\n",
       "  'recall_order': 6,\n",
       "  'ranking_score': 9.6875,\n",
       "  'ranking_order': 0,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 9,\n",
       "  'reranking_order': 0},\n",
       " {'result': 'ICWIKI202309040294',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.78,\n",
       "  'relevant': False,\n",
       "  'recall_order': 5,\n",
       "  'ranking_score': 9.6875,\n",
       "  'ranking_order': 1,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 8,\n",
       "  'reranking_order': 1},\n",
       " {'result': 'ICWIKI202307243887',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.78,\n",
       "  'relevant': False,\n",
       "  'recall_order': 7,\n",
       "  'ranking_score': 9.6796875,\n",
       "  'ranking_order': 2,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 7,\n",
       "  'reranking_order': 2},\n",
       " {'result': 'ICWIKI202307243886',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.77,\n",
       "  'relevant': True,\n",
       "  'recall_order': 0,\n",
       "  'ranking_score': 6.08203125,\n",
       "  'ranking_order': 3,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 6,\n",
       "  'reranking_order': 3},\n",
       " {'result': 'ICWIKI202307244160',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.66,\n",
       "  'relevant': False,\n",
       "  'recall_order': 8,\n",
       "  'ranking_score': -4.98828125,\n",
       "  'ranking_order': 4,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 5,\n",
       "  'reranking_order': 4},\n",
       " {'result': 'ICWIKI202307260010',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 2,\n",
       "  'ranking_score': -6.5546875,\n",
       "  'ranking_order': 5,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 4,\n",
       "  'reranking_order': 5},\n",
       " {'result': 'ICWIKI202307260006',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 3,\n",
       "  'ranking_score': -6.640625,\n",
       "  'ranking_order': 6,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 3,\n",
       "  'reranking_order': 6},\n",
       " {'result': 'ICWIKI202308090052',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.63,\n",
       "  'relevant': False,\n",
       "  'recall_order': 1,\n",
       "  'ranking_score': -6.87890625,\n",
       "  'ranking_order': 7,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 2,\n",
       "  'reranking_order': 7},\n",
       " {'result': 'ICWIKI202307260011',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 4,\n",
       "  'ranking_score': -6.9375,\n",
       "  'ranking_order': 8,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 1,\n",
       "  'reranking_order': 8},\n",
       " {'result': 'ICWIKI202307243883',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 9,\n",
       "  'ranking_score': -7.01171875,\n",
       "  'ranking_order': 9,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 0,\n",
       "  'reranking_order': 9}]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"GT_rank_bge\"]>=3].iloc[0].reranking_bge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "acb4b5a3-d502-4d30-9519-8202dccb8787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model</th>\n",
       "      <th>effective</th>\n",
       "      <th>update_by</th>\n",
       "      <th>update_time</th>\n",
       "      <th>model_list</th>\n",
       "      <th>model_num</th>\n",
       "      <th>model_id</th>\n",
       "      <th>cat_name</th>\n",
       "      <th>ada_002</th>\n",
       "      <th>bge_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>ICWIKI202307243916</td>\n",
       "      <td>故障问题</td>\n",
       "      <td>扫地机拖地出水少不出水</td>\n",
       "      <td>1，引导客户查看拖布是否安装到位并正常工作，拖地时完全打湿拖布，安装好后使用观察\\n2，取出...</td>\n",
       "      <td>G10S, P10, G20, T7S, T7SPlus, G10, G10Plus, T8...</td>\n",
       "      <td>2023-09-11 11:24:01 已生效</td>\n",
       "      <td>王鹏程</td>\n",
       "      <td>2023-09-11 11:24:00.000000</td>\n",
       "      <td>g10s,p10,g20,t7s,t7splus,g10,g10plus,t8,t8plus...</td>\n",
       "      <td>12</td>\n",
       "      <td>ICMU025,ICMU028,ICMU030,ICMU017,ICMU018,ICMU01...</td>\n",
       "      <td>扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机</td>\n",
       "      <td>[-0.018422875553369522, -0.010261740535497665,...</td>\n",
       "      <td>[0.017396926879882812, -0.017865771427750587, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  qa_id qa_type     question  \\\n",
       "743  ICWIKI202307243916    故障问题  扫地机拖地出水少不出水   \n",
       "\n",
       "                                                answer  \\\n",
       "743  1，引导客户查看拖布是否安装到位并正常工作，拖地时完全打湿拖布，安装好后使用观察\\n2，取出...   \n",
       "\n",
       "                                                 model  \\\n",
       "743  G10S, P10, G20, T7S, T7SPlus, G10, G10Plus, T8...   \n",
       "\n",
       "                   effective update_by                 update_time  \\\n",
       "743  2023-09-11 11:24:01 已生效       王鹏程  2023-09-11 11:24:00.000000   \n",
       "\n",
       "                                            model_list  model_num  \\\n",
       "743  g10s,p10,g20,t7s,t7splus,g10,g10plus,t8,t8plus...         12   \n",
       "\n",
       "                                              model_id  \\\n",
       "743  ICMU025,ICMU028,ICMU030,ICMU017,ICMU018,ICMU01...   \n",
       "\n",
       "                                            cat_name  \\\n",
       "743  扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机   \n",
       "\n",
       "                                               ada_002  \\\n",
       "743  [-0.018422875553369522, -0.010261740535497665,...   \n",
       "\n",
       "                                             bge_large  \n",
       "743  [0.017396926879882812, -0.017865771427750587, ...  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.qa_id==\"ICWIKI202307243916\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
