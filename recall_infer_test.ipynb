{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:05.273132005Z",
     "start_time": "2024-05-09T09:40:00.125135718Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import joblib\n",
    "import json \n",
    "import jieba \n",
    "import copy\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import matplotlib.pyplot as plt \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import FlagReranker\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a367387e-f525-4599-912c-c68be7331cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:08.364703812Z",
     "start_time": "2024-05-09T09:40:08.322972768Z"
    }
   },
   "outputs": [],
   "source": [
    "# 原始数据处理\n",
    "def format_model(x):\n",
    "    model_list = x.split(',')\n",
    "    model_list = [i.strip().lower() for i in model_list]\n",
    "    new_list = [model_list[0]]\n",
    "    i = 1\n",
    "    while i < len(model_list):\n",
    "        if (i != len(model_list) - 1) and (model_list[i-1] == model_list[i]):\n",
    "            new_list.append(model_list[i]+model_list[i+1])\n",
    "            if i < len(model_list) - 1:\n",
    "                i += 2\n",
    "            else:\n",
    "                break\n",
    "        elif (i != len(model_list) - 1) and (model_list[i-1] != model_list[i]):\n",
    "            new_list.append(model_list[i])\n",
    "            i += 1\n",
    "        elif (model_list[i] == \"上下水\") or (model_list[i] == \"air\"):\n",
    "            for j in range(len(new_list)):\n",
    "                if model_list[i-1] == new_list[j]:\n",
    "                    new_list.pop(j)\n",
    "                    break\n",
    "            new_list.append(model_list[i-1]+model_list[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            new_list.append(model_list[i])\n",
    "            break\n",
    "    return new_list\n",
    "\n",
    "def format_all_models(x, dim_df):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"全型号\") >= 0:\n",
    "            end_idx = i.find(\"全型号\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[dim_df['cat_name'] == name].model.tolist() if j not in x]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "def format_series(x, dim_df):\n",
    "    def contains_chinese(s):\n",
    "        return re.search('[\\u4e00-\\u9fff]', s) is not None\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"系列\") >= 0:\n",
    "            end_idx = i.find(\"系列\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[(dim_df.model.str.find(name)>=0) & (\n",
    "                dim_df.model.apply(lambda x: not contains_chinese(x)))].model.tolist() if j not in x]\n",
    "            new_list += [i]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ec7f8a-e9c3-48b5-9dbf-b26fb5045320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:16.983130878Z",
     "start_time": "2024-05-09T09:40:16.950139933Z"
    }
   },
   "outputs": [],
   "source": [
    "# 拼接openai embedding\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16717201-59cd-412f-9e3d-f2b2a5592356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:32.240072094Z",
     "start_time": "2024-05-09T09:40:32.194164126Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集处理及计算与正确qa的相似度\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def search_docs(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = generate_embeddings(\n",
    "        user_query,\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_002.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[[\"qa_id\", \"question\", \"answer\", \"similarities\"]]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def concat(x):\n",
    "    return \",\".join(x.astype(str).tolist())\n",
    "\n",
    "def format_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return x\n",
    "    else:\n",
    "        return \",\".join(x.split(\"\\n\"))\n",
    "\n",
    "def count_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x.split(\",\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cce4679-0c44-45a8-89dd-808f7a33977d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:37.755209759Z",
     "start_time": "2024-05-09T09:40:37.747532152Z"
    }
   },
   "outputs": [],
   "source": [
    "# 向量召回\n",
    "def search_docs_bge(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = model.encode(user_query, normalize_embeddings=True).tolist()\n",
    "    df[\"similarities\"] = df.bge_large.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False, \n",
    "                       kind=\"mergesort\"\n",
    "                      )\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def find_non_chinese_substrings(s):\n",
    "    # 正则表达式解释：\n",
    "    # [^\\u4e00-\\u9fff\\W]+ 匹配非中文字符和非ASCII标点的连续字符\n",
    "    # 但这样会排除空格，所以我们需要允许空格存在\n",
    "    # 我们使用(?:[^\\u4e00-\\u9fff\\W]| )+ 来实现这一点，(?:) 是非捕获组，用于匹配模式但不作为捕获结果返回\n",
    "    # [^\\u4e00-\\u9fff\\W] 匹配非中文且非标点的字符，| 表示或，空格 ' ' 被显式允许\n",
    "    pattern = r'(?:[^\\u4e00-\\u9fff\\W]| )+'\n",
    "    \n",
    "    # 使用findall方法查找所有匹配项\n",
    "    matches = re.findall(pattern, s)\n",
    "    \n",
    "    # 过滤掉只包含空格的字符串\n",
    "    matches = [match for match in matches if not match.isspace()]\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.replace(\" \", \"\").lower()\n",
    "    return s\n",
    "\n",
    "def find_model(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    x = find_non_chinese_substrings(x)\n",
    "    result = [clean_string(s) for s in x]\n",
    "    return [model for model in all_model_list if model in result]\n",
    "\n",
    "def find_cat(x, all_cat_list):\n",
    "    return [name for name in all_cat_list if name in x]   \n",
    "\n",
    "def filter_model(x, model_list):\n",
    "    x = x.split(\",\")\n",
    "    for model in model_list:\n",
    "        if model in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_error_with_reason(a):\n",
    "    # 第一次匹配“错误xxx”\n",
    "    pattern1 = r\"错误\\s*\\d+\"\n",
    "    matches1 = re.findall(pattern1, a)\n",
    "    \n",
    "    # 第二次匹配“错误原因xxx”\n",
    "    pattern2 = r\"错误原因\\s*\\d+\"\n",
    "    matches2 = re.findall(pattern2, a)\n",
    "\n",
    "    # 合并两次匹配的结果\n",
    "    matches = matches1 + matches2\n",
    "    \n",
    "    return [name.replace(\" \", \"\").replace(\"原因\", \"\") for name in matches]\n",
    "\n",
    "def filter_reason(x, query_reason_list):\n",
    "    reason_list = find_error_with_reason(x)\n",
    "    for name in query_reason_list:\n",
    "        if name in reason_list:\n",
    "            return True \n",
    "    return False\n",
    "\n",
    "def transform_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        cleaned_name = clean_string(name)\n",
    "        for model in all_model_list:\n",
    "            if cleaned_name == model:\n",
    "                x = x.replace(name, model)\n",
    "                break\n",
    "    return x \n",
    "\n",
    "def remove_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        if clean_string(name) in all_model_list:\n",
    "            x = x.replace(name, \"\")\n",
    "    return x \n",
    "\n",
    "class BM25_Model(object):\n",
    "    def __init__(self, documents_list, k1=2, k2=1, b=0.5):\n",
    "        self.documents_list = documents_list\n",
    "        self.documents_number = len(documents_list)\n",
    "        self.avg_documents_len = sum([len(document) for document in documents_list]) / self.documents_number\n",
    "        self.f = []\n",
    "        self.idf = {}\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.b = b\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        df = {}\n",
    "        for document in self.documents_list:\n",
    "            temp = {}\n",
    "            for word in document:\n",
    "                temp[word] = temp.get(word, 0) + 1\n",
    "            self.f.append(temp)\n",
    "            for key in temp.keys():\n",
    "                df[key] = df.get(key, 0) + 1\n",
    "        for key, value in df.items():\n",
    "            self.idf[key] = np.log((self.documents_number - value + 0.5) / (value + 0.5))\n",
    "\n",
    "    def get_score(self, index, query):\n",
    "        score = 0.0\n",
    "        document_len = len(self.f[index])\n",
    "        qf = Counter(query)\n",
    "        for q in query:\n",
    "            if q not in self.f[index]:\n",
    "                continue\n",
    "            score += self.idf[q] * (self.f[index][q] * (self.k1 + 1) / (\n",
    "                        self.f[index][q] + self.k1 * (1 - self.b + self.b * document_len / self.avg_documents_len))) * (\n",
    "                                 qf[q] * (self.k2 + 1) / (qf[q] + self.k2))\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_documents_score(self, query, indices):\n",
    "        score_list = []\n",
    "        for i in indices:\n",
    "            score_list.append(self.get_score(i, query))\n",
    "        return score_list\n",
    "\n",
    "\n",
    "class WordCut:\n",
    "    def __init__(self, all_model_list=None):\n",
    "        with open('/data/dataset/kefu/hit_stopwords.txt', encoding='utf-8') as f: # 可根据需要打开停用词库，然后加上不想显示的词语\n",
    "            con = f.readlines()\n",
    "            stop_words = set()\n",
    "            for i in con:\n",
    "                i = i.replace(\"\\n\", \"\")   # 去掉读取每一行数据的\\n\n",
    "                stop_words.add(i)\n",
    "        self.stop_words = stop_words\n",
    "        self.all_model_list = all_model_list\n",
    "        \n",
    "    def cut(self, mytext):\n",
    "        # jieba.load_userdict('自定义词典.txt')  # 这里你可以添加jieba库识别不了的网络新词，避免将一些新词拆开\n",
    "        # jieba.initialize()  # 初始化jieba\n",
    "        # 文本预处理 ：去除一些无用的字符只提取出中文出来\n",
    "        # new_data = re.findall('[\\u4e00-\\u9fa5]+', mytext, re.S)\n",
    "        # new_data = \" \".join(new_data)\n",
    "        # 匹配中英文标点符号，以及全角和半角符号\n",
    "        pattern = r'[\\u3000-\\u303f\\uff01-\\uff0f\\uff1a-\\uff20\\uff3b-\\uff40\\uff5b-\\uff65\\u2018\\u2019\\u201c\\u201d\\u2026\\u00a0\\u2022\\u2013\\u2014\\u2010\\u2027\\uFE10-\\uFE1F\\u3001-\\u301E]|[\\.,!¡?¿\\-—_(){}[\\]\\'\\\";:/]'\n",
    "        # 使用 re.sub 替换掉符合模式的字符为空字符\n",
    "        new_data = re.sub(pattern, '', mytext)\n",
    "        if self.all_model_list is not None:\n",
    "            new_data = transform_model_name(new_data, self.all_model_list)\n",
    "        # 文本分词\n",
    "        seg_list_exact = jieba.lcut(new_data)\n",
    "        result_list = []\n",
    "        # 去除停用词并且去除单字\n",
    "        for word in seg_list_exact:\n",
    "            if word not in self.stop_words and len(word) > 1:\n",
    "                result_list.append(word) \n",
    "        return result_list\n",
    "\n",
    "def search_docs_bm25(df, indices, user_query, top_n=4):\n",
    "    # document_list = [wc.cut(doc) for doc in df.question]\n",
    "    # bm25_model = BM25_Model(document_list)\n",
    "    embedding = wc.cut(user_query)\n",
    "    df[\"similarities\"] = bm25_model.get_documents_score(embedding, indices)\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82256265-3637-4f14-8fad-ff436810319f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:39.906522207Z",
     "start_time": "2024-05-09T09:40:39.877750125Z"
    }
   },
   "outputs": [],
   "source": [
    "# 综合分析\n",
    "def ranking_metric(x):\n",
    "    if (x.find(\"error\")>=0) and (x.find(\"model\")>=0):\n",
    "        return 1 \n",
    "    elif (x.find(\"error\")>=0) and (x.find(\"cat\")>=0):\n",
    "        return 2 \n",
    "    elif (x.find(\"error\")>=0):\n",
    "        return 3 \n",
    "    elif (x.find(\"model\")>=0):\n",
    "        return 4\n",
    "    elif (x.find(\"cat\")>=0):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def mine_hard_negative(x, similarities, reason, result, positive):\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = pd.DataFrame(x[[similarities, reason, result]].to_dict())\n",
    "    df = df[~df[result].isin(positives)]\n",
    "    df[\"ranking\"] = df[reason].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", similarities], ascending=[True, False])\n",
    "    df = df.drop_duplicates(result)\n",
    "    df = df.iloc[:10]\n",
    "    return pd.Series({col+\"_hard\": df[col].values.tolist() for col in [similarities, reason, result]})\n",
    "\n",
    "def format_result(x, similarities, reason, result):\n",
    "    num_result = len(x[result])\n",
    "    new_set = dict()\n",
    "    for j in range(num_result):\n",
    "        result_name = x[result][j]\n",
    "        sim = x[similarities][j]\n",
    "        reason_code = x[reason][j]\n",
    "        if result_name in new_set:\n",
    "            if (ranking_metric(reason_code) <= ranking_metric(new_set[result_name][\"reason\"])\n",
    "               ) & (sim > new_set[result_name][\"similarities\"]):\n",
    "                new_set.update({result_name: {\"similarities\": sim, \"reason\": reason_code}})\n",
    "        else:\n",
    "            new_set.update({result_name: {\"similarities\": sim, \"reason\": reason_code}})\n",
    "    df = pd.DataFrame(new_set).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def merge_recall(x, recall_list, weights):\n",
    "    pool = {}\n",
    "    for i in range(len(weights)):\n",
    "        weight = weights[i] \n",
    "        recall_name = recall_list[i]\n",
    "        num_results = len(x[recall_name])\n",
    "        for j in range(num_results):\n",
    "            result_item = x[recall_name][j]\n",
    "            result = result_item[\"result\"]\n",
    "            if result in pool:\n",
    "                if ranking_metric(result_item['reason']) < ranking_metric(pool[result]['reason']):\n",
    "                    reason = result_item['reason']\n",
    "                    pool[result]['reason'] = reason\n",
    "                pool[result]['similarities'] += weight * result_item['similarities'] / sum(weights)\n",
    "                pool[result]['full_reason'] = pool[result]['full_reason']+\",\"+result_item['reason']+\"_\"+recall_name\n",
    "            else:\n",
    "                pool[result]= {\n",
    "                    \"reason\": result_item['reason'],\n",
    "                    \"similarities\": weight * result_item['similarities'] / sum(weights),\n",
    "                    \"full_reason\": result_item['reason']+\"_\"+recall_name\n",
    "                              }\n",
    "    df = pd.DataFrame(pool).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'full_reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def mine_hard_negative2(x, recall, top_n, positive, output_cols):\n",
    "    df = pd.DataFrame(x[recall])\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = df[~df[\"result\"].isin(positives)]\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    df = df.iloc[:top_n]\n",
    "    return df[output_cols].to_dict(orient='records')  \n",
    "\n",
    "def split_recall(x, output_cols, new_cols):\n",
    "    df = pd.DataFrame(x)\n",
    "    return pd.Series({new_col: df[col].values.tolist() \n",
    "                      for col, new_col in zip(output_cols, new_cols)})\n",
    "\n",
    "def find_score_limit(x):\n",
    "    min_all = float(\"inf\")\n",
    "    max_all = float(\"-inf\")\n",
    "    for i in range(len(x)):\n",
    "        min_i = min(x[i])\n",
    "        max_i = max(x[i])\n",
    "        min_all = min(min_all, min_i)\n",
    "        max_all = max(max_all, max_i)\n",
    "    return min_all, max_all\n",
    "\n",
    "def convert_limit(x, min_all, max_all):\n",
    "    return [(i-min_all)/(max_all-min_all) for i in x]\n",
    "\n",
    "def convert_df_to_jsonl(df, filename, query=\"question_cleaned\", pos_col=\"question_positive\", neg_col=\"question_bge_hard\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            # Constructing the dictionary for each row\n",
    "            data = {\n",
    "                \"query\": row[query],\n",
    "                \"pos\": row[pos_col],\n",
    "                \"neg\": row[neg_col]\n",
    "            }\n",
    "            # Writing the JSON string followed by a newline character to make it JSONL\n",
    "            file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea1a11e3-d608-41ef-a2ea-d33f675bc371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:55.976370404Z",
     "start_time": "2024-05-09T09:40:55.963956411Z"
    }
   },
   "outputs": [],
   "source": [
    "# 排序\n",
    "def mrr_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    mrr_score = 0\n",
    "    for rank, index in enumerate(pred_ranking[:k]):\n",
    "        if is_relevant[index]:\n",
    "            mrr_score = 1 / (rank + 1)\n",
    "            break\n",
    "\n",
    "    return mrr_score\n",
    "\n",
    "def recall_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    recall_score = 0\n",
    "    for index in pred_ranking[:k]:\n",
    "        if is_relevant[index]:\n",
    "            recall_score = 1\n",
    "            break\n",
    "\n",
    "    return recall_score\n",
    "\n",
    "def ap_score(is_relevant, pred_scores):\n",
    "    \"\"\"\n",
    "    Computes AP score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_scores (`List[float]` of length `num_pos+num_neg`): Predicted similarity scores\n",
    "\n",
    "    Returns:\n",
    "        ap_score (`float`): AP score\n",
    "    \"\"\"\n",
    "    # preds = np.array(is_relevant)[pred_scores_argsort]\n",
    "    # precision_at_k = np.mean(preds[:k])\n",
    "    # ap = np.mean([np.mean(preds[: k + 1]) for k in range(len(preds)) if preds[k]])\n",
    "    ap = average_precision_score(is_relevant, pred_scores)\n",
    "    return ap\n",
    "\n",
    "def compute_recall_score(df, model, query, recall):\n",
    "    pairs = []\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        for p in sample[recall]:\n",
    "            pairs.append([sample[query], p])\n",
    "    all_scores = model.compute_score(pairs)\n",
    "    result = []\n",
    "    start_inx = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        pred_scores = all_scores[start_inx:start_inx + len(sample[recall])]\n",
    "        result.append(pred_scores)\n",
    "        start_inx += len(sample[recall])\n",
    "    return result\n",
    "\n",
    "def compute_metrics_batched_from_crossencoder(df, score, relevant, \n",
    "                                              mrr_at_k=10, recall_at_list=[1,2], metrics=[\"map\", \"mrr\", \"recall\"]):\n",
    "    all_mrr_scores = []\n",
    "    all_ap_scores = []\n",
    "    all_recall_scores = [[] for _ in range(len(recall_at_list))]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        is_relevant = sample[relevant]\n",
    "        pred_scores = np.array(sample[score])\n",
    "\n",
    "        pred_scores_argsort = np.argsort(-pred_scores)  # Sort in decreasing order\n",
    "        if \"mrr\" in metrics:\n",
    "            mrr = mrr_at_k_score(is_relevant, pred_scores_argsort, mrr_at_k)\n",
    "            all_mrr_scores.append(mrr)\n",
    "        if \"map\" in metrics:\n",
    "            ap = ap_score(is_relevant, pred_scores)\n",
    "            all_ap_scores.append(ap)\n",
    "        if \"recall\" in metrics:\n",
    "            for recall_index, recall_at in enumerate(recall_at_list):\n",
    "                recall_score = recall_at_k_score(is_relevant, pred_scores_argsort, recall_at)\n",
    "                all_recall_scores[recall_index].append(recall_score)\n",
    "\n",
    "    result = {}\n",
    "    if \"map\" in metrics:\n",
    "        mean_ap = np.mean(all_ap_scores)\n",
    "        result[\"map\"] = mean_ap\n",
    "    if \"mrr\" in metrics:\n",
    "        mean_mrr = np.mean(all_mrr_scores)\n",
    "        result[f\"mrr@{mrr_at_k}\"] = mean_mrr\n",
    "    if \"recall\" in metrics:\n",
    "        for recall_index, recall_at in enumerate(recall_at_list):\n",
    "            result[f\"recall@{recall_at}\"] = np.mean(all_recall_scores[recall_index])\n",
    "    return result\n",
    "\n",
    "def find_T_loc(x, relevant, score):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    for rank, index in enumerate(pred_scores_argsort):\n",
    "        if is_relevant[index]:\n",
    "            return rank\n",
    "    return np.nan\n",
    "\n",
    "def get_reranking(x, relevant, score, recall, reason, postranking=False):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores, kind=\"mergesort\")\n",
    "    recall_list = copy.deepcopy(x[recall])\n",
    "    for index, i in enumerate(recall_list):\n",
    "        i.update({\"relevant\": is_relevant[index], \"recall_order\": index})\n",
    "    reranking = []\n",
    "    for index, i in enumerate(pred_scores_argsort):\n",
    "        temp = recall_list[i]\n",
    "        temp.update({\"ranking_score\": pred_scores[i], \"ranking_order\": index})\n",
    "        reranking.append(temp)\n",
    "    if postranking:\n",
    "        reranking = pd.DataFrame(reranking)\n",
    "        reranking[\"if_special\"] = reranking[reason].apply(\n",
    "            lambda x: (x.find(\"model\") >= 0)|(x.find(\"error\") >= 0)|(len(x.split(\",\"))>1)).astype(int)\n",
    "        reranking.loc[(reranking[\"if_special\"]==1)&(reranking[\"similarities\"]<=0.75), \"if_special\"] = 0\n",
    "        reranking[\"ranking\"] = reranking[reason].apply(lambda x: ranking_metric(x))\n",
    "        top_list = reranking[reranking[\"if_special\"]==1].sort_values(\n",
    "            [\"if_special\", \"ranking\", \"ranking_score\"], ascending=[False, True, False], kind=\"mergesort\")[\"result\"].iloc[:2].tolist()\n",
    "        reranking[\"if_top\"] = reranking[\"result\"].isin(top_list)\n",
    "        reranking = pd.concat([reranking[reranking[\"if_top\"]==True], reranking[reranking[\"if_top\"]==False]], axis=0).reset_index(drop=True)\n",
    "        reranking[\"reranking_score\"] = list(range(reranking.shape[0]))[::-1]\n",
    "        reranking[\"reranking_order\"] = list(range(reranking.shape[0]))\n",
    "        reranking = reranking.drop(\"ranking\", axis=1)\n",
    "        reranking = reranking.to_dict(orient=\"records\")\n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d514496-9b26-4fa1-bba4-35bb6ff63345",
   "metadata": {},
   "source": [
    "# 向量召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664df7cf0601055b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:58.076077657Z",
     "start_time": "2024-05-09T09:40:58.032251974Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "oot = pd.read_csv(\"/data/dataset/kefu/oot20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7641a473-b5b1-4837-b39f-bed036db6b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:40:59.166777629Z",
     "start_time": "2024-05-09T09:40:59.098862790Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/data/dataset/kefu/database20240506.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785107d7-d45c-4a6d-bb8c-1d2390e29d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:00.054061618Z",
     "start_time": "2024-05-09T09:41:00.034789944Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2[\"error_list\"] = df2.question.apply(lambda x: \",\".join(find_error_with_reason(x))).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939574dd-c1da-4c48-99e7-ff56b07de1f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:00.380386081Z",
     "start_time": "2024-05-09T09:41:00.355014099Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2.to_csv(\"/data/dataset/kefu/database20240506.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec85ec5-d2fd-4b5d-a728-f7c39ca7821b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:07.668682966Z",
     "start_time": "2024-05-09T09:41:02.468621612Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('/workspace/data/private/zhuxiaohai/models/bge_finetune_emb')\n",
    "q_embeddings = model.encode(df2.question.tolist(), normalize_embeddings=True, batch_size=32)\n",
    "df2['bge_large'] = q_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8137af06-7808-42e6-9f65-38e5492aae29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:09.457366805Z",
     "start_time": "2024-05-09T09:41:09.423932119Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2679e67b-764b-4b97-bf55-25f71ddfceec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:09.825313949Z",
     "start_time": "2024-05-09T09:41:09.795846106Z"
    }
   },
   "outputs": [],
   "source": [
    "test = oot\n",
    "df1 = df2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1b109ba5-c061-4615-a5b1-738d8e856844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签+向量3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad22de5-1d27-4f1d-869f-93f650f1a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打标阶段测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "baae63dd-114b-496e-8cd5-c190ceb3de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(test.shape[0]):\n",
    "    question = test['question'].iloc[i]\n",
    "    model_list = find_model(question, all_model_list)\n",
    "    cat_list = find_cat(question, all_cat_list)   \n",
    "    cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "    reason_list = find_error_with_reason(question)\n",
    "    question = remove_model_name(question, all_model_list)\n",
    "    result = {\"model\": list(set(model_list)),\n",
    "              \"cat\": list(set(cat_list)),\n",
    "              \"error\": list(set(reason_list)),\n",
    "              \"query_cleaned\": question}\n",
    "    results.append(json.dumps(result, ensure_ascii=False))\n",
    "test[\"labeller\"] = results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4c68972d-5c65-44ad-a0f8-939d640b4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"question\", \"labeller\"]].to_csv(\"tests/data/data_labeller_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "363eb8b3-d728-4885-ae73-2b9be17be7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:35.325950131Z",
     "start_time": "2024-05-09T09:41:16.448639549Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_worker(result, score, reason, top_n):\n",
    "    if (filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)).sum() > 0:\n",
    "        aug_mask = filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = filter_mask & (~(reason_indicator.str.find(\"errorcode\")>=0))\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "    else:\n",
    "        aug_mask = filter_mask\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "\n",
    "    aug_mask = (~filter_mask) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "    if aug_mask.sum() > 0:\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "    return result, score, reason\n",
    "    \n",
    "label = []\n",
    "result_list = []\n",
    "infer_list = []\n",
    "top_n = 10\n",
    "for i in range(test.shape[0]):\n",
    "    gt = test['gt_qa_id'].iloc[i].split(\",\")\n",
    "    question = test['question'].iloc[i]\n",
    "    model_list = find_model(question, all_model_list)\n",
    "    cat_list = find_cat(question, all_cat_list)   \n",
    "    cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "    reason_list = find_error_with_reason(question)\n",
    "    model_mask = (df1.model_list.apply(lambda x: filter_model(x, model_list)))\n",
    "    cat_mask = (df1.cat_name.apply(lambda x: filter_model(x, cat_list)))\n",
    "    reason_mask = (df1.question.apply(lambda x: filter_reason(x, reason_list)))\n",
    "    reason_indicator = pd.Series([\"none\"]*df1.shape[0], index=df1.index)\n",
    "    reason_indicator[model_mask] = reason_indicator[model_mask].apply(lambda x: x + \"|model\" if x != \"none\" else \"model\")\n",
    "    reason_indicator[cat_mask] = reason_indicator[cat_mask].apply(lambda x: x + \"|cat\" if x != \"none\" else \"cat\")\n",
    "    reason_indicator[reason_mask] = reason_indicator[reason_mask].apply(lambda x: x + \"|errorcode\" if x != \"none\" else \"errorcode\")\n",
    "    result = []\n",
    "    score = []\n",
    "    reason = []\n",
    "    question = remove_model_name(question, all_model_list)\n",
    "    filter_mask = (reason_indicator.str.find(\"model\")>=0)\n",
    "    if filter_mask.sum() > 0:\n",
    "        result, score, reason = sub_worker(result, score, reason, top_n)\n",
    "    else:\n",
    "        filter_mask = (reason_indicator.str.find(\"cat\")>=0)   \n",
    "        if filter_mask.sum() > 0:\n",
    "            result, score, reason = sub_worker(result, score, reason, top_n)\n",
    "    if len(result) == 0:\n",
    "        filter_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if filter_mask.sum() > 0:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "            aug_mask = (~filter_mask)\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "        else:\n",
    "            filtered_df = df1.copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator.copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=top_n)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "    \n",
    "    found = False\n",
    "    for j in result:\n",
    "        if j in gt:\n",
    "            found = True\n",
    "            break \n",
    "    if found:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    result_list.append({\"qa_id\": test['qa_id'].iloc[i], \n",
    "                        \"result\": result, \n",
    "                        \"similarities\": score, \n",
    "                        \"hit_reason\": reason, \n",
    "                        \"label\": int(found)})\n",
    "    infer_list.append([{\"id\": result_name, \"score\": result_score, \"info\": result_reason} \n",
    "                      for result_name, result_score, result_reason in zip(result, score, reason)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf5e613a-8b7e-4689-b679-4c741fff1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量召回阶段测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70db0ce0-3d55-483a-8f71-b6fa1c7acadb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:35.393124771Z",
     "start_time": "2024-05-09T09:41:35.367708243Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_list)\n",
    "result_df[\"recall_list\"] = [json.dumps(i, ensure_ascii=False) for i in infer_list]\n",
    "test_result = test.merge(result_df, how='left', left_on='qa_id', right_on='qa_id')\n",
    "test_result[\"sim_max\"] = test_result[\"similarities\"].apply(lambda x: max(x))\n",
    "test_result[\"sim_min\"] = test_result[\"similarities\"].apply(lambda x: min(x))\n",
    "test_result[\"result_num\"] = test_result.result.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32401bfe-dfd4-47be-aa33-c5709bbd46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result[[\"qa_id\", \"question\", \"recall_list\"]].to_csv(\"tests/data/data_vector_search.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee448874-be86-482e-b2d4-2b7bffeaed5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:36.764545965Z",
     "start_time": "2024-05-09T09:41:36.722606851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df47911-96af-47dc-aa74-a17484a2afa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_result.label.mean()\n",
    "0.9487179487179487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8296ce3-c998-4894-8e27-648b08573b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签+bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6851af43-1b93-4085-b1cb-069eaef5473b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:41.058951155Z",
     "start_time": "2024-05-09T09:41:41.027778513Z"
    }
   },
   "outputs": [],
   "source": [
    "wc = WordCut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53de1cab-97dd-4c74-a88e-300311ab4259",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:42.524567785Z",
     "start_time": "2024-05-09T09:41:41.527692668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.815 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "document_list = [wc.cut(doc) for doc in df1.question]\n",
    "bm25_model = BM25_Model(document_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "461d90e1-2740-40e9-817e-4ef988b99c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:44.469883526Z",
     "start_time": "2024-05-09T09:41:43.220679606Z"
    }
   },
   "outputs": [],
   "source": [
    "def sub_worker_bm25(result, score, reason, top_n):\n",
    "    if (filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)).sum() > 0:\n",
    "        aug_mask = filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = filter_mask & (~(reason_indicator.str.find(\"errorcode\")>=0))\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "    else:\n",
    "        aug_mask = filter_mask\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        aug_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "\n",
    "    aug_mask = (~filter_mask) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "    # aug_mask = (~filter_mask) & (~(reason_indicator.str.find(\"errorcode\")>=0)) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "    if aug_mask.sum() > 0:\n",
    "        filtered_df = df1[aug_mask].copy()\n",
    "        filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "        filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "        res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "        result += [j[\"qa_id\"] for j in res]\n",
    "        score += [round(j[\"similarities\"], 2) for j in res]\n",
    "        reason += [j[\"hit_reason\"] for j in res]\n",
    "\n",
    "    return result, score, reason\n",
    "\n",
    "label = []\n",
    "result_list = []\n",
    "infer_list = []\n",
    "top_n = 10\n",
    "for i in range(test.shape[0]):\n",
    "    gt = test['gt_qa_id'].iloc[i].split(\",\")\n",
    "    question = test['question'].iloc[i]\n",
    "    model_list = find_model(question, all_model_list)\n",
    "    cat_list = find_cat(question, all_cat_list)   \n",
    "    cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "    reason_list = find_error_with_reason(question)\n",
    "    model_mask = (df1.model_list.apply(lambda x: filter_model(x, model_list)))\n",
    "    cat_mask = (df1.cat_name.apply(lambda x: filter_model(x, cat_list)))\n",
    "    reason_mask = (df1.question.apply(lambda x: filter_reason(x, reason_list)))\n",
    "    reason_indicator = pd.Series([\"none\"]*df1.shape[0], index=df1.index)\n",
    "    reason_indicator[model_mask] = reason_indicator[model_mask].apply(lambda x: x + \"|model\" if x != \"none\" else \"model\")\n",
    "    reason_indicator[cat_mask] = reason_indicator[cat_mask].apply(lambda x: x + \"|cat\" if x != \"none\" else \"cat\")\n",
    "    reason_indicator[reason_mask] = reason_indicator[reason_mask].apply(lambda x: x + \"|errorcode\" if x != \"none\" else \"errorcode\")\n",
    "    result = []\n",
    "    score = []\n",
    "    reason = []\n",
    "    question = remove_model_name(question, all_model_list)\n",
    "    filter_mask = (reason_indicator.str.find(\"model\")>=0)\n",
    "    if filter_mask.sum() > 0:\n",
    "        result, score, reason = sub_worker_bm25(result, score, reason, top_n)\n",
    "    else:\n",
    "        filter_mask = (reason_indicator.str.find(\"cat\")>=0)   \n",
    "        if filter_mask.sum() > 0:\n",
    "            result, score, reason = sub_worker_bm25(result, score, reason, top_n)\n",
    "    if len(result) == 0:\n",
    "        filter_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "        if filter_mask.sum() > 0:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "            aug_mask = (~filter_mask)\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))[aug_mask.values]\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=int(top_n/2))\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]  \n",
    "        else:\n",
    "            filtered_df = df1.copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator.copy()\n",
    "            filtered_indices = np.array(range(df1.shape[0]))\n",
    "            res = search_docs_bm25(filtered_df, filtered_indices, question, top_n=top_n)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "    # result_list.append({\"qa_id\": test['qa_id'].iloc[i], \"result\": result, \"similarities\": score, \"hit_reason\": reason})\n",
    "    found = False\n",
    "    for j in result:\n",
    "        if j in gt:\n",
    "            found = True\n",
    "            break \n",
    "    if found:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "    result_list.append({\"qa_id\": test['qa_id'].iloc[i], \"result\": result, \n",
    "                        \"similarities\": score, \"hit_reason\": reason, \"label\": int(found)})\n",
    "    infer_list.append([{\"id\": result_name, \"score\": result_score, \"info\": result_reason} \n",
    "                  for result_name, result_score, result_reason in zip(result, score, reason)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e35ec455-5506-4413-9ae7-a8d9975407a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:44.488343639Z",
     "start_time": "2024-05-09T09:41:44.479277582Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_list)\n",
    "result_df[\"recall_list\"] = [json.dumps(i, ensure_ascii=False) for i in infer_list]\n",
    "test_result2 = test.merge(result_df, how='left', left_on='qa_id', right_on='qa_id')\n",
    "test_result2[\"sim_max\"] = test_result2[\"similarities\"].apply(lambda x: max(x) if len(x)>0 else np.nan)\n",
    "test_result2[\"sim_min\"] = test_result2[\"similarities\"].apply(lambda x: min(x) if len(x)>0 else np.nan)\n",
    "test_result2[\"result_num\"] = test_result2.result.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b63d57-ef19-4559-a047-e6462bae0f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:45.188826309Z",
     "start_time": "2024-05-09T09:41:45.143454017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205128205128205"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result2.label.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887fdb96-f168-4d45-929f-995c1de0fd15",
   "metadata": {},
   "source": [
    "# 综合分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f15c518-a06b-4744-9b00-cc5dbe439a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:49.633396599Z",
     "start_time": "2024-05-09T09:41:49.604746744Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result = pd.merge(left=test_result, right=test_result2[[\"qa_id\",\n",
    "                                               \"result\",\n",
    "                                               \"similarities\",\n",
    "                                               \"hit_reason\",\n",
    "                                               \"recall_list\",\n",
    "                                               \"label\",\n",
    "                                               \"sim_max\",\n",
    "                                               \"sim_min\",\n",
    "                                               \"result_num\"]], \n",
    "                 left_on=\"qa_id\", right_on=\"qa_id\", how=\"left\",\n",
    "                 suffixes=[\"_bge\", \"_bm25\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d68e41f-7974-49a8-be41-bdae403b3333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:41:51.789529366Z",
     "start_time": "2024-05-09T09:41:51.753255010Z"
    }
   },
   "outputs": [],
   "source": [
    "final_result['label_all'] = final_result[[\"label_bge\", \"label_bm25\"]].apply(lambda x: max(x[\"label_bge\"], x[\"label_bm25\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e551574a-ca18-48ec-84fc-7ac7753949e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9487179487179487"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.label_all.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "962062d7-2d4f-4c43-a51a-f2f86ab8a3ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:42:45.874399647Z",
     "start_time": "2024-05-09T09:42:45.847466935Z"
    }
   },
   "outputs": [],
   "source": [
    "min_all, max_all = find_score_limit(final_result[\"similarities_bm25\"].tolist())\n",
    "final_result[\"similarities_rescaled_bm25\"] = final_result[\"similarities_bm25\"].apply(\n",
    "    lambda x: convert_limit(x, min_all, max_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e2c07fc-b154-48dc-93b3-4a363713a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\"]\n",
    "final_result[\"recall_bge\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "cols = [\"similarities_rescaled_bm25\", \"hit_reason_bm25\", \"result_bm25\"]\n",
    "final_result[\"recall_bm25\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "final_result[\"recall_all\"] = final_result[[\"recall_bge\", \"recall_bm25\"]].apply(\n",
    "    lambda x: merge_recall(x, \n",
    "                           recall_list=[\"recall_bge\", \"recall_bm25\"], \n",
    "                           weights=[0.9, 0.84]\n",
    "                          ), \n",
    "    axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22f279-b4af-4c2f-8012-443cba944d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单通道融合， 只取向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3f3cc1d-8b06-4d30-bb81-bd378c027e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:43:02.862394290Z",
     "start_time": "2024-05-09T09:43:02.485381435Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\"]\n",
    "final_result[\"recall_bge\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "final_result[\"similarities_rescaled_bm25\"] = final_result[\"similarities_rescaled_bm25\"].apply(lambda x: [round(i, 2) for i in x])\n",
    "cols = [\"similarities_rescaled_bm25\", \"hit_reason_bm25\", \"result_bm25\"]\n",
    "final_result[\"recall_bm25\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "final_result[\"recall_all\"] = final_result[[\"recall_bge\", \"recall_bm25\"]].apply(\n",
    "    lambda x: merge_recall(x, \n",
    "                           recall_list=[\"recall_bge\"], \n",
    "                           weights=[1.0]\n",
    "                          ), \n",
    "    axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e5037688-fadd-4667-9f83-8a76fddaff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"recall_bge\"] = final_result[\"recall_bge\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[\"recall_bm25\"] = final_result[\"recall_bm25\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[\"recall_all\"] = final_result[\"recall_all\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[[\"recall_list\", \"recall_bge\", \"recall_all\"]].rename(\n",
    "    columns={\"recall_list\": \"raw\", \"recall_bge\": \"duplicated\", \"recall_all\": \"merged\"}\n",
    ").to_csv(\"tests/data/data_merge_one_recall_channel.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e307e-fe54-49af-acc7-e6217e2d273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多通道融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "4423d1c2-48f2-4198-b138-b80462842373",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"similarities_rescaled_bm25\"] = final_result[\"similarities_rescaled_bm25\"].apply(lambda x: [round(i, 2) for i in x])\n",
    "\n",
    "# 去重\n",
    "cols = [\"similarities_bge\", \"hit_reason_bge\", \"result_bge\"]\n",
    "final_result[\"recall_bge\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "\n",
    "# 去重\n",
    "cols = [\"similarities_rescaled_bm25\", \"hit_reason_bm25\", \"result_bm25\"]\n",
    "final_result[\"recall_bm25\"] = final_result[cols].apply(lambda x: format_result(x, *cols), axis=1) \n",
    "\n",
    "# 原始召回\n",
    "cols = [\"similarities_rescaled_bm25\", \"hit_reason_bm25\", \"result_bm25\"]\n",
    "final_result[\"recall_list_bm25\"] = final_result[cols].apply(lambda x: [{\"id\": result_name, \"score\": result_score, \"info\": result_reason} \n",
    "                  for result_name, result_score, result_reason in \n",
    "                  zip(x[\"result_bm25\"], x[\"similarities_rescaled_bm25\"], x[\"hit_reason_bm25\"])], axis=1)\n",
    "# 融合\n",
    "final_result[\"recall_all\"] = final_result[[\"recall_bge\", \"recall_bm25\"]].apply(\n",
    "    lambda x: merge_recall(x, \n",
    "                           recall_list=[\"recall_bge\", \"recall_bm25\"], \n",
    "                           weights=[0.9, 0.84]\n",
    "                          ), \n",
    "    axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ee6c7e35-abf3-4b65-9814-8a2f6fe55689",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"recall_list_bm25\"] = final_result[\"recall_list_bm25\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[\"recall_bge\"] = final_result[\"recall_bge\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[\"recall_bm25\"] = final_result[\"recall_bm25\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[\"recall_all\"] = final_result[\"recall_all\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "final_result[[\"recall_list_bge\", \"recall_bge\", \"recall_list_bm25\", \"recall_bm25\", \"recall_all\"]].to_csv(\n",
    "    \"tests/data/data_merge_two_recall_channel.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbdd4d-db0b-4173-9625-61d2fa752fca",
   "metadata": {},
   "source": [
    "# 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "730257e8-4d6e-468d-9480-041b9b1ee0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"question_cleaned\"] = final_result[\"question\"].apply(lambda x: remove_model_name(x, all_model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4606ffe7-0695-48c9-a7af-4358b59f0781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:43:38.248399534Z",
     "start_time": "2024-05-09T09:43:35.300123313Z"
    }
   },
   "outputs": [],
   "source": [
    "model_reranker = FlagReranker(\"/workspace/data/private/zhuxiaohai/models/bge_finetune_reranker_question_top20\", use_fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bca01aa-6d12-45f7-868a-4212637175bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81365ced-c75f-4448-9bd6-4640f981d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "recall_list = [\"recall_bge\"]\n",
    "top_n = [1, 2]\n",
    "use_sim_score = False\n",
    "result_all = {}\n",
    "result_T_loc = {}\n",
    "result_reranking = {}\n",
    "preranking = None\n",
    "target = \"question\"\n",
    "postranking = True\n",
    "for recall in recall_list:\n",
    "    # 召回特性\n",
    "    temp = final_result.copy()\n",
    "    if preranking is not None:\n",
    "        temp[recall] = temp[recall].apply(lambda x: x[:preranking])\n",
    "    temp[f\"{recall}_all\"] = temp[recall].apply(lambda x: [i[\"result\"] for i in x])\n",
    "    temp[\"relevant\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(\n",
    "        lambda x: [True if i in x[\"gt_qa_id\"].split(\",\") else False for i in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp_exploded = temp.explode(f\"{recall}_all\")[['qa_id', f\"{recall}_all\"]]\n",
    "    temp_right = df1[['qa_id', 'question', 'answer']].copy()\n",
    "    temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                             left_on=f\"{recall}_all\", right_on='qa_id', \n",
    "                             how='left', suffixes=[\"\", \"_right\"])[[\"qa_id\", f\"{recall}_all\", \"question\", \"answer\"]]\n",
    "    temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question\", \"answer\"]].apply(\n",
    "        lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "    temp = pd.merge(left=temp[[\"qa_id\", \"question_cleaned\", f\"{recall}_all\", \"relevant\", recall]], right=temp_exploded,\n",
    "                    left_on='qa_id', right_on='qa_id', how='left')\n",
    "    if use_sim_score:\n",
    "        temp[\"score\"] = temp[f\"{recall}_all\"].apply(lambda x: list(range(len(x)))[::-1])\n",
    "    else:\n",
    "        temp[\"score\"] = compute_recall_score(temp, model_reranker, \"question_cleaned\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ac97b61-ea73-46a8-a66a-0d2d609b3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"recall_bge\"] = temp[\"recall_bge\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[\"recall_question\"] = temp[\"question\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[\"score\"] = temp[\"score\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[[\"question_cleaned\", \"recall_bge\", \"recall_question\", \"score\"]].to_csv(\"tests/data/data_rank.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ffd3b6-8688-4372-9d09-20968fe47aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5165e37-08f1-4ac3-8c71-c88a4fd30dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:45:29.858788137Z",
     "start_time": "2024-05-09T09:45:29.262193660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.70it/s]\n"
     ]
    }
   ],
   "source": [
    "recall_list = [\"recall_bge\"]\n",
    "top_n = [1, 2]\n",
    "use_sim_score = False\n",
    "result_all = {}\n",
    "result_T_loc = {}\n",
    "result_reranking = {}\n",
    "preranking = None\n",
    "target = \"question\"\n",
    "postranking = True\n",
    "for recall in recall_list:\n",
    "    # 召回特性\n",
    "    temp = final_result.copy()\n",
    "    if preranking is not None:\n",
    "        temp[recall] = temp[recall].apply(lambda x: x[:preranking])\n",
    "    temp[f\"{recall}_all\"] = temp[recall].apply(lambda x: [i[\"result\"] for i in x])\n",
    "    temp[\"relevant\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(\n",
    "        lambda x: [True if i in x[\"gt_qa_id\"].split(\",\") else False for i in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp_exploded = temp.explode(f\"{recall}_all\")[['qa_id', f\"{recall}_all\"]]\n",
    "    temp_right = df1[['qa_id', 'question', 'answer']].copy()\n",
    "    temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                             left_on=f\"{recall}_all\", right_on='qa_id', \n",
    "                             how='left', suffixes=[\"\", \"_right\"])[[\"qa_id\", f\"{recall}_all\", \"question\", \"answer\"]]\n",
    "    temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question\", \"answer\"]].apply(\n",
    "        lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "    temp = pd.merge(left=temp[[\"qa_id\", \"question_cleaned\", f\"{recall}_all\", \"relevant\", recall]], right=temp_exploded,\n",
    "                    left_on='qa_id', right_on='qa_id', how='left')\n",
    "    if use_sim_score:\n",
    "        temp[\"score\"] = temp[f\"{recall}_all\"].apply(lambda x: list(range(len(x)))[::-1])\n",
    "    else:\n",
    "        temp[\"score\"] = compute_recall_score(temp, model_reranker, \"question_cleaned\", target)\n",
    "    # T_loc = temp[[\"relevant\", \"score\"]].apply(lambda x: find_T_loc(x, \"relevant\", \"score\"), axis=1)\n",
    "    if recall.find(\"_all\") >= 0:\n",
    "        reason = \"full_reason\"\n",
    "    else:\n",
    "        reason = \"reason\"\n",
    "    result_reranking[recall] = temp[[\"relevant\", \"score\", recall]].apply(\n",
    "        lambda x: get_reranking(x, \"relevant\", \"score\", recall, reason, postranking), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8d761-2b7d-4925-ab47-dc8b7a5c3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拉通测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4556878-d9cf-4dcb-a798-93d588b4b3b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:45:30.541389770Z",
     "start_time": "2024-05-09T09:45:30.494335812Z"
    }
   },
   "outputs": [],
   "source": [
    "temp[\"reranking\"] = result_reranking[recall]\n",
    "temp[\"raw_question\"] = final_result.question.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e4b2824-87b0-4431-b638-a1b5b7085e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"reranking\"] = temp[\"reranking\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[[\"raw_question\", \"reranking\"]].to_csv(\"tests/data/data_pipeline.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e70210-d89e-4574-ad5a-d0ee5c2b77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重排测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9f8fb8e-34d2-4454-be88-12ff4e2509be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:45:33.391088584Z",
     "start_time": "2024-05-09T09:45:33.373368811Z"
    }
   },
   "outputs": [],
   "source": [
    "temp[\"reranking\"] = result_reranking[recall]\n",
    "temp[\"recall_bge\"] = temp[\"recall_bge\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[\"score\"] = temp[\"score\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[\"reranking\"] = temp[\"reranking\"].apply(lambda x: json.dumps(x, ensure_ascii=False)) \n",
    "temp[[\"recall_bge\", \"score\", \"reranking\"]].to_csv(\"tests/data/data_rerank.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb16ca-fdd2-47fd-816f-1a53f7aa8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总体效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62a08d02-c40f-4344-b905-a852eab6f1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T09:43:56.235724809Z",
     "start_time": "2024-05-09T09:43:53.616921586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.50it/s]\n",
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s]\n",
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  8.74it/s]\n",
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  8.56it/s]\n",
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.93it/s]\n",
      "Compute Scores: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "recall_list = [\"recall_bge\", \"recall_bm25\", \"recall_all\"]\n",
    "top_n = [1, 2]\n",
    "use_sim_score = False\n",
    "result_all = {}\n",
    "result_T_loc = {}\n",
    "result_reranking = {}\n",
    "preranking = None\n",
    "target = \"question\"\n",
    "postranking = True\n",
    "for recall in recall_list:\n",
    "    # 召回特性\n",
    "    temp = final_result.copy()\n",
    "    if preranking is not None:\n",
    "        temp[recall] = temp[recall].apply(lambda x: x[:preranking])\n",
    "    temp[f\"{recall}_all\"] = temp[recall].apply(lambda x: [i[\"result\"] for i in x])\n",
    "    temp[\"relevant\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(\n",
    "        lambda x: [True if i in x[\"gt_qa_id\"].split(\",\") else False for i in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp_exploded = temp.explode(f\"{recall}_all\")[['qa_id', f\"{recall}_all\"]]\n",
    "    temp_right = df1[['qa_id', 'question', 'answer']].copy()\n",
    "    temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                             left_on=f\"{recall}_all\", right_on='qa_id', \n",
    "                             how='left', suffixes=[\"\", \"_right\"])[[\"qa_id\", f\"{recall}_all\", \"question\", \"answer\"]]\n",
    "    temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question\", \"answer\"]].apply(\n",
    "        lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "    temp = pd.merge(left=temp[[\"qa_id\", \"question_cleaned\", f\"{recall}_all\", \"relevant\", recall]], right=temp_exploded,\n",
    "                    left_on='qa_id', right_on='qa_id', how='left')\n",
    "    if use_sim_score:\n",
    "        temp[\"score\"] = temp[f\"{recall}_all\"].apply(lambda x: list(range(len(x)))[::-1])\n",
    "    else:\n",
    "        temp[\"score\"] = compute_recall_score(temp, model_reranker, \"question_cleaned\", target)\n",
    "    # T_loc = temp[[\"relevant\", \"score\"]].apply(lambda x: find_T_loc(x, \"relevant\", \"score\"), axis=1)\n",
    "    if recall.find(\"_all\") >= 0:\n",
    "        reason = \"full_reason\"\n",
    "    else:\n",
    "        reason = \"reason\"\n",
    "    result_reranking[recall] = temp[[\"relevant\", \"score\", recall]].apply(\n",
    "        lambda x: get_reranking(x, \"relevant\", \"score\", recall, reason, postranking), axis=1)\n",
    "    # result_T_loc[recall] = T_loc\n",
    "    if postranking:\n",
    "        temp[\"score\"] = [[j[\"reranking_score\"] for j in i] for i in result_reranking[recall]] \n",
    "        temp[\"relevant\"] = [[j[\"relevant\"] for j in i] for i in result_reranking[recall]]\n",
    "    T_loc = temp[[\"relevant\", \"score\"]].apply(lambda x: find_T_loc(x, \"relevant\", \"score\"), axis=1)\n",
    "    result_T_loc[recall] = T_loc\n",
    "    result_all[recall] = compute_metrics_batched_from_crossencoder(temp, \"score\", \"relevant\", metrics=[\"recall\"], recall_at_list=top_n)\n",
    "\n",
    "    # 排序特性\n",
    "    temp = final_result.copy()\n",
    "    if preranking is not None:\n",
    "        temp[recall] = temp[recall].apply(lambda x: x[:preranking])\n",
    "    temp[f\"{recall}_all\"] = temp[recall].apply(lambda x: [i[\"result\"] for i in x])\n",
    "    temp[f\"{recall}_all\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(lambda x: x[f\"{recall}_all\"] + [\n",
    "        i for i in x[\"gt_qa_id\"].split(\",\") if i not in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp[\"relevant\"] = temp[[f\"{recall}_all\", \"gt_qa_id\"]].apply(\n",
    "        lambda x: [True if i in x[\"gt_qa_id\"].split(\",\") else False for i in x[f\"{recall}_all\"]], axis=1)\n",
    "    temp_exploded = temp.explode(f\"{recall}_all\")[['qa_id', f\"{recall}_all\"]]\n",
    "    temp_right = df1[['qa_id', 'question', 'answer']].copy()\n",
    "    temp_exploded = pd.merge(left=temp_exploded, right=temp_right, \n",
    "                             left_on=f\"{recall}_all\", right_on='qa_id', \n",
    "                             how='left', suffixes=[\"\", \"_right\"])[[\"qa_id\", f\"{recall}_all\", \"question\", \"answer\"]]\n",
    "    temp_exploded = temp_exploded.groupby(\"qa_id\")[[\"question\", \"answer\"]].apply(\n",
    "        lambda x: pd.Series({col: x[col].tolist() for col in x.columns}))\n",
    "    temp = pd.merge(left=temp[[\"qa_id\", \"question_cleaned\", f\"{recall}_all\", \"relevant\"]], right=temp_exploded,\n",
    "                    left_on='qa_id', right_on='qa_id', how='left')\n",
    "    if use_sim_score:\n",
    "        temp[\"score\"] = temp[f\"{recall}_all\"].apply(lambda x: list(range(len(x)))[::-1])\n",
    "    else:\n",
    "        temp[\"score\"] = compute_recall_score(temp, model_reranker, \"question_cleaned\", target)\n",
    "    result_all[recall].update(compute_metrics_batched_from_crossencoder(temp, \"score\", \"relevant\", metrics=[\"map\", \"mrr\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "285bfa9d-18c3-4424-b185-7de51df29e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_all</th>\n",
       "      <th>proportion_x</th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>proportion_y</th>\n",
       "      <th>recall_bm25</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recall_all  proportion_x  recall_bge  proportion_y  recall_bm25  proportion\n",
       "0         0.0      0.769231         0.0      0.820513          0.0    0.769231\n",
       "1         1.0      0.025641         1.0      0.051282          NaN         NaN\n",
       "2         2.0      0.025641         NaN           NaN          2.0    0.025641\n",
       "3         3.0      0.051282         NaN           NaN          3.0    0.025641\n",
       "4         4.0      0.025641         NaN           NaN          NaN         NaN\n",
       "5         6.0      0.025641         6.0      0.051282          NaN         NaN\n",
       "6         7.0      0.025641         NaN           NaN          NaN         NaN\n",
       "7       100.0      0.051282       100.0      0.076923        100.0    0.179487"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bge ranker finetune过后\n",
    "a = pd.DataFrame(result_T_loc)\n",
    "cols = a.columns.tolist()\n",
    "len_cols = [a[col].unique().shape[0] for col in cols]\n",
    "anchor = cols[np.argmax(len_cols)]\n",
    "stat = a[anchor].fillna(100).value_counts(\"mean\").sort_index().reset_index()\n",
    "for col in [col for col in cols if col != anchor]:\n",
    "    temp = a[col].fillna(100).value_counts(\"mean\").sort_index().reset_index()\n",
    "    stat = pd.merge(left=stat, right=temp, left_on=anchor, right_on=col, how=\"outer\")\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c2007ce-a2b5-498d-b93b-a1aaf5279f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>recall_bm25</th>\n",
       "      <th>recall_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall@1</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@2</th>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map</th>\n",
       "      <td>0.816545</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.810481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr@10</th>\n",
       "      <td>0.835775</td>\n",
       "      <td>0.880189</td>\n",
       "      <td>0.825244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          recall_bge  recall_bm25  recall_all\n",
       "recall@1    0.820513     0.769231    0.769231\n",
       "recall@2    0.871795     0.769231    0.794872\n",
       "map         0.816545     0.863095    0.810481\n",
       "mrr@10      0.835775     0.880189    0.825244"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bge ranker finetune过后\n",
    "pd.DataFrame(result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2ac08de0-bd94-4318-92ac-67933fb668e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>proportion_x</th>\n",
       "      <th>recall_bm25</th>\n",
       "      <th>proportion_y</th>\n",
       "      <th>recall_all</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recall_bge  proportion_x  recall_bm25  proportion_y  recall_all  proportion\n",
       "0         0.0      0.820513          0.0      0.769231         0.0    0.743590\n",
       "1         1.0      0.025641          NaN           NaN         1.0    0.051282\n",
       "2         2.0      0.025641          2.0      0.025641         2.0    0.025641\n",
       "3         NaN           NaN          NaN           NaN         3.0    0.076923\n",
       "4         4.0      0.025641          NaN           NaN         NaN         NaN\n",
       "5         6.0      0.051282          NaN           NaN         6.0    0.051282\n",
       "6       100.0      0.051282        100.0      0.179487       100.0    0.051282\n",
       "7         NaN           NaN          3.0      0.025641         NaN         NaN"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bge ranker finetune过后\n",
    "a = pd.DataFrame(result_T_loc)\n",
    "cols = a.columns.tolist()\n",
    "len_cols = [a[col].unique().shape[0] for col in cols]\n",
    "anchor = cols[np.argmax(len_cols)]\n",
    "stat = a[anchor].fillna(100).value_counts(\"mean\").sort_index().reset_index()\n",
    "for col in [col for col in cols if col != anchor]:\n",
    "    temp = a[col].fillna(100).value_counts(\"mean\").sort_index().reset_index()\n",
    "    stat = pd.merge(left=stat, right=temp, left_on=anchor, right_on=col, how=\"outer\")\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "341c8d4a-32c8-4d26-9614-b41cd71439f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>recall_bm25</th>\n",
       "      <th>recall_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall@1</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@2</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map</th>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.863095</td>\n",
       "      <td>0.810939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrr@10</th>\n",
       "      <td>0.835775</td>\n",
       "      <td>0.880189</td>\n",
       "      <td>0.827839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          recall_bge  recall_bm25  recall_all\n",
       "recall@1    0.820513     0.769231    0.743590\n",
       "recall@2    0.846154     0.769231    0.794872\n",
       "map         0.818681     0.863095    0.810939\n",
       "mrr@10      0.835775     0.880189    0.827839"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bge ranker finetune过后\n",
    "pd.DataFrame(result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "480070fb-a4ca-4f7b-a2cd-2b3fccaec089",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"reranking_bge\"] = pd.DataFrame(result_reranking)[\"recall_bge\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d363ba31-7770-4858-b19a-0a9012df19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"GT_rank_bge\"] = pd.DataFrame(result_T_loc)[\"recall_bge\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b1754d9-718d-4ddc-80ed-1a9cb9009d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GT_rank_bge\n",
       "0.0    32\n",
       "6.0     2\n",
       "1.0     1\n",
       "2.0     1\n",
       "4.0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[\"GT_rank_bge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "434a61d2-451c-40a9-80d7-48323ada9c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_positive</th>\n",
       "      <th>answer_positive</th>\n",
       "      <th>GT_rank_bge</th>\n",
       "      <th>recall_bge</th>\n",
       "      <th>reranking_bge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7S PLUS 错误一</td>\n",
       "      <td>[扫地机器人机器人报错误1激光头遮挡]</td>\n",
       "      <td>[1,引导客户提供报错时照片或视频，进一步确认；\\n*有贴膜，优先引导客户取下贴膜后再关机重...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243886', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202402061673', 'reason': 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>G10S不集尘</td>\n",
       "      <td>[为什么扫地机清扫结束没有自动集尘？]</td>\n",
       "      <td>[您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>G20不集尘</td>\n",
       "      <td>[为什么扫地机清扫结束没有自动集尘？]</td>\n",
       "      <td>[您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202307243982', 'reason': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>G10无法清洗拖布，请清理基座附近障碍物</td>\n",
       "      <td>[无法清洗拖布/回充失败/无法回充/不回基站]</td>\n",
       "      <td>[您好，基座未通电会出现上述情况，确认基座指示灯是否亮起；\\n（1）如不亮，参考话术：\\n关...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[{'result': 'ICWIKI202307243284', 'reason': 'm...</td>\n",
       "      <td>[{'result': 'ICWIKI202307243284', 'reason': 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question        question_positive  \\\n",
       "6           T7S PLUS 错误一      [扫地机器人机器人报错误1激光头遮挡]   \n",
       "18               G10S不集尘      [为什么扫地机清扫结束没有自动集尘？]   \n",
       "32                G20不集尘      [为什么扫地机清扫结束没有自动集尘？]   \n",
       "34  G10无法清洗拖布，请清理基座附近障碍物  [无法清洗拖布/回充失败/无法回充/不回基站]   \n",
       "\n",
       "                                      answer_positive  GT_rank_bge  \\\n",
       "6   [1,引导客户提供报错时照片或视频，进一步确认；\\n*有贴膜，优先引导客户取下贴膜后再关机重...          3.0   \n",
       "18  [您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...          6.0   \n",
       "32  [您好，若扫地机不能自动集尘，请按照以下操作排查：\\n（1）扫地机在勿扰模式期间不会主动集尘...          6.0   \n",
       "34  [您好，基座未通电会出现上述情况，确认基座指示灯是否亮起；\\n（1）如不亮，参考话术：\\n关...          3.0   \n",
       "\n",
       "                                           recall_bge  \\\n",
       "6   [{'result': 'ICWIKI202307243886', 'reason': 'm...   \n",
       "18  [{'result': 'ICWIKI202307243982', 'reason': 'm...   \n",
       "32  [{'result': 'ICWIKI202307243982', 'reason': 'm...   \n",
       "34  [{'result': 'ICWIKI202307243284', 'reason': 'm...   \n",
       "\n",
       "                                        reranking_bge  \n",
       "6   [{'result': 'ICWIKI202402061673', 'reason': 'c...  \n",
       "18  [{'result': 'ICWIKI202307243982', 'reason': 'm...  \n",
       "32  [{'result': 'ICWIKI202307243982', 'reason': 'm...  \n",
       "34  [{'result': 'ICWIKI202307243284', 'reason': 'm...  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"GT_rank_bge\"]>=3][[\"question\", \n",
    "                                              \"question_positive\", \n",
    "                                              \"answer_positive\", \n",
    "                                              \"GT_rank_bge\", \n",
    "                                              \"recall_bge\",\n",
    "                                              \"reranking_bge\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "030aa51a-bd29-4f1a-a1a0-e65c8d55402e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ICWIKI202307243886'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"GT_rank_bge\"]>=3].iloc[0].gt_qa_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b4acc753-b1f6-4862-9aa5-971e2c409d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'result': 'ICWIKI202402061673',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.78,\n",
       "  'relevant': False,\n",
       "  'recall_order': 6,\n",
       "  'ranking_score': 9.6875,\n",
       "  'ranking_order': 0,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 9,\n",
       "  'reranking_order': 0},\n",
       " {'result': 'ICWIKI202309040294',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.78,\n",
       "  'relevant': False,\n",
       "  'recall_order': 5,\n",
       "  'ranking_score': 9.6875,\n",
       "  'ranking_order': 1,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 8,\n",
       "  'reranking_order': 1},\n",
       " {'result': 'ICWIKI202307243887',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.78,\n",
       "  'relevant': False,\n",
       "  'recall_order': 7,\n",
       "  'ranking_score': 9.6796875,\n",
       "  'ranking_order': 2,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 7,\n",
       "  'reranking_order': 2},\n",
       " {'result': 'ICWIKI202307243886',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.77,\n",
       "  'relevant': True,\n",
       "  'recall_order': 0,\n",
       "  'ranking_score': 6.08203125,\n",
       "  'ranking_order': 3,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 6,\n",
       "  'reranking_order': 3},\n",
       " {'result': 'ICWIKI202307244160',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.66,\n",
       "  'relevant': False,\n",
       "  'recall_order': 8,\n",
       "  'ranking_score': -4.98828125,\n",
       "  'ranking_order': 4,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 5,\n",
       "  'reranking_order': 4},\n",
       " {'result': 'ICWIKI202307260010',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 2,\n",
       "  'ranking_score': -6.5546875,\n",
       "  'ranking_order': 5,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 4,\n",
       "  'reranking_order': 5},\n",
       " {'result': 'ICWIKI202307260006',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 3,\n",
       "  'ranking_score': -6.640625,\n",
       "  'ranking_order': 6,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 3,\n",
       "  'reranking_order': 6},\n",
       " {'result': 'ICWIKI202308090052',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.63,\n",
       "  'relevant': False,\n",
       "  'recall_order': 1,\n",
       "  'ranking_score': -6.87890625,\n",
       "  'ranking_order': 7,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 2,\n",
       "  'reranking_order': 7},\n",
       " {'result': 'ICWIKI202307260011',\n",
       "  'reason': 'model|cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 4,\n",
       "  'ranking_score': -6.9375,\n",
       "  'ranking_order': 8,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 1,\n",
       "  'reranking_order': 8},\n",
       " {'result': 'ICWIKI202307243883',\n",
       "  'reason': 'cat',\n",
       "  'similarities': 0.62,\n",
       "  'relevant': False,\n",
       "  'recall_order': 9,\n",
       "  'ranking_score': -7.01171875,\n",
       "  'ranking_order': 9,\n",
       "  'if_special': 0,\n",
       "  'if_top': False,\n",
       "  'reranking_score': 0,\n",
       "  'reranking_order': 9}]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result[final_result[\"GT_rank_bge\"]>=3].iloc[0].reranking_bge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "acb4b5a3-d502-4d30-9519-8202dccb8787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa_type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model</th>\n",
       "      <th>effective</th>\n",
       "      <th>update_by</th>\n",
       "      <th>update_time</th>\n",
       "      <th>model_list</th>\n",
       "      <th>model_num</th>\n",
       "      <th>model_id</th>\n",
       "      <th>cat_name</th>\n",
       "      <th>ada_002</th>\n",
       "      <th>bge_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>ICWIKI202307243916</td>\n",
       "      <td>故障问题</td>\n",
       "      <td>扫地机拖地出水少不出水</td>\n",
       "      <td>1，引导客户查看拖布是否安装到位并正常工作，拖地时完全打湿拖布，安装好后使用观察\\n2，取出...</td>\n",
       "      <td>G10S, P10, G20, T7S, T7SPlus, G10, G10Plus, T8...</td>\n",
       "      <td>2023-09-11 11:24:01 已生效</td>\n",
       "      <td>王鹏程</td>\n",
       "      <td>2023-09-11 11:24:00.000000</td>\n",
       "      <td>g10s,p10,g20,t7s,t7splus,g10,g10plus,t8,t8plus...</td>\n",
       "      <td>12</td>\n",
       "      <td>ICMU025,ICMU028,ICMU030,ICMU017,ICMU018,ICMU01...</td>\n",
       "      <td>扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机</td>\n",
       "      <td>[-0.018422875553369522, -0.010261740535497665,...</td>\n",
       "      <td>[0.017396926879882812, -0.017865771427750587, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  qa_id qa_type     question  \\\n",
       "743  ICWIKI202307243916    故障问题  扫地机拖地出水少不出水   \n",
       "\n",
       "                                                answer  \\\n",
       "743  1，引导客户查看拖布是否安装到位并正常工作，拖地时完全打湿拖布，安装好后使用观察\\n2，取出...   \n",
       "\n",
       "                                                 model  \\\n",
       "743  G10S, P10, G20, T7S, T7SPlus, G10, G10Plus, T8...   \n",
       "\n",
       "                   effective update_by                 update_time  \\\n",
       "743  2023-09-11 11:24:01 已生效       王鹏程  2023-09-11 11:24:00.000000   \n",
       "\n",
       "                                            model_list  model_num  \\\n",
       "743  g10s,p10,g20,t7s,t7splus,g10,g10plus,t8,t8plus...         12   \n",
       "\n",
       "                                              model_id  \\\n",
       "743  ICMU025,ICMU028,ICMU030,ICMU017,ICMU018,ICMU01...   \n",
       "\n",
       "                                            cat_name  \\\n",
       "743  扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机,扫地机   \n",
       "\n",
       "                                               ada_002  \\\n",
       "743  [-0.018422875553369522, -0.010261740535497665,...   \n",
       "\n",
       "                                             bge_large  \n",
       "743  [0.017396926879882812, -0.017865771427750587, ...  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.qa_id==\"ICWIKI202307243916\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
