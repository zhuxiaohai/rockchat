{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T14:11:06.959071886Z",
     "start_time": "2024-03-28T14:11:00.676852853Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pandasql import sqldf\n",
    "import re\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "import joblib\n",
    "import json \n",
    "import jieba \n",
    "import copy\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import matplotlib.pyplot as plt \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from FlagEmbedding import FlagReranker\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3c94a74b02eeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:46.162727178Z",
     "start_time": "2024-03-25T06:02:46.099330239Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# pandasql查询函数需要的环境\n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a367387e-f525-4599-912c-c68be7331cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:46.614837917Z",
     "start_time": "2024-03-25T06:02:46.594416571Z"
    }
   },
   "outputs": [],
   "source": [
    "# 原始数据处理\n",
    "def format_model(x):\n",
    "    model_list = x.split(',')\n",
    "    model_list = [i.strip().lower() for i in model_list]\n",
    "    new_list = [model_list[0]]\n",
    "    i = 1\n",
    "    while i < len(model_list):\n",
    "        if (i != len(model_list) - 1) and (model_list[i-1] == model_list[i]):\n",
    "            new_list.append(model_list[i]+model_list[i+1])\n",
    "            if i < len(model_list) - 1:\n",
    "                i += 2\n",
    "            else:\n",
    "                break\n",
    "        elif (i != len(model_list) - 1) and (model_list[i-1] != model_list[i]):\n",
    "            new_list.append(model_list[i])\n",
    "            i += 1\n",
    "        elif (model_list[i] == \"上下水\") or (model_list[i] == \"air\"):\n",
    "            for j in range(len(new_list)):\n",
    "                if model_list[i-1] == new_list[j]:\n",
    "                    new_list.pop(j)\n",
    "                    break\n",
    "            new_list.append(model_list[i-1]+model_list[i])\n",
    "            i += 1\n",
    "        else:\n",
    "            new_list.append(model_list[i])\n",
    "            break\n",
    "    return new_list\n",
    "\n",
    "def format_all_models(x, dim_df):\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"全型号\") >= 0:\n",
    "            end_idx = i.find(\"全型号\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[dim_df['cat_name'] == name].model.tolist() if j not in x]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list\n",
    "\n",
    "def format_series(x, dim_df):\n",
    "    def contains_chinese(s):\n",
    "        return re.search('[\\u4e00-\\u9fff]', s) is not None\n",
    "    new_list = []\n",
    "    for i in x:\n",
    "        if i.find(\"系列\") >= 0:\n",
    "            end_idx = i.find(\"系列\")\n",
    "            name = i[:end_idx]\n",
    "            new_list += [j for j in dim_df[(dim_df.model.str.find(name)>=0) & (\n",
    "                dim_df.model.apply(lambda x: not contains_chinese(x)))].model.tolist() if j not in x]\n",
    "            new_list += [i]\n",
    "        else:\n",
    "            new_list.append(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ec7f8a-e9c3-48b5-9dbf-b26fb5045320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:47.275074278Z",
     "start_time": "2024-03-25T06:02:47.228000273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 拼接openai embedding\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16717201-59cd-412f-9e3d-f2b2a5592356",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:47.759486977Z",
     "start_time": "2024-03-25T06:02:47.702318041Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集处理及计算与正确qa的相似度\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def search_docs(df, user_query, top_n=4, to_print=True):\n",
    "    embedding = generate_embeddings(\n",
    "        user_query,\n",
    "    )\n",
    "    df[\"similarities\"] = df.ada_002.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[[\"qa_id\", \"question\", \"answer\", \"similarities\"]]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def concat(x):\n",
    "    return \",\".join(x.astype(str).tolist())\n",
    "\n",
    "def format_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return x\n",
    "    else:\n",
    "        return \",\".join(x.split(\"\\n\"))\n",
    "\n",
    "def count_gt(x):\n",
    "    if str(x) == \"nan\":\n",
    "        return 0\n",
    "    else:\n",
    "        return len(x.split(\",\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cce4679-0c44-45a8-89dd-808f7a33977d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T06:02:48.269259251Z",
     "start_time": "2024-03-25T06:02:48.231943506Z"
    }
   },
   "outputs": [],
   "source": [
    "# 向量召回\n",
    "# def search_docs_bge(df, user_query, top_n=4, to_print=True):\n",
    "#     embedding = model.encode(user_query, normalize_embeddings=True).tolist()\n",
    "#     df[\"similarities\"] = df.bge_large.apply(lambda x: cosine_similarity(x, embedding))\n",
    "#     output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "#     if \"hit_reason\" in df.columns:\n",
    "#         output_columns.append(\"hit_reason\")\n",
    "#     res = (\n",
    "#         df.sort_values(\"similarities\", ascending=False)\n",
    "#         .head(top_n)\n",
    "#     )[output_columns]\n",
    "#     return res.to_dict(orient='records')\n",
    "\n",
    "def search_docs_bge(df, user_query, top_n=4, to_print=True, add_instruction=False):\n",
    "    df = df.copy()\n",
    "    # if add_instruction:\n",
    "    #     instruction = \"为这个句子生成表示以用于检索相关文章：\"\n",
    "    #     user_query = instruction+user_query\n",
    "    embedding = model.encode_queries(user_query, max_length=96).tolist()\n",
    "    df[\"similarities\"] = df.bge_large.apply(lambda x: cosine_similarity(x, embedding))\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')\n",
    "\n",
    "def find_non_chinese_substrings(s):\n",
    "    # 正则表达式解释：\n",
    "    # [^\\u4e00-\\u9fff\\W]+ 匹配非中文字符和非ASCII标点的连续字符\n",
    "    # 但这样会排除空格，所以我们需要允许空格存在\n",
    "    # 我们使用(?:[^\\u4e00-\\u9fff\\W]| )+ 来实现这一点，(?:) 是非捕获组，用于匹配模式但不作为捕获结果返回\n",
    "    # [^\\u4e00-\\u9fff\\W] 匹配非中文且非标点的字符，| 表示或，空格 ' ' 被显式允许\n",
    "    pattern = r'(?:[^\\u4e00-\\u9fff\\W]| )+'\n",
    "    \n",
    "    # 使用findall方法查找所有匹配项\n",
    "    matches = re.findall(pattern, s)\n",
    "    \n",
    "    # 过滤掉只包含空格的字符串\n",
    "    matches = [match for match in matches if not match.isspace()]\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def clean_string(s):\n",
    "    s = s.replace(\" \", \"\").lower()\n",
    "    return s\n",
    "\n",
    "def find_model(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    x = find_non_chinese_substrings(x)\n",
    "    result = [clean_string(s) for s in x]\n",
    "    return [model for model in all_model_list if model in result]\n",
    "\n",
    "def find_cat(x, all_cat_list):\n",
    "    return [name for name in all_cat_list if name in x]   \n",
    "\n",
    "def filter_model(x, model_list):\n",
    "    x = x.split(\",\")\n",
    "    for model in model_list:\n",
    "        if model in x:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def find_error_with_reason(a):\n",
    "    # 第一次匹配“错误xxx”\n",
    "    pattern1 = r\"错误\\s*\\d+\"\n",
    "    matches1 = re.findall(pattern1, a)\n",
    "    \n",
    "    # 第二次匹配“错误原因xxx”\n",
    "    pattern2 = r\"错误原因\\s*\\d+\"\n",
    "    matches2 = re.findall(pattern2, a)\n",
    "\n",
    "    # 合并两次匹配的结果\n",
    "    matches = matches1 + matches2\n",
    "    \n",
    "    return [name.replace(\" \", \"\").replace(\"原因\", \"\") for name in matches]\n",
    "\n",
    "def filter_reason(x, query_reason_list):\n",
    "    reason_list = find_error_with_reason(x)\n",
    "    for name in query_reason_list:\n",
    "        if name in reason_list:\n",
    "            return True \n",
    "    return False\n",
    "\n",
    "def transform_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        cleaned_name = clean_string(name)\n",
    "        for model in all_model_list:\n",
    "            if cleaned_name == model:\n",
    "                x = x.replace(name, model)\n",
    "                break\n",
    "    return x \n",
    "\n",
    "def remove_model_name(x, all_model_list):\n",
    "    x = x.replace(\"\\n\", \"\") \n",
    "    candidates = find_non_chinese_substrings(x)\n",
    "    for name in candidates:\n",
    "        if clean_string(name) in all_model_list:\n",
    "            x = x.replace(name, \"\")\n",
    "    return x \n",
    "\n",
    "class BM25_Model(object):\n",
    "    def __init__(self, documents_list, k1=2, k2=1, b=0.5):\n",
    "        self.documents_list = documents_list\n",
    "        self.documents_number = len(documents_list)\n",
    "        self.avg_documents_len = sum([len(document) for document in documents_list]) / self.documents_number\n",
    "        self.f = []\n",
    "        self.idf = {}\n",
    "        self.k1 = k1\n",
    "        self.k2 = k2\n",
    "        self.b = b\n",
    "        self.init()\n",
    "\n",
    "    def init(self):\n",
    "        df = {}\n",
    "        for document in self.documents_list:\n",
    "            temp = {}\n",
    "            for word in document:\n",
    "                temp[word] = temp.get(word, 0) + 1\n",
    "            self.f.append(temp)\n",
    "            for key in temp.keys():\n",
    "                df[key] = df.get(key, 0) + 1\n",
    "        for key, value in df.items():\n",
    "            self.idf[key] = np.log((self.documents_number - value + 0.5) / (value + 0.5))\n",
    "\n",
    "    def get_score(self, index, query):\n",
    "        score = 0.0\n",
    "        document_len = len(self.f[index])\n",
    "        qf = Counter(query)\n",
    "        for q in query:\n",
    "            if q not in self.f[index]:\n",
    "                continue\n",
    "            score += self.idf[q] * (self.f[index][q] * (self.k1 + 1) / (\n",
    "                        self.f[index][q] + self.k1 * (1 - self.b + self.b * document_len / self.avg_documents_len))) * (\n",
    "                                 qf[q] * (self.k2 + 1) / (qf[q] + self.k2))\n",
    "\n",
    "        return score\n",
    "\n",
    "    def get_documents_score(self, query, indices):\n",
    "        score_list = []\n",
    "        for i in indices:\n",
    "            score_list.append(self.get_score(i, query))\n",
    "        return score_list\n",
    "\n",
    "\n",
    "class WordCut:\n",
    "    def __init__(self, all_model_list=None):\n",
    "        with open('/data/dataset/kefu/hit_stopwords.txt', encoding='utf-8') as f: # 可根据需要打开停用词库，然后加上不想显示的词语\n",
    "            con = f.readlines()\n",
    "            stop_words = set()\n",
    "            for i in con:\n",
    "                i = i.replace(\"\\n\", \"\")   # 去掉读取每一行数据的\\n\n",
    "                stop_words.add(i)\n",
    "        self.stop_words = stop_words\n",
    "        self.all_model_list = all_model_list\n",
    "        \n",
    "    def cut(self, mytext):\n",
    "        # jieba.load_userdict('自定义词典.txt')  # 这里你可以添加jieba库识别不了的网络新词，避免将一些新词拆开\n",
    "        # jieba.initialize()  # 初始化jieba\n",
    "        # 文本预处理 ：去除一些无用的字符只提取出中文出来\n",
    "        # new_data = re.findall('[\\u4e00-\\u9fa5]+', mytext, re.S)\n",
    "        # new_data = \" \".join(new_data)\n",
    "        # 匹配中英文标点符号，以及全角和半角符号\n",
    "        pattern = r'[\\u3000-\\u303f\\uff01-\\uff0f\\uff1a-\\uff20\\uff3b-\\uff40\\uff5b-\\uff65\\u2018\\u2019\\u201c\\u201d\\u2026\\u00a0\\u2022\\u2013\\u2014\\u2010\\u2027\\uFE10-\\uFE1F\\u3001-\\u301E]|[\\.,!¡?¿\\-—_(){}[\\]\\'\\\";:/]'\n",
    "        # 使用 re.sub 替换掉符合模式的字符为空字符\n",
    "        new_data = re.sub(pattern, '', mytext)\n",
    "        new_data = transform_model_name(new_data, self.all_model_list)\n",
    "        # 文本分词\n",
    "        seg_list_exact = jieba.lcut(new_data)\n",
    "        result_list = []\n",
    "        # 去除停用词并且去除单字\n",
    "        for word in seg_list_exact:\n",
    "            if word not in self.stop_words and len(word) > 1:\n",
    "                result_list.append(word) \n",
    "        return result_list\n",
    "\n",
    "def search_docs_bm25(df, indices, user_query, top_n=4):\n",
    "    # document_list = [wc.cut(doc) for doc in df.question]\n",
    "    # bm25_model = BM25_Model(document_list)\n",
    "    embedding = wc.cut(user_query)\n",
    "    df[\"similarities\"] = bm25_model.get_documents_score(embedding, indices)\n",
    "    output_columns = [\"qa_id\", \"question\", \"answer\", \"similarities\"]\n",
    "    if \"hit_reason\" in df.columns:\n",
    "        output_columns.append(\"hit_reason\")\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )[output_columns]\n",
    "    return res.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82256265-3637-4f14-8fad-ff436810319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 综合分析\n",
    "def ranking_metric(x):\n",
    "    if (x.find(\"error\")>=0) and (x.find(\"model\")>=0):\n",
    "        return 1 \n",
    "    elif (x.find(\"error\")>=0) and (x.find(\"cat\")>=0):\n",
    "        return 2 \n",
    "    elif (x.find(\"error\")>=0):\n",
    "        return 3 \n",
    "    elif (x.find(\"model\")>=0):\n",
    "        return 4\n",
    "    elif (x.find(\"cat\")>=0):\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "def mine_hard_negative(x, similarities, reason, result, positive):\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = pd.DataFrame(x[[similarities, reason, result]].to_dict())\n",
    "    df = df[~df[result].isin(positives)]\n",
    "    df[\"ranking\"] = df[reason].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", similarities], ascending=[True, False])\n",
    "    df = df.drop_duplicates(result)\n",
    "    df = df.iloc[:10]\n",
    "    return pd.Series({col+\"_hard\": df[col].values.tolist() for col in [similarities, reason, result]})\n",
    "\n",
    "def format_result(x, similarities, reason, result):\n",
    "    num_result = len(x[result])\n",
    "    new_set = dict()\n",
    "    for j in range(num_result):\n",
    "        result_name = x[result][j]\n",
    "        sim = x[similarities][j]\n",
    "        reason_code = x[reason][j]\n",
    "        if result_name in new_set:\n",
    "            if (ranking_metric(reason_code) <= ranking_metric(new_set[result_name][\"reason\"])\n",
    "               ) & (sim > new_set[result_name][\"similarities\"]):\n",
    "                new_set.update({result_name: {\"similarities\": sim, \"reason\": reason_code}})\n",
    "        else:\n",
    "            new_set.update({result_name: {\"similarities\": sim, \"reason\": reason_code}})\n",
    "    df = pd.DataFrame(new_set).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def merge_recall(x, recall_list, weights):\n",
    "    pool = {}\n",
    "    for i in range(len(weights)):\n",
    "        weight = weights[i] \n",
    "        recall_name = recall_list[i]\n",
    "        num_results = len(x[recall_name])\n",
    "        for j in range(num_results):\n",
    "            result_item = x[recall_name][j]\n",
    "            result = result_item[\"result\"]\n",
    "            if result in pool:\n",
    "                if ranking_metric(result_item['reason']) < ranking_metric(pool[result]['reason']):\n",
    "                    reason = result_item['reason']\n",
    "                    pool[result]['reason'] = reason\n",
    "                pool[result]['similarities'] += weight * result_item['similarities'] / sum(weights)\n",
    "                pool[result]['full_reason'] = pool[result]['full_reason']+\",\"+result_item['reason']+\"_\"+recall_name\n",
    "            else:\n",
    "                pool[result]= {\n",
    "                    \"reason\": result_item['reason'],\n",
    "                    \"similarities\": weight * result_item['similarities'] / sum(weights),\n",
    "                    \"full_reason\": result_item['reason']+\"_\"+recall_name\n",
    "                              }\n",
    "    df = pd.DataFrame(pool).T.reset_index().rename(columns={\"index\": \"result\"})\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    return df[['result', 'reason', 'full_reason', 'similarities']].to_dict(orient='records')\n",
    "\n",
    "def mine_hard_negative2(x, recall, top_n, positive, output_cols):\n",
    "    df = pd.DataFrame(x[recall])\n",
    "    positives = x[positive].split(\",\")\n",
    "    df = df[~df[\"result\"].isin(positives)]\n",
    "    df[\"ranking\"] = df[\"reason\"].apply(lambda x: ranking_metric(x))\n",
    "    df = df.sort_values([\"ranking\", \"similarities\"], ascending=[True, False])\n",
    "    df = df.iloc[:top_n]\n",
    "    return df[output_cols].to_dict(orient='records')  \n",
    "\n",
    "def split_recall(x, output_cols, new_cols):\n",
    "    df = pd.DataFrame(x)\n",
    "    return pd.Series({new_col: df[col].values.tolist() \n",
    "                      for col, new_col in zip(output_cols, new_cols)})\n",
    "\n",
    "def find_score_limit(x):\n",
    "    min_all = float(\"inf\")\n",
    "    max_all = float(\"-inf\")\n",
    "    for i in range(len(x)):\n",
    "        min_i = min(x[i])\n",
    "        max_i = max(x[i])\n",
    "        min_all = min(min_all, min_i)\n",
    "        max_all = max(max_all, max_i)\n",
    "    return min_all, max_all\n",
    "\n",
    "def convert_limit(x, min_all, max_all):\n",
    "    return [(i-min_all)/(max_all-min_all) for i in x]\n",
    "\n",
    "def convert_df_to_jsonl(df, filename, query=\"question_cleaned\", pos_col=\"question_positive\", neg_col=\"question_bge_hard\"):\n",
    "    with open(filename, 'w') as file:\n",
    "        for _, row in df.iterrows():\n",
    "            # Constructing the dictionary for each row\n",
    "            data = {\n",
    "                \"query\": row[query],\n",
    "                \"pos\": row[pos_col],\n",
    "                \"neg\": row[neg_col]\n",
    "            }\n",
    "            # Writing the JSON string followed by a newline character to make it JSONL\n",
    "            file.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1a11e3-d608-41ef-a2ea-d33f675bc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序\n",
    "def mrr_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    mrr_score = 0\n",
    "    for rank, index in enumerate(pred_ranking[:k]):\n",
    "        if is_relevant[index]:\n",
    "            mrr_score = 1 / (rank + 1)\n",
    "            break\n",
    "\n",
    "    return mrr_score\n",
    "\n",
    "def recall_at_k_score(is_relevant, pred_ranking, k):\n",
    "    \"\"\"\n",
    "    Computes MRR@k score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_ranking (`List[int]` of length `num_pos+num_neg`): Indices of the documents sorted in decreasing order\n",
    "            of the similarity score\n",
    "\n",
    "    Returns:\n",
    "        mrr_score (`float`): MRR@k score\n",
    "    \"\"\"\n",
    "    recall_score = 0\n",
    "    for index in pred_ranking[:k]:\n",
    "        if is_relevant[index]:\n",
    "            recall_score = 1\n",
    "            break\n",
    "\n",
    "    return recall_score\n",
    "\n",
    "def ap_score(is_relevant, pred_scores):\n",
    "    \"\"\"\n",
    "    Computes AP score\n",
    "\n",
    "    Args:\n",
    "        is_relevant (`List[bool]` of length `num_pos+num_neg`): True if the document is relevant\n",
    "        pred_scores (`List[float]` of length `num_pos+num_neg`): Predicted similarity scores\n",
    "\n",
    "    Returns:\n",
    "        ap_score (`float`): AP score\n",
    "    \"\"\"\n",
    "    # preds = np.array(is_relevant)[pred_scores_argsort]\n",
    "    # precision_at_k = np.mean(preds[:k])\n",
    "    # ap = np.mean([np.mean(preds[: k + 1]) for k in range(len(preds)) if preds[k]])\n",
    "    ap = average_precision_score(is_relevant, pred_scores)\n",
    "    return ap\n",
    "\n",
    "def compute_recall_score(df, model, query, recall):\n",
    "    pairs = []\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        for p in sample[recall]:\n",
    "            pairs.append([sample[query], p])\n",
    "    all_scores = model.compute_score(pairs)\n",
    "    result = []\n",
    "    start_inx = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        pred_scores = all_scores[start_inx:start_inx + len(sample[recall])]\n",
    "        result.append(pred_scores)\n",
    "        start_inx += len(sample[recall])\n",
    "    return result\n",
    "\n",
    "def compute_metrics_batched_from_crossencoder(df, score, relevant, \n",
    "                                              mrr_at_k=10, recall_at_list=[1,2], metrics=[\"map\", \"mrr\", \"recall\"]):\n",
    "    all_mrr_scores = []\n",
    "    all_ap_scores = []\n",
    "    all_recall_scores = [[] for _ in range(len(recall_at_list))]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        sample = df.iloc[i]\n",
    "        is_relevant = sample[relevant]\n",
    "        pred_scores = np.array(sample[score])\n",
    "\n",
    "        pred_scores_argsort = np.argsort(-pred_scores)  # Sort in decreasing order\n",
    "        if \"mrr\" in metrics:\n",
    "            mrr = mrr_at_k_score(is_relevant, pred_scores_argsort, mrr_at_k)\n",
    "            all_mrr_scores.append(mrr)\n",
    "        if \"map\" in metrics:\n",
    "            ap = ap_score(is_relevant, pred_scores)\n",
    "            all_ap_scores.append(ap)\n",
    "        if \"recall\" in metrics:\n",
    "            for recall_index, recall_at in enumerate(recall_at_list):\n",
    "                recall_score = recall_at_k_score(is_relevant, pred_scores_argsort, recall_at)\n",
    "                all_recall_scores[recall_index].append(recall_score)\n",
    "\n",
    "    result = {}\n",
    "    if \"map\" in metrics:\n",
    "        mean_ap = np.mean(all_ap_scores)\n",
    "        result[\"map\"] = mean_ap\n",
    "    if \"mrr\" in metrics:\n",
    "        mean_mrr = np.mean(all_mrr_scores)\n",
    "        result[f\"mrr@{mrr_at_k}\"] = mean_mrr\n",
    "    if \"recall\" in metrics:\n",
    "        for recall_index, recall_at in enumerate(recall_at_list):\n",
    "            result[f\"recall@{recall_at}\"] = np.mean(all_recall_scores[recall_index])\n",
    "    return result\n",
    "\n",
    "def find_T_loc(x, relevant, score):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    for rank, index in enumerate(pred_scores_argsort):\n",
    "        if is_relevant[index]:\n",
    "            return rank\n",
    "    return np.nan\n",
    "\n",
    "def get_reranking(x, relevant, score, recall, reason, postranking=False):\n",
    "    is_relevant = x[relevant]\n",
    "    pred_scores = np.array(x[score])\n",
    "    pred_scores_argsort = np.argsort(-pred_scores)\n",
    "    recall_list = copy.deepcopy(x[recall])\n",
    "    for index, i in enumerate(recall_list):\n",
    "        i.update({\"relevant\": is_relevant[index], \"recall_order\": index})\n",
    "    reranking = []\n",
    "    for index, i in enumerate(pred_scores_argsort):\n",
    "        temp = recall_list[i]\n",
    "        temp.update({\"ranking_score\": pred_scores[i], \"ranking_order\": index})\n",
    "        reranking.append(temp)\n",
    "    if postranking:\n",
    "        reranking = pd.DataFrame(reranking)\n",
    "        reranking[\"if_special\"] = reranking[reason].apply(\n",
    "            lambda x: (x.find(\"model\") >= 0)|(x.find(\"error\") >= 0)|(len(x.split(\",\"))>1)).astype(int)\n",
    "        reranking.loc[(reranking[\"if_special\"]==1)&(reranking[\"similarities\"]<=0.75), \"if_special\"] = 0\n",
    "        reranking[\"ranking\"] = reranking[reason].apply(lambda x: ranking_metric(x))\n",
    "        top_list = reranking[reranking[\"if_special\"]==1].sort_values(\n",
    "            [\"if_special\", \"ranking\", \"similarities\"], ascending=[False, True, False])[\"result\"].iloc[:2].tolist()\n",
    "        reranking[\"if_top\"] = reranking[\"result\"].isin(top_list)\n",
    "        reranking = pd.concat([reranking[reranking[\"if_top\"]==True], reranking[reranking[\"if_top\"]==False]], axis=0).reset_index(drop=True)\n",
    "        reranking[\"reranking_score\"] = list(range(reranking.shape[0]))[::-1]\n",
    "        reranking[\"reranking_order\"] = list(range(reranking.shape[0]))\n",
    "        reranking = reranking.drop(\"ranking\", axis=1)\n",
    "        reranking = reranking.to_dict(orient=\"records\")\n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d514496-9b26-4fa1-bba4-35bb6ff63345",
   "metadata": {},
   "source": [
    "# 向量召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "664df7cf0601055b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:38.687361618Z",
     "start_time": "2024-03-21T11:33:38.519915254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "oot = pd.read_csv(\"/data/dataset/kefu/oot20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7641a473-b5b1-4837-b39f-bed036db6b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:40.730909535Z",
     "start_time": "2024-03-21T11:33:39.108590586Z"
    }
   },
   "outputs": [],
   "source": [
    "# test = pd.read_csv(\"/data/dataset/kefu/test20240315.csv\")\n",
    "# df1 = pd.read_csv(\"/data/dataset/kefu/database_before_online_with_emb.csv\")\n",
    "df2 = pd.read_csv(\"/data/dataset/kefu/database_with_emb20240315.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec85ec5-d2fd-4b5d-a728-f7c39ca7821b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:52:22.903675555Z",
     "start_time": "2024-03-22T01:52:15.663951567Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 95/95 [01:20<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer('/data/dataset/huggingface/hub/bge-large-zh-v1.5')\n",
    "# model = SentenceTransformer('/workspace/data/private/zhuxiaohai/models/bge_emb_finetune_from_db/checkpoint-400')\n",
    "from FlagEmbedding import FlagModel\n",
    "model = FlagModel('/workspace/data/private/zhuxiaohai/models/bge_emb_finetune_from_db', \n",
    "                  query_instruction_for_retrieval=\"为这个句子生成表示以用于检索相关文章：\",\n",
    "                  use_fp16=False) \n",
    "# q_embeddings = model.encode(df1.question.tolist(), normalize_embeddings=True, batch_size=32)\n",
    "# df1['bge_large'] = q_embeddings.tolist()\n",
    "q_embeddings = model.encode(df2.answer.tolist(), batch_size=32)\n",
    "df2['bge_large'] = q_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0b4806-c61d-4d77-b6ae-49f686830eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df2[df2.answer.apply(lambda x: True if x.lower().strip()[:10].find(\"http\")<0 else False)]\n",
    "# df2 = df2[df2.question.apply(lambda x: True if x.lower().strip().find(\"开箱图\")<0 else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8137af06-7808-42e6-9f65-38e5492aae29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T11:33:49.128203734Z",
     "start_time": "2024-03-21T11:33:49.055985301Z"
    }
   },
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(\"/data/dataset/kefu/dim_df20240315.csv\")\n",
    "all_model_list = dim_df.model.tolist()\n",
    "all_cat_list = dim_df.cat_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2679e67b-764b-4b97-bf55-25f71ddfceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = oot.copy()\n",
    "df1 = df2.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d397df-52cb-4143-921c-de8c1a3113d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test.sample(40)\n",
    "# test[\"gt_qa_id\"] = test['qa_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b109ba5-c061-4615-a5b1-738d8e856844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签+向量3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65854ddd9779e874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:43:54.549725297Z",
     "start_time": "2024-03-22T01:36:06.607606216Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.3076923076923077\n",
      "4 0.5897435897435898\n",
      "6 0.6153846153846154\n",
      "8 0.6923076923076923\n",
      "10 0.7435897435897436\n",
      "12 0.7948717948717948\n",
      "14 0.8205128205128205\n",
      "16 0.8461538461538461\n",
      "18 0.8461538461538461\n",
      "20 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "top_list = range(2, 22, 2)\n",
    "acc_list = []\n",
    "for top_n in top_list:\n",
    "    def sub_worker(result, score, reason, top_n):\n",
    "        if (filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)).sum() > 0:\n",
    "            aug_mask = filter_mask & (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            \n",
    "            aug_mask = filter_mask & (~(reason_indicator.str.find(\"errorcode\")>=0))\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "        else:\n",
    "            aug_mask = filter_mask\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "            \n",
    "            aug_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "            if aug_mask.sum() > 0:\n",
    "                filtered_df = df1[aug_mask].copy()\n",
    "                filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "                res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "                result += [j[\"qa_id\"] for j in res]\n",
    "                score += [round(j[\"similarities\"], 2) for j in res]\n",
    "                reason += [j[\"hit_reason\"] for j in res]\n",
    "    \n",
    "        aug_mask = (~filter_mask) & (reason_indicator.str.find(\"cat\")>=0)\n",
    "        if aug_mask.sum() > 0:\n",
    "            filtered_df = df1[aug_mask].copy()\n",
    "            filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "            res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "            result += [j[\"qa_id\"] for j in res]\n",
    "            score += [round(j[\"similarities\"], 2) for j in res]\n",
    "            reason += [j[\"hit_reason\"] for j in res]\n",
    "        return result, score, reason\n",
    "    label = []\n",
    "    result_list = []\n",
    "    for i in range(test.shape[0]):\n",
    "        gt = test['gt_qa_id'].iloc[i].split(\",\")\n",
    "        question = test['question'].iloc[i]\n",
    "        model_list = find_model(question, all_model_list)\n",
    "        cat_list = find_cat(question, all_cat_list)   \n",
    "        cat_list += [cat for cat in dim_df.loc[dim_df.model.isin(model_list), 'cat_name'].tolist() if cat not in cat_list]\n",
    "        reason_list = find_error_with_reason(question)\n",
    "        model_mask = (df1.model_list.apply(lambda x: filter_model(x, model_list)))\n",
    "        cat_mask = (df1.cat_name.apply(lambda x: filter_model(x, cat_list)))\n",
    "        reason_mask = (df1.question.apply(lambda x: filter_reason(x, reason_list)))\n",
    "        reason_indicator = pd.Series([\"none\"]*df1.shape[0], index=df1.index)\n",
    "        reason_indicator[model_mask] = reason_indicator[model_mask].apply(lambda x: x + \"|model\" if x != \"none\" else \"model\")\n",
    "        reason_indicator[cat_mask] = reason_indicator[cat_mask].apply(lambda x: x + \"|cat\" if x != \"none\" else \"cat\")\n",
    "        reason_indicator[reason_mask] = reason_indicator[reason_mask].apply(lambda x: x + \"|errorcode\" if x != \"none\" else \"errorcode\")\n",
    "        result = []\n",
    "        score = []\n",
    "        reason = []\n",
    "        # question = remove_model_name(question, all_model_list)\n",
    "        filter_mask = (reason_indicator.str.find(\"model\")>=0)\n",
    "        if filter_mask.sum() > 0:\n",
    "            result, score, reason = sub_worker(result, score, reason, top_n)\n",
    "        else:\n",
    "            filter_mask = (reason_indicator.str.find(\"cat\")>=0)   \n",
    "            if filter_mask.sum() > 0:\n",
    "                result, score, reason = sub_worker(result, score, reason, top_n)\n",
    "        if len(result) == 0:\n",
    "            filter_mask = (reason_indicator.str.find(\"errorcode\")>=0)\n",
    "            if filter_mask.sum() > 0:\n",
    "                aug_mask = filter_mask\n",
    "                filtered_df = df1[aug_mask].copy()\n",
    "                filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "                res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "                result += [j[\"qa_id\"] for j in res]\n",
    "                score += [round(j[\"similarities\"], 2) for j in res]\n",
    "                reason += [j[\"hit_reason\"] for j in res]  \n",
    "                aug_mask = (~filter_mask)\n",
    "                filtered_df = df1[aug_mask].copy()\n",
    "                filtered_df[\"hit_reason\"] = reason_indicator[aug_mask].copy()\n",
    "                res = search_docs_bge(filtered_df, question, top_n=int(top_n/2), add_instruction=True)\n",
    "                result += [j[\"qa_id\"] for j in res]\n",
    "                score += [round(j[\"similarities\"], 2) for j in res]\n",
    "                reason += [j[\"hit_reason\"] for j in res]  \n",
    "            else:\n",
    "                filtered_df = df1.copy()\n",
    "                filtered_df[\"hit_reason\"] = reason_indicator.copy()\n",
    "                res = search_docs_bge(filtered_df, question, top_n=top_n, add_instruction=True)\n",
    "                result += [j[\"qa_id\"] for j in res]\n",
    "                score += [round(j[\"similarities\"], 2) for j in res]\n",
    "                reason += [j[\"hit_reason\"] for j in res]\n",
    "        \n",
    "        found = False\n",
    "        for j in result:\n",
    "            if j in gt:\n",
    "                found = True\n",
    "                break \n",
    "        if found:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "        result_list.append({\"qa_id\": test['qa_id'].iloc[i], \n",
    "                            \"result\": result, \n",
    "                            \"similarities\": score, \n",
    "                            \"hit_reason\": reason, \n",
    "                            \"label\": int(found)})\n",
    "    acc_list.append(sum(label)/len(label))\n",
    "    print(top_n, sum(label)/len(label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
